\documentclass[12pt,a4paper,openright,twoside]{book}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{disi-thesis}
\usepackage{code-lstlistings}
\usepackage{notes}
\usepackage{shortcuts}
\usepackage{acronym}
\usepackage{placeins}
\usepackage{booktabs}
\usepackage{float}
\usepackage{microtype}

\school{\unibo}
\programme{Corso di Laurea in Ingegneria e Scienze Informatiche}
\title{Prompt-to-Action: un Model Context Protocol per l’integrazione real-time con configuratori 3D}
\author{Latini Luca}
\date{\today}
\subject{Computer Graphics}
\supervisor{Prof. Damiana Lazzaro}
\cosupervisor{Dott. Christian Lillini}
%\morecosupervisor{Dott. CoSupervisor 2}
\session{Sessione di laurea unica}
\academicyear{2024-2025}

% Definition of acronyms (keys in lowercase)
\acrodef{mcp}[\textit{MCP}]{\textit{Model Context Protocol}}
\acrodef{llm}[\textit{LLM}]{\textit{Large Language Model}}
\acrodef{api}[\textit{API}]{\textit{Application Programming Interface}}
\acrodef{lsp}[\textit{LSP}]{\textit{Language Server Protocol}}
\acrodef{ide}[\textit{IDE}]{\textit{Integrated Development Environment}}
\acrodef{ai}[\textit{AI}]{\textit{Artificial Intelligence}}
\acrodef{http}[\textit{HTTP}]{\textit{HyperText Transfer Protocol}}
\acrodef{lts}[\textit{LTS}]{\textit{Long Term Support}}
\acrodef{nlp}[\textit{NLP}]{\textit{Natural Language Processing}}
\acrodef{rfc}[\textit{RFC}]{\textit{Request for Comments}}
\acrodef{ietf}[\textit{IETF}]{\textit{Internet Engineering Task Force}}
\acrodef{tcp}[\textit{TCP}]{\textit{Transmission Control Protocol}}
\acrodef{rest}[\textit{REST}]{\textit{Representational State Transfer}}
\acrodef{tls}[\textit{TLS}]{\textit{Transport Layer Security}}
\acrodef{cors}[\textit{CORS}]{\textit{Cross-Origin Resource Sharing}}
\acrodef{nat}[\textit{NAT}]{\textit{Network Address Translation}}
\acrodef{sse}[\textit{SSE}]{\textit{Server-Sent Events}}
\acrodef{bom}[\textit{BOM}]{\textit{Bill of Materials}}
\acrodef{csp}[\textit{CSP}]{\textit{Constraint Satisfaction Problem}}
\acrodef{soa}[\textit{SOA}]{\textit{Service-Oriented Architecture}}
\acrodef{xhtml}[\textit{XHTML}]{\textit{Extensible HyperText Markup Language}}
\acrodef{ajax}[\textit{AJAX}]{\textit{Asynchronous JavaScript and XML}}
\acrodef{json}[\textit{JSON}]{\textit{JavaScript Object Notation}}
\acrodef{xml}[\textit{XML}]{\textit{eXtensible Markup Language}}
\acrodef{dbms}[\textit{DBMS}]{\textit{Database Management System}}
\acrodef{vr}[\textit{VR}]{\textit{Virtual Reality}}
\acrodef{nl}[\textit{NL}]{\textit{Natural Language}}
\acrodef{gcd}[\textit{GCD}]{\textit{Grammar Constrained Decoding}}
\acrodef{jwt}[\textit{JWT}]{\textit{JSON Web Token}}
\acrodef{crud}[\textit{CRUD}]{\textit{Create, Read, Update, Delete}}
\acrodef{oauth}[\textit{OAuth}]{\textit{Open Authorization}}
\acrodef{uri}[\textit{URI}]{\textit{Uniform Resource Identifier}}
\acrodef{webgl}[\textit{WebGL}]{\textit{Web Graphics Library}}
\acrodef{citygml}[\textit{CityGML}]{\textit{City Geography Markup Language}}
\acrodef{cswsh}[\textit{CSWSH}]{\textit{Cross-Site WebSocket Hijacking}}

\mainlinespacing{1.241} % line spacing in mainmatter, comment to default (1)

\raggedbottom
\begin{document}

\frontmatter\frontispiece

\begin{abstract}
Il presente lavoro di tesi descrive la progettazione e realizzazione di un prototipo di Model Context Protocol (MCP) volto a consentire il controllo e la configurazione di un configuratore grafico 3D mediante l’uso di prompt testuali. L’obiettivo principale è stato definire e implementare un meccanismo che traduca comandi descritti in linguaggio naturale nella chiamata automatica degli strumenti appropriati e nell’esecuzione delle operazioni corrispondenti all’interno del configuratore. Il sistema è realizzato in C\# e si articola in moduli per la gestione del contesto, l’invocazione dei tool e la comunicazione in tempo reale con il client grafico tramite WebSocket. Il lavoro comprende l’analisi dei requisiti, la progettazione dell’architettura software, l’implementazione dei moduli principali e la validazione funzionale tramite scenari di test. I risultati dimostrano la fattibilità del paradigma prompt\(\rightarrow\)tool per operazioni di gestione progetto nel configuratore, evidenziando punti di forza e limiti attuali in termini di robustezza semantica, gestione degli errori e scalabilità. Come contributo si propone un prototipo funzionante e linee guida per future estensioni, quali la gestione multi-utente.
\end{abstract}

\begin{dedication} % this is optional
Optional. Max a few lines.
\end{dedication}

%----------------------------------------------------------------------------------------
\tableofcontents
\listoffigures     % (optional) comment if empty
\lstlistoflistings % (optional) comment if empty
%----------------------------------------------------------------------------------------

\mainmatter

%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------
\chapter*{Introduzione}
\addcontentsline{toc}{chapter}{Introduzione}
\markboth{Introduzione}{Introduzione}
%Write your intro here.
%\sidenote{Add sidenotes in this way. They are named after the author of the thesis}

%You can use acronyms that your defined previously,
%such as \ac{IoT}.
%
%If you use acronyms twice,
%they will be written in full only once
%(indeed, you can mention the \ac{IoT} now without it being fully explained).
%
%In some cases, you may need a plural form of the acronym.
%
%For instance,
%that you are discussing \acp{vm},
%you may need both \ac{vm} and \acp{vm}.

Il lavoro di ricerca e sviluppo descritto in questa tesi è stato condotto nell'ambito di un tirocinio presso \textbf{Apra S.p.A.}, una realtà consolidata nel panorama delle software house italiane, attiva da oltre quarant'anni nella trasformazione digitale delle imprese. L'azienda si distingue per la sua competenza in settori strategici quali Cloud Computing, Big Data, Internet of Things e Industria 4.0, offrendo consulenza e soluzioni tecnologiche mirate all'ottimizzazione dei processi di business.

L'attività è stata svolta all'interno del team di Ricerca e Sviluppo, un'unità focalizzata sull'esplorazione di nuove paradigmi per l'orchestrazione tra servizi di Intelligenza Artificiale e applicazioni enterprise. In questo contesto, è emerso un forte interesse verso l'integrazione tra il Model Context Protocol (MCP) e interfacce utente specializzate, nello specifico configuratori grafici tridimensionali. Tale ambito, sebbene ancora poco esplorato in letteratura, presenta un potenziale significativo per l'evoluzione dei flussi di lavoro aziendali, promettendo di semplificare l'interazione uomo-macchina in scenari complessi.

Il progetto ha avuto una natura prettamente esplorativa, con l'intento di verificare la fattibilità tecnica di un sistema in cui un server MCP possa controllare un ambiente 3D. L'indagine si è concentrata sulla prototipazione e sulla valutazione dei pattern di integrazione necessari per far dialogare il server MCP con il client grafico attraverso un bridge \emph{real-time}. L'attenzione è stata posta sui vincoli operativi critici, quali i meccanismi di autenticazione, la sincronizzazione istantanea degli stati e la robustezza semantica nell'interpretazione dei comandi. Il risultato atteso non consiste in un prodotto commerciale finito, bensì in un insieme di evidenze empiriche e raccomandazioni architetturali che possano guidare futuri sviluppi, come l'eventuale integrazione di moduli di Natural Language Processing (NLP) o il supporto multi-utente.

Dal punto di vista infrastrutturale, il progetto ha preso le mosse da due asset tecnologici già presenti in azienda: un sistema di comunicazione \emph{real-time} basato su SignalR e un configuratore grafico 3D, responsabile del rendering e della logica di visualizzazione. Il compito fondamentale è stato quello di orchestrare questi elementi, sviluppando ex novo il server MCP e adattando il client grafico affinché potesse stabilire una connessione bidirezionale, interpretare i messaggi in ingresso e tradurli in azioni concrete sulla scena tridimensionale.


L'obiettivo generale del lavoro è la progettazione e la realizzazione di un prototipo operativo basato sul Model Context Protocol, capace di pilotare un configuratore 3D attraverso prompt testuali. Tale implementazione mira a validare la fattibilità dell'integrazione \emph{real-time} e a tracciare una roadmap tecnica per una possibile industrializzazione della soluzione.

Nello specifico, il progetto si è articolato in diverse fasi implementative. In primo luogo, è stato necessario sviluppare il nucleo logico del server MCP in linguaggio C\#, definendo i meccanismi che mappano le richieste testuali (prompt) in strumenti e comandi eseguibili (tool). Parallelamente, l'integrazione ha richiesto lo sfruttamento del bridge esistente basato su SignalR e WebSocket per stabilire un canale di comunicazione bidirezionale stabile e reattivo tra il server e l'interfaccia grafica.

Un aspetto cruciale ha riguardato l'adattamento del configuratore 3D: il software client è stato esteso per gestire la connessione al canale di messaggistica, decodificare le istruzioni provenienti dal server MCP e invocare le funzioni interne necessarie per aggiornare la vista o modificare il modello in tempo reale. A supporto dell'interazione, si è lavorato anche sul front-end, sviluppato in Svelte, per garantire un'interfaccia utente efficace nell'invio dei prompt e nella visualizzazione del feedback di sistema.

La validazione del sistema è stata condotta attraverso la definizione e la verifica di molteplici scenari d'uso \emph{end-to-end}, che spaziano dalla creazione di un nuovo progetto all'aggiunta di componenti specifici, fino alla consultazione del catalogo prodotti, coprendo le funzionalità core tipiche di un flusso di configurazione.

È opportuno precisare che il perimetro del progetto si è limitato all'integrazione e all'adattamento dei sistemi, escludendo lo sviluppo da zero di motori \emph{real-time} proprietari o la riscrittura del motore grafico. Inoltre, l'interpretazione dei comandi si basa su strutture predefinite, rimandando a sviluppi futuri l'implementazione di algoritmi avanzati per la comprensione del linguaggio naturale libero.

Il presente lavoro si articola in sei capitoli, strutturati per accompagnare il lettore dall'analisi teorica alla realizzazione pratica del sistema:

\begin{itemize}
    \item Il \textbf{Capitolo 1 (Introduzione)} presenta il contesto aziendale in cui è maturato il progetto presso Apra S.p.A., definendone le motivazioni e gli obiettivi principali.
    \item Il \textbf{Capitolo 2 (Background)} approfondisce lo stato dell'arte relativo al \ac{mcp}, alla comunicazione \emph{real-time} tramite WebSocket e ai principi di funzionamento dei moderni configuratori 3D.
    \item Il \textbf{Capitolo 3 (Stack Tecnologico)} descrive l'ecosistema software adottato, motivando la scelta di .NET 8, SignalR e delle tecnologie frontend impiegate.
    \item Il \textbf{Capitolo 4 (Progettazione del Sistema)} illustra l'architettura logica del prototipo, i moduli funzionali che lo compongono e i protocolli di scambio dati definiti per l'interazione tra IA e ambiente grafico.
    \item Il \textbf{Capitolo 5 (Implementazione)} analizza nel dettaglio lo sviluppo del server mcp in C\#, l'integrazione del bridge di messaggistica e l'adattamento del client grafico per l'esecuzione dei comandi.
    \item Il \textbf{Capitolo 6 (Conclusioni e sviluppi futuri)} sintetizza i risultati raggiunti, valuta l'efficacia del paradigma prompt-to-action e delinea i possibili sviluppi per l'estensione delle capacità del sistema.
\end{itemize}

\chapter{Fondamenti Teorici e Contesto Tecnologico}
\label{chap:background}
Questo capitolo introduce il contesto teorico e tecnologico di riferimento del lavoro di tesi. L’obiettivo è fornire le basi necessarie per comprendere le tecnologie utilizzate e le motivazioni che hanno guidato le scelte progettuali.

Nella prima parte viene analizzato il problema della frammentazione nell’ecosistema dell’intelligenza artificiale e viene presentato il Model Context Protocol come proposta di standard per migliorare l’interoperabilità tra modelli e sistemi esterni. Successivamente viene descritto il protocollo WebSocket, evidenziandone il ruolo nella comunicazione real-time e il suo utilizzo attraverso framework di più alto livello. L’ultima parte del capitolo è dedicata ai configuratori 3D, al loro funzionamento e alle principali sfide legate alla loro integrazione con sistemi di intelligenza artificiale.

Questo inquadramento permette di collocare il progetto all’interno di un contesto più ampio e di preparare il lettore alla descrizione delle soluzioni adottate nei capitoli successivi.

\section{La Crisi della Frammentazione nell'Ecosistema AI}
Modelli Linguistici di Grande Scala (LLM) sono diventati centrali nell'Intel\-ligenza Artificiale (Artificial Intelligence) moderna, dimostrando capacità straordinarie nella comprensione e generazione del linguaggio naturale \cite{mcp_survey_kent}, e alimentando agenti autonomi che operano in ambienti cloud, edge e desktop\cite{mcp_survey_kent}. Questi agenti sono cruciali per automatizzare compiti complessi ed eseguire azioni interagendo con servizi o strumenti esterni.\cite{mcp_karimova_analysis}

Nonostante i rapidi progressi nel ragionamento degli LLM, essi rimangono intrinsecamente vincolati dalla dipendenza da dataset di addestramento statici, limitando la loro applicabilità in scenari dinamici e in tempo reale \cite{mcp_survey_aditi}. Tradizionalmente, l'integrazione degli LLM con sistemi esterni si è basata su interfacce di programmazione (\textit{Application Programming Interface (API)}) frammentate e costruite su misura.\cite{mcp_survey_kent}

Questa mancanza di standardizzazione crea una crisi di frammentazione\cite{mcp_survey_transport}, ostacolando la scalabilità, la sicurezza e la generalizzazione della comunicazione tra agenti guidati dagli LLM\cite{mcp_survey_kent}. Le integrazioni ad-hoc comportano una duplicazione dello sforzo di sviluppo, aumentano la complessità, e introducono inconsistenze di sicurezza\cite{mcp_survey_aditi}. Per ottenere flussi di lavoro multi-agente modulari, riutilizzabili e resilienti, l'interoperabilità,la capacità dei sistemi distinti di scoprire capacità, scambiare contesto e coordinare azioni in modo fluido, è considerata essenziale.\cite{mcp_survey_kent}

\section{Definizione e Ruolo del Model Context Protocol (MCP)}
\label{sec:mcp-definition}
Per rispondere a questa esigenza sistemica di standardizzazione, Anthropic ha introdotto il \ac{mcp} nel novembre 2024 \cite{mcp_anthropic_launch}. Questo standard open-source nasce con l'ambizione di unificare il modo in cui le applicazioni basate su intelligenza artificiale comunicano con sistemi esterni, superando la frammentazione delle integrazioni ad-hoc che caratterizza l'attuale panorama tecnologico \cite{mcp_doc_whatis}.

La metafora utilizzata per descrivere l'MCP è quella della "porta USB-C per l'AI": così come lo standard USB-C ha reso universale la connettività fisica tra dispositivi eterogenei, l'MCP si propone di fornire un'interfaccia unificata attraverso cui gli LLM possono accedere a dati e strumenti esterni in modo predicibile e sicuro \cite{mcp_doc_whatis}. L'analogia non è casuale e si inserisce in una tradizione consolidata di protocolli di standardizzazione che hanno rivoluzionato i rispettivi domini: le \ac{api} REST per l'interoperabilità web e il (Language Server Protocol (LSP)) per l'integrazione degli strumenti di sviluppo negli \ac{ide} moderni rappresentano precedenti significativi di questo approccio architetturale \cite{mcp_doc_whatis}.

L'obiettivo fondamentale dell'MCP è permettere la sostituzione delle integrazioni frammentate e proprietarie con un protocollo condiviso che riduca gli sforzi in fase di sviluppo e migliorare l'efficacia degli LLM fornendo loro accesso strutturato a contesti dinamici e aggiornati, superando il limite intrinseco dei dataset di addestramento statici. Questo secondo aspetto è particolarmente rilevante in scenari applicativi dove la pertinenza delle risposte dipende dalla capacità del modello di accedere a informazioni in tempo reale, come cataloghi prodotti, database aziendali o interfacce di controllo di sistemi complessi.

\subsection{Architettura e Componenti Centrali}
\label{subsec:sicurezza-autenticazione}
L'architettura dell'MCP segue un modello client-server persistente progettato per gestire l'interazione strutturata tra modelli linguistici e risorse esterne. L'ecosistema è composto da tre organi principali ciascuno dei quali ha responsabilità ben definite che garantiscono la separazione dei compiti e la modularità del sistema \cite{mcp_doc_arch}.

L'\textbf{MCP Host} rappresenta l'applicazione di front-end che orchestra l'intera esperienza utente. Tipicamente rappresentato da strumenti come Claude Desktop o ambienti di sviluppo integrati, l'Host funge da contenitore per il modello linguistico e coordina le connessioni verso uno o più Server MCP. La sua responsabilità critica risiede nella gestione del consenso dell'utente. Prima di accedere a dati sensibili o eseguire azioni potenzialmente impattanti, l'Host deve richiedere e ottenere l'autorizzazione esplicita dell'utilizzatore finale. Inoltre, quando il contesto necessario per rispondere a una richiesta proviene da multiple sorgenti, l'Host si occupa di aggregare le informazioni raccolte dai vari client e di presentarle al modello in forma coerente \cite{mcp_doc_arch}.

L'\textbf{MCP Client} opera come componente di traduzione e mediazione. Ogni istanza di client mantiene una connessione dedicata uno-a-uno con un singolo Server MCP, responsabilizzandosi della conversione bidirezionale dei messaggi: trasforma le richieste dell'LLM, spesso espresse come chiamate a funzioni strutturate, nel formato wire del protocollo MCP, e viceversa converte le risposte del server in rappresentazioni comprensibili al modello linguistico. Il client gestisce anche la fase di discovery, identificando i server disponibili nell'ambiente e le capacità che ciascuno espone \cite{mcp_doc_arch}.

L'\textbf{MCP Server} costituisce il punto di integrazione effettivo con sistemi e dati esterni. Ogni server è progettato per concentrarsi su un dominio specifico, ad esempio l'accesso a un database, l'interazione con un'API REST, o il controllo di un'applicazione desktop. Questa specializzazione favorisce la riutilizzabilità e semplifica la manutenzione. I server possono operare in modalità locale, comunicando tramite standard input/output (Stdio) per minimizzare l'overhead di rete, oppure in modalità remota attraverso protocolli HTTP, permettendo deployment distribuiti e scenari cloud-native \cite{mcp_doc_arch}.

Dal punto di vista implementativo, il protocollo si articola su due strati ben distinti che riflettono la classica separazione tra semantica e trasporto nelle architetture di rete \cite{mcp_survey_aditi, mcp_doc_arch}. Il \textbf{Data Layer} definisce la struttura logica delle interazioni, basandosi sulla specifica JSON-RPC 2.0 per la serializzazione dei messaggi. Questo livello regola il ciclo di vita delle connessioni, inclusa la fase di negoziazione iniziale delle capacità supportate da client e server, e definisce i primitivi fondamentali del protocollo che verranno discussi nella sezione successiva. Il \textbf{Transport Layer}, invece, si occupa della trasmissione fisica dei dati. L'MCP supporta nativamente due modalità di trasporto: lo Stdio, ottimale per comunicazioni locali tra processi sulla stessa macchina grazie all'assenza di overhead di rete, e lo Streamable HTTP, che sfrutta richieste POST per i messaggi client-server e opzionalmente Server-Sent Events per lo streaming di risposte lunghe, con supporto integrato per meccanismi di autenticazione standard come bearer token o OAuth \cite{mcp_doc_arch, mcp_survey_kent}.
Il concetto di \textbf{primitive} rappresenta il nucleo semantico dell'MCP. Esse vanno a definire le modalità attraverso cui i server possono esporre funzionalità e contesto alle applicazioni basate su intelligenza artificiale. La specifica distingue tre categorie principali di primitive, ciascuna con un diverso modello di controllo che riflette la natura dell'interazione \cite{mcp_doc_servers}.

I \textbf{Tools} (strumenti) costituiscono primitive controllate dal modello linguistico stesso. Quando un LLM determina che per rispondere a una richiesta utente è necessario eseguire un'azione specifica, come interrogare un database o invocare un'API esterna, può decidere autonomamente di chiamare uno degli strumenti esposti dal server MCP. Questa capacità di invocazione dinamica rappresenta il cuore dell'agentic AI, permettendo ai modelli di andare oltre la semplice generazione testuale per interagire concretamente con sistemi esterni. Ad esempio, uno strumento potrebbe permettere al modello di creare un nuovo record in un gestionale aziendale o di recuperare informazioni in tempo reale da un catalogo prodotti \cite{mcp_doc_servers}.

Le \textbf{Resources} (risorse) sono invece primitive controllate dall'applicazione host. Rappresentano sorgenti di dati strutturati in sola lettura che arricchiscono il contesto disponibile al modello senza richiederne l'invocazione esplicita. Ogni risorsa è identificata da un uri univoco che ne specifica la natura e la locazione, seguendo convenzioni familiari come \texttt{file:///path/to/document.md} per file locali o schemi custom per risorse specializzate. Questo approccio dichiarativo permette all'applicazione di decidere quali contesti rendere disponibili, mantenendo il controllo sulla sicurezza e sull'accesso ai dati sensibili \cite{mcp_doc_servers}.

I \textbf{Prompts} (template) sono primitive controllate dall'utente finale, progettate per standardizzare e parametrizzare pattern di interazione ricorrenti. Attraverso template riutilizzabili, gli utenti possono definire flussi di lavoro complessi che combinano più operazioni in sequenze coerenti, garantendo consistenza nelle modalità di interrogazione del sistema. Questa categoria di primitive risulta particolarmente utile in contesti aziendali dove procedure standard devono essere ripetute con variazioni parametriche, permettendo di astrarre la complessità sottostante attraverso interfacce semplificate \cite{mcp_doc_servers}.

\subsection{Primitive Bidirezionali e Interazione Utente}
Oltre alle primitive esposte dai server, la specifica MCP definisce meccanismi che i server possono utilizzare per invocare funzionalità sul lato client, abilitando interazioni bidirezionali più sofisticate e mantenendo l'utente umano al centro del processo decisionale \cite{mcp_doc_clients}.

Il meccanismo di \textbf{Sampling} permette ai server di richiedere al client l'esecuzione di inferenze da parte dell'LLM senza essere direttamente accoppiati a un modello specifico. Questa astrazione è fondamentale in scenari dove il server necessita di capacità di elaborazione del linguaggio naturale, ad esempio per generare sintesi di documenti o estrarre informazioni strutturate da testo libero. Come illustrato in Figura \ref{fig:sampling}, il flusso prevede che il server invii una richiesta di completamento al client, il quale la sottopone al modello linguistico. Prima di restituire il risultato al server, il sistema può richiedere l'approvazione esplicita dell'utente, implementando così un pattern di \emph{human-in-the-loop} che garantisce supervisione e controllo sulle operazioni potenzialmente sensibili \cite{mcp_doc_clients}.

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=.8\linewidth]{figures/Sampling.png}
  \caption{Architettura del primitive Sampling nel \ac{mcp} che mostra il ciclo di richiesta–inferenza–approvazione tra client, server e utente umano.\cite{mcp_doc_clients}}
  \label{fig:sampling}
\end{figure}

\FloatBarrier

La primitive di \textbf{Elicitation} affronta invece la necessità di raccogliere input specifici dall'utente durante l'esecuzione di operazioni complesse. Quando un server decide che per completare un'azione è necessaria una conferma esplicita o un parametro aggiuntivo, può invocare il client richiedendo l'interazione diretta con l'utilizzatore. Questo pattern risulta essenziale in scenari transazionali come la finalizzazione di una prenotazione o l'autorizzazione di un pagamento, dove la conferma umana rappresenta un requisito necessario. La Figura \ref{fig:Elicitation} illustra il ciclo completo di richiesta, interazione con l'utente e restituzione della risposta al server \cite{mcp_doc_clients}.

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=.8\linewidth]{figures/Elicitation.png}
  \caption{Architettura del primitive Elicitation nell'MCP che mostra il ciclo di richiesta-interazione umana-risposta tra Server, Client e utente.\cite{mcp_doc_clients}}
\label{fig:Elicitation}
\end{figure}

\FloatBarrier

Il concetto di \textbf{Roots} introduce un meccanismo per definire i confini logici entro cui i server devono operare. Tipicamente utilizzato per determinare quali porzioni di filesystem o scope operativi specifici possono essere utilizzati, queste primitive guidano i server nella selezione delle risorse su cui concentrare le proprie attività, evitando accessi non autorizzati o sprechi computazionali dovuti all'analisi di dati irrilevanti \cite{mcp_doc_clients}.

\subsection{Vantaggi Sistemici dell'Adozione MCP}
L'introduzione di uno standard condiviso per l'integrazione tra sistemi AI e risorse esterne genera benefici che trascendono il singolo progetto, impattando l'intero ecosistema di sviluppo e deployment di applicazioni intelligenti.

La \textbf{standardizzazione} costituisce il vantaggio più immediato e tangibile. Elimi(\-)nando la necessità di sviluppare integrazioni proprietarie per ciascuna combinazione LLM-sistema esterno, il protocollo riduce drasticamente il numero di sforzi ingegneristici e permette agli sviluppatori di concentrarsi sulla logica di business piuttosto che sulla gestione dell'infrastruttura di comunicazione. Il codice di integrazione diventa riutilizzabile attraverso diverse applicazioni AI, accelerando il time-to-market e riducendo i costi di sviluppo \cite{mcp_doc_whatis, mcp_karimova_analysis}.

Sull'aspetto della \textbf{sicurezza}, l'MCP promuove l'adozione di pattern consolidati per l'autenticazione, l'autorizzazione e l'audit delle operazioni. La presenza di meccanismi standardizzati riduce le vulnerabilità introdotte da implementazioni ad-hoc e facilita la conformità a requisiti normativi in settori regolamentati. La trasparenza delle interazioni, garantita dal logging strutturato delle chiamate a strumenti e risorse, supporta inoltre attività di troubleshooting e analisi forense \cite{mcp_survey_aditi, mcp_karimova_analysis}.

La \textbf{composabilità} del protocollo abilita architetture modulari dove i componenti possono essere sviluppati, testati e scalati indipendentemente. Particolarmente rilevante è la capacità dei nodi di funzionare contemporaneamente come client e server, permettendo la costruzione di catene di agenti gerarchiche dove server intermedi aggregano e trasformano dati provenienti da server di livello inferiore prima di esporli ai client di livello superiore. Questa flessibilità architetturale supporta scenari complessi tipici di sistemi enterprise distribuiti \cite{mcp_survey_aditi, mcp_karimova_analysis}.

Infine, dal punto di vista strategico, l'MCP si posiziona come fondamento di una roadmap evolutiva più ampia nell'ecosistema dei protocolli AI. La sua adozione rappresenta un primo passo verso standard più sofisticati per la coordinazione multi-agente (Agent-to-Agent protocols) e la gestione di workflow complessi, fungendo da base tecnica e concettuale per future iterazioni del panorama tecnologico \cite{mcp_survey_kent}.

\section{WebSocket: Protocollo per Comunicazione Real-Time}
\label{sec:websocket-protocollo}
%----------------------------------------------------------------------------------------

% NUOVA SEZIONE - Contenuto teorico compatto (1-1.5 pagine)
%
% Contenuti da sviluppare:
%
% A) Introduzione WebSocket (0.5 pagine):
% - RFC 6455: standard IETF per comunicazione bidirezionale full-duplex
% - Problema risolto: limitazioni HTTP polling (overhead, latenza, scalabilità)
% - Handshake HTTP Upgrade: transizione da HTTP a protocollo WebSocket
% - Connessione persistente su TCP: mantiene socket aperto per comunicazione continua
%
% B) Caratteristiche Protocollo (0.5 pagine):
% - Full-duplex: client e server inviano messaggi contemporaneamente
% - Low-latency: no overhead header HTTP ripetuti (frame leggeri)
% - Message-oriented: supporto frame text (UTF-8) e binary
% - Keep-alive: ping/pong frames per mantenere connessione attiva
%
% C) Vantaggi WebSocket (0.25 pagine):
% - Performance: riduzione latenza 50-80% vs HTTP long polling
% - Scalabilità: minor overhead rete, meno connessioni simultanee
% - Real-time bidirectional: server push senza polling client
% - Supporto browser: standard nativo (Chrome, Firefox, Safari, Edge)
%
% D) Limitazioni Protocollo (0.25 pagine):
% - No fallback automatico: se WebSocket non supportato, connessione fallisce
% - Riconnessione manuale: developer deve implementare retry logic
% - Gestione stato: server deve tracciare connessioni attive (memory overhead)
% - Sicurezza: richiede WSS (WebSocket Secure su TLS) per traffico cifrato
% - Cross-origin: CORS deve essere configurato correttamente
%
% E) Collegamento con il Progetto (breve paragrafo):
% - WebSocket è fondamento per SignalR (astrazione high-level)
% - Progetto usa SignalR invece di WebSocket raw per produttività e robustezza
% - Dettagli implementativi SignalR in Cap. 3 Stack Tecnologico
%
% NO code snippet (protocollo standard, teoria)
%
% Elementi visivi OPZIONALI:
% - Diagramma handshake HTTP → WebSocket upgrade
% - Tabella confronto HTTP polling vs WebSocket (latenza, overhead, scalabilità)
%
% Pagine stimate: 1-1.5\section{Introduzione al protocollo WebSocket}

Il protocollo WebSocket, standardizzato dall’IETF con la RFC~6455 nel dicembre 2011 \cite{fette_rfc6455}, rappresenta la tecnologia di riferimento per la gestione di comunicazioni bidirezionali (\emph{full-duplex}) e persistenti tra client e server. Nato con l'obiettivo di superare i limiti dell'architettura RESTful tradizionale, questo standard definisce un meccanismo di trasporto su TCP che, pur mantenendo la compatibilità con l'infrastruttura web esistente (come proxy e firewall), si discosta radicalmente dal modello richiesta-risposta tipico di HTTP \cite{fette_rfc6455}.

Il ciclo di vita di una connessione WebSocket inizia con una fase di negoziazione, nota come \emph{opening handshake}, che sfrutta lo stesso protocollo HTTP per stabilire il canale. Il client invia una richiesta \texttt{GET} contenente l'header \texttt{Upgrade: websocket}, segnalando l'intenzione di cambiare protocollo; se il server accetta la richiesta, risponde con lo stato \texttt{101 Switching Protocols} \cite{fette_rfc6455}. Terminato questo scambio iniziale, il protocollo HTTP viene abbandonato e la connessione TCP sottostante rimane aperta, andando a creare un tunnel persistente per lo scambio continuo di dati.

Tale approccio risolve le inefficienze storiche legate alle tecniche di \emph{polling} o \emph{long-polling}, dove il client era costretto a interrogare periodicamente il server o a mantenere aperte connessioni HTTP multiple in attesa di dati. WebSocket ha eliminando la necessità di instaurare nuove connessioni TCP e di inviare ridondanti header HTTP per ogni singolo messaggio,  riducendo drasticamente l'overhead di rete e la latenza, aprendo a nuovi scenari real-time ad alte prestazioni come dashboard finanziarie, giochi multiplayer o sistemi di messaggistica istantanea \cite{microsoft_signalr_docs}.

\subsection{Caratteristiche architetturali}

La peculiarità fondamentale del protocollo risiede nella sua natura \emph{full-duplex}, che disaccoppia la comunicazione dalla logica di richiesta esplicita: client e server possono trasmettere dati in qualsiasi momento e in modo indipendente l'uno dall'altro \cite{fette_rfc6455} determinando una maggiore libertà operativa. Essa è supportata da una struttura orientata ai messaggi (\emph{message-oriented}), che si contrappone al flusso di byte continuo ("stream") tipico del TCP puro. I dati applicativi vengono incapsulati in unità discrete denominate \emph{frame}, le quali possono trasportare payload testuali (codificati in UTF-8) o binari, semplificando notevolmente l'implementazione lato applicativo rispetto alla gestione diretta dei socket grezzi \cite{fette_rfc6455}.

L'efficienza del protocollo è garantita da un framing estremamente leggero. A differenza dei pacchetti HTTP, che trasportano corposi metadati a ogni scambio, i frame WebSocket aggiungono solo pochi byte di intestazione al payload utile. Questo design minimizza il consumo di banda e riduce significativamente la latenza percepita rispetto alle soluzioni basate su polling, eliminando il ritardo introdotto dall'instaurazione ripetuta delle connessioni \cite{microsoft_signalr_docs}. Inoltre, il protocollo prevede frame di controllo specifici, come \emph{Ping} e \emph{Pong}, essenziali per monitorare lo stato di salute della connessione (heartbeat). Tramite tali meccanismi gli endpoint sono in grado di rilevare disconnessioni anomale e di mantenere attivo il canale anche in presenza di NAT o proxy che potrebbero chiudere le connessioni inattive, garantendo così la stabilità e l'affidabilità necessarie per le moderne applicazioni web \cite{fette_rfc6455}.

\subsection{Vantaggi operativi e prestazionali}

L’adozione dello standard WebSocket comporta un significativo avanzamento rispetto alle architetture tradizionali basate su polling, offrendo benefici concreti in ambito  di efficienza di rete che di reattività applicativa. Il vantaggio più immediato risiede nel drastico abbattimento della latenza \emph{end-to-end}. Eliminando la necessità di negoziare ripetutamente la connessione e di trasmettere ridondanti header HTTP per ogni scambio di dati, il protocollo minimizza l’overhead strutturale successivo all'\emph{handshake} iniziale. Le documentazioni tecniche confermano come questa ottimizzazione del payload garantisca un utilizzo della larghezza di banda strettamente limitato ai dati applicativi reali, superando le limitazioni prestazionali del \emph{long-polling} \cite{microsoft_signalr_docs}.

La peculiarità della leggerezza strutturale apporta dei vantaggi anche sulla scalabilità lato server. A differenza del polling, che invia al backend migliaia di richieste HTTP distinte, WebSocket mantiene attive singole connessioni TCP persistenti. Questo modello riduce il carico computazionale necessario per l'apertura e chiusura dei socket, permettendo all'infrastruttura di gestire un numero elevato di connessioni concorrenti con un consumo di risorse contenuto \cite{microsoft_signalr_docs}. Tale caratteristica rende l'architettura particolarmente idonea per scenari ad alta densità di utenti, facilitando le strategie di scaling orizzontale.

Dal punto di vista funzionale, il protocollo abilita un vero e proprio modello di comunicazione \emph{push} proattivo. Il server diviene in grado di trasmettere informazioni al client istantaneamente, non appena queste divengono disponibili, svincolandosi dalle logiche di richiesta esplicita. Tale cambio di paradigma è fondamentale per l'implementazione di funzionalità \emph{real-time} moderne, come chat, notifiche istantanee o dashboard live, senza ricorrere a complessi meccanismi di sincronizzazione. Infine, l'affermazione dell'ecosistema garantisce un'ampia interoperabilità: il supporto nativo dell'API \texttt{WebSocket} in tutti i moderni browser e l'integrazione nei principali framework lato server (incluso l'ambiente .NET tramite SignalR \cite{ms_signalr_intro}) rendono l'adozione di questa tecnologia uno standard de facto, privo della necessità di plugin esterni o soluzioni proprietarie.

\subsection{Limitazioni intrinseche e sfide implementative}

Sebbene il protocollo WebSocket offra innegabili vantaggi in termini di latenza e ridotto overhead, la sua adozione introduce complessità architetturali non trascurabili rispetto al modello HTTP stateless tradizionale. Una prima criticità riguarda la gestione delle risorse lato server, infatti la natura persistente della connessione impone che il server mantenga attivo lo stato per ogni client collegato, gestendo allocazione di memoria, socket aperti e meccanismi di \emph{heartbeat} (ping/pong). In scenari ad alta concorrenza, ciò comporta un consumo di risorse significativamente superiore rispetto a un approccio stateless, richiedendo strategie di scalabilità orizzontale più sofisticate.

Un ulteriore ostacolo risiede nell'affidabilità della connessione in ambienti di rete eterogenei. Il protocollo, nella sua forma "grezza" (\emph{raw}), non prevede meccanismi nativi di fallback, indispensabili qualora la connessione non possa essere stabilita a causa di proxy restrittivi, firewall aziendali o client obsoleti, la comunicazione fallisce senza alternative automatiche. Spetta dunque allo sviluppatore il compito di implementare logiche personalizzate di riconnessione o di degradazione verso protocolli alternativi.

Infine, vanno considerati gli aspetti di sicurezza. L'utilizzo del protocollo su canali cifrati (\texttt{wss://}) è doveroso per proteggere l'integrità dei dati, introducendo tuttavia un costo computazionale aggiuntivo per le operazioni crittografiche TLS. Parallelamente, il modello di sicurezza differisce da quello delle richieste HTTP standard dove le policy CORS (Cross-Origin Resource Sharing) non si applicano direttamente all'handshake WebSocket, costringendo il server a validare esplicitamente l'header \texttt{Origin} per prevenire attacchi di tipo Cross-Site WebSocket Hijacking (CSWSH).

\subsection{Adozione di SignalR nel contesto progettuale}

Alla luce delle sfide operative sopra discusse, l'architettura del progetto realizzato in questa tesi ha previsto l'integrazione di SignalR come livello di astrazione per la gestione della comunicazione real-time. Questa scelta strategica permette di beneficiare delle prestazioni del protocollo WebSocket, utilizzato come trasporto preferenziale in conformità alla RFC 6455, alleggerendone al contempo le rigidità strutturali \cite{ms_signalr_intro}.

Il vantaggio determinante di SignalR risiede nella sua capacità di negoziare automaticamente il miglior trasporto disponibile. Qualora l'ambiente di rete non supporti WebSocket, la libreria esegue un fallback trasparente verso tecnologie alternative, come i Server-Sent Events (SSE) o il long-polling, garantendo la continuità del servizio senza richiedere interventi manuali nel codice applicativo. Delegando al framework la complessità della gestione delle connessioni, delle riconnessioni automatiche e della compatibilità trasversale, è stato possibile concentrare lo sviluppo sulla logica di business, aumentando la robustezza complessiva del sistema. I dettagli implementativi e la configurazione specifica di SignalR all'interno dello stack tecnologico verranno analizzati approfonditamente nel Capitolo 3.


\section{Panoramica e contesto su i Configuratori 3D}

Nel contesto dell'informatica applicata ai processi industriali e commerciali, la configurazione di prodotto rappresenta un'attività progettuale specifica che interviene a valle della definizione ingegneristica primaria \cite{zhang2014product}. Essa può essere definita come il processo di composizione di un prodotto personalizzato partendo da un insieme predefinito di componenti, parti o assemblaggi, nel rispetto di un set di vincoli ben determinati che limitano le modalità di selezione e combinazione degli elementi stessi \cite{zhang2014product}. L'obiettivo finale di tale processo, supportato da sistemi software denominati configuratori, è la generazione di una specifica di prodotto valida, che includa distinta base (BOM), parametri di design e relazioni strutturali \cite{zhang2014product}.

L'evoluzione verso la \textit{Mass Customization} ha reso necessario lo sviluppo di piattaforme che permettano al cliente di interagire direttamente con lo "spazio delle soluzioni" del prodotto \cite{haug2009from}. In questo scenario, i configuratori 3D assumono un ruolo cruciale, non limitandosi alla sola selezione delle opzioni proposte, ma offrendo una visualizzazione in tempo reale delle scelte effettuate. La letteratura identifica nella rappresentazione visiva un elemento critico,infatti, mentre i configuratori tradizionali possono limitarsi a descrizioni testuali o bidimensionali, le moderne piattaforme web-based integrano tecnologie di visualizzazione 3D per colmare il divario tra le aspettative del cliente e il prodotto finale \cite{amirebrahimi2012integrated}. Tuttavia, l'efficacia di tali sistemi dipende strettamente dalla capacità di gestire la complessità computazionale e la trasmissione dei dati su reti web, spesso ricorrendo a tecnologie come WebGL o viewer basati su plugin (ad esempio Google Earth API o standard CityGML) per il rendering della scena \cite{amirebrahimi2012integrated}.

\subsection{Gestione delle Regole e Motore di Configurazione}

Il cuore funzionale di un configuratore non risiede solamente nella sua interfaccia grafica, ma nel motore logico che regola la coerenza del prodotto. La configurazione opera all'interno di uno spazio di soluzioni predefinito, caratterizzato da processi stabili ma flessibili \cite{haug2009from}. Per gestire questa complessità, il sistema deve contenere conoscenze del dominio organizzate in ontologie, vincoli e regole \cite{zhang2014product}.

Le regole di configurazione permettono di porre un controllo sulla fattibilità tecnica definendo le relazioni tra i componenti (ad esempio, "Se viene selezionato il Componente A, allora il Componente B è obbligatorio") e prevengono combinazioni invalide. In contesti ingegneristici complessi (\textit{Engineer-To-Order}), la sfida principale nella progettazione del configuratore risiede proprio nella costruzione di una base di conoscenza (\textit{Knowledge Base}) robusta, capace di automatizzare compiti di specificazione che tradizionalmente richiederebbero l'intervento umano \cite{haug2009from}. Modellare tale conoscenza può avvalersi di approcci basati su \textit{Constraint Satisfaction Problems} (CSP), che permettono al sistema di verificare la consistenza delle scelte dell'utente e, se necessario, proporre spiegazioni o diagnosi in caso di conflitti \cite{zhang2014product}.

\subsection{Calcolo Dinamico e Output del Processo}

Parallelamente alla validazione tecnica, il configuratore deve gestire gli aspetti economici e documentali della transazione. Sebbene in un contesto di \textit{Mass Customization} l'obiettivo sia mantenere i prezzi vicini a quelli della produzione di massa, nei sistemi complessi il configuratore agisce spesso come strumento di automazione per la generazione di preventivi (quotazioni) \cite{haug2009from}.

Il calcolo dinamico del prezzo avviene in tempo reale in risposta alle modifiche apportate dall'utente alla configurazione 3D. Il sistema associa a ogni componente o variante selezionata un valore economico, aggiornando istantaneamente il totale. Al termine del processo, l'output non è limitato alla sola visualizzazione a schermo ma  il configuratore deve essere in grado di esportare dati strutturati necessari per la produzione e la vendita. Essi includono tipicamente la distinta base (BOM), i piani di instradamento (\textit{routing plans}), le specifiche tecniche dettagliate e la documentazione di offerta \cite{zhang2014product}. In alcuni scenari avanzati, come nel settore dell'impiantistica o dell'ingegneria civile, l'automazione riguarda la creazione di specifiche di prodotto complete che fungono esse stesse da output primario del processo \cite{haug2009from}.

\subsection{Architettura del Sistema: Frontend, Backend e Scambio Dati}

Dal punto di vista dell'implementazione tecnica, un configuratore 3D moderno adotta tipicamente un'Architettura Orientata ai Servizi (SOA), strutturata in livelli concettuali distinti che garantiscono modularità e scalabilità \cite{amirebrahimi2012integrated}.
\begin{itemize}
  \item Il livello di \textbf{Frontend:} (o \textit{Presentation Layer}) è responsabile dell'interfaccia utente e della visualizzazione 3D. Implementato  tramite tecnologie web standard (XHTML dinamico, Ajax, JavaScript), questo livello gestisce l'interazione con l'utente e comunica con il server per aggiornare la scena \cite{amirebrahimi2012integrated}. La visualizzazione 3D richiede la gestione efficiente di oggetti geometrici complessi per questo è essenziale ottimizzare il formato di scambio dati tra client e server. Sebbene l'XML (\textit{eXtensible Markup Language})sia stato storicamente utilizzato, è stato osservato che esso comporta un \textit{overhead} eccessivo per la trasmissione di grandi moli di dati geometrici. Di conseguenza, formati più compatti come JSON (\textit{JavaScript Object Notation}) sono preferibili per garantire prestazioni elevate e ridurre i tempi di caricamento nel viewer 3D \cite{amirebrahimi2012integrated}.
  \item  Il \textbf{Backend} ospita il motore della piattaforma (\textit{Platform Engine} o \textit{Business Layer}). Questo livello contiene i componenti core che eseguono la logica di business, gestiscono il \textit{workflow} di configurazione e coordinano l'analisi dei modelli \cite{amirebrahimi2012integrated}. È in questo strato che risiede il \textit{Model Coordinator}, responsabile di orchestrare gli input e gli output dei vari moduli di calcolo e assicura che i dati scambiati tra le componenti siano semanticamente coerenti
  \item Infine, il livello \textbf{Database} (o \textit{Data Layer}) costituisce il repository per la persistenza dei dati. In applicazioni che richiedono la gestione di oggetti spaziali e modelli 3D, è necessario utilizzare \textit{Database Management Systems} (DBMS) capaci di gestire dati spaziali e non spaziali, timestamp e metadati relativi alle librerie di modelli \cite{amirebrahimi2012integrated}. L'accesso a questi dati è gestito da un livello di accesso ai dati (\textit{Data Access Layer}) in grado di diminuire la complessità delle query dirette al database grazie all'esposione di  API per il recupero e la manipolazione degli oggetti necessari alla configurazione. Questa separazione garantisce che la logica di visualizzazione nel frontend rimanga disaccoppiata dalla struttura fisica di memorizzazione dei dati, facilitando la manutenzione e l'evoluzione futura del sistema \cite{amirebrahimi2012integrated}.
\end{itemize}

\subsection{Casi d'uso e applicazioni dei configuratori 3D}

L'adozione di configuratori 3D nell'ambito della mass customization rappresenta un punto di svolta nell'interazione tra aziende e consumatori, andando a creare un  valore sia per chi acquista sia per chi produce. L'analisi della letteratura scientifica permette di comprendere come questi strumenti si inseriscano in diversi contesti applicativi, con impatti concreti su molteplici dimensioni del processo di acquisto e produzione.

La mass customization, definita come la capacità di fornire prodotti personalizzati a ogni cliente attraverso agilità, flessibilità e integrazione di processo \cite{frutos2004decision}, trova nei configuratori 3D uno degli strumenti più efficaci per conciliare la produzione di massa con le esigenze individuali dei clienti. L'obiettivo primario è fornire prodotti che rispondano al meglio alle scelte reali dei clienti, basate su necessità e preferenze specifiche, mantenendo al contempo un'efficienza prossima a quella della produzione di massa \cite{frutos2004decision}. I configuratori 3D si collocano in questo contesto come mediatori tra la complessità tecnica del design modulare e la semplicità richiesta dall'esperienza utente.

Uno dei settori in cui i configuratori 3D hanno dimostrato particolare efficacia è quello della personalizzazione di prodotti complessi e costosi, come nel caso della configurazione di appartamenti residenziali. In tale ambito, i configuratori permettono ai clienti di navigare tra componenti e opzioni offerte dall'azienda, definendo vincoli e regole relative alle configurazioni possibili del prodotto \cite{frutos2004decision}. La modularità dei prodotti, basata sulla composizione di componenti standard o sulla variazione controllata di elementi predefiniti, favorisce l'uso di interfacce 3D che rendono le scelte immediatamente comprensibili.

Dal \textbf{punto di vista del cliente:}

I configuratori 3D rispondono a una lacuna fondamentale dei siti di e-commerce tradizionali, ovvero la carenza di esperienze di acquisto che si avvicinino alla realtà. Le interfacce 2D, basate su immagini statiche e testo, non permettono ai consumatori di sviluppare una sensazione di presenza, interattività e coinvolgimento collaborativo \cite{elradi2017commerce}. Al contrario, gli ambienti 3D simulano spazi reali, offrono modelli di prodotto tridimensionali e consentono ai clienti di navigare virtualmente attraverso le proprie scelte, replicando dinamiche tipiche dei negozi fisici. Questa esperienza immersiva migliora significativamente la qualità percepita dell'interazione e la soddisfazione complessiva del consumatore.

In particolare, l'integrazione di tecnologie di realtà virtuale (VR) negli ambienti di e-commerce 3D consente ai clienti di sperimentare i prodotti in modo più realistico prima dell'acquisto, superando i limiti delle recensioni scritte o delle valutazioni numeriche. La possibilità di testare virtualmente prodotti prima della fase di acquisto riduce l'incertezza e favorisce una valutazione più accurata delle alternative disponibili \cite{elradi2017commerce}. Inoltre, l'uso di strumenti interattivi basati su avatar e agenti virtuali contribuisce a creare un senso di presenza sociale e fiducia, elementi cruciali nei contesti di commercio online \cite{elradi2017commerce}.

L'efficacia dei configuratori 3D si estende anche alla gestione della complessità decisionale. Quando i clienti sono chiamati a configurare un prodotto selezionando tra un numero elevato di componenti e opzioni, il processo decisionale può diventare complesso e frustrante, specialmente per utenti non esperti. I configuratori avanzati integrano modelli decisionali multicriterio che supportano il cliente nell'identificare la configurazione ottimale in base alle proprie preferenze e vincoli. Ad esempio, un sistema decisionale che utilizza tecniche di programmazione lineare intera può massimizzare l'utilità del cliente soggetta a vincoli tecnici, estetici e finanziari definiti sia dall'utente sia dai progettisti \cite{frutos2004decision}. In questo modo, il configuratore non si limita a visualizzare le opzioni, ma guida attivamente l'utente verso scelte che rispondono al meglio alle sue esigenze.

\textbf{Dal lato aziendale:}

L'adozione di configuratori 3D offre vantaggi strategici e operativi significativi. In primo luogo, questi strumenti facilitano l'acquisizione di conoscenza tacita dai clienti, trasformandola in informazioni esplicite e strutturate che possono essere integrate nei database aziendali. Il processo di configurazione genera dati preziosi sulle preferenze individuali, sulle funzioni di valore assegnate agli attributi dei prodotti e sui vincoli espressi dai consumatori. Questa base di conoscenza costituisce un patrimonio informativo che l'azienda può utilizzare per orientare lo sviluppo di nuovi prodotti e per affinare le strategie di marketing \cite{frutos2004decision}.

Inoltre, i configuratori 3D contribuiscono a ridurre i costi di personalizzazione, rendendo la mass customization economicamente sostenibile. La  modularità, supportata da rappresentazioni compatte e gerarchiche delle architetture di prodotto consente alle aziende di offrire varianti in modo economicamente sostenibile. L'adozione di modelli object‑oriented e algoritmi di ottimizzazione permette di affrontare la complessità derivante dalle combinazioni, mantenendo coerenza tecnica e fattibilità produttiva \cite{frutos2004decision}.

Un altro beneficio rilevante per le aziende riguarda il miglioramento della fiducia dei consumatori. Nei contesti di e-commerce tradizionale, la costruzione della fiducia è ostacolata dalla mancanza di interazione fisica e dalla difficoltà di valutare la qualità dei prodotti. I configuratori 3D, attraverso la simulazione realistica e la visualizzazione dettagliata, aumentano la trasparenza del processo di acquisto e facilitano la formazione di fiducia cognitiva ed emotiva nei confronti del fornitore \cite{elradi2017commerce}. La presenza di avatar che fungono da consulenti virtuali e l'uso di interfacce vocali contribuiscono ulteriormente a migliorare la percezione di affidabilità e competenza dell'azienda.

Nel settore del marketing, i configuratori 3D si configurano come strumenti promozio(\-)nali altamente efficaci. La possibilità di coinvolgere i clienti in esperienze immersive e interattive aumenta il livello di engagement e rafforza l'equità del brand. La ricchezza dell'ambiente virtuale e il grado di coinvolgimento che esso genera hanno un impatto positivo sull'intenzione di acquisto e sulla fedeltà del cliente \cite{elradi2017commerce}. Le aziende possono sfruttare questi strumenti per condurre test di mercato su prototipi virtuali di nuovi prodotti, raccogliendo feedback dai consumatori in modo rapido e meno oneroso rispetto ai test su prodotti fisici.

L'applicazione dei configuratori 3D si estende anche a settori che richiedono elevata personalizzazione tecnica, come la produzione di biciclette su misura, l'arredamento personalizzato e la progettazione di componenti biomeccanici. In questi ambiti, la combinazione di modelli 3D interattivi con sistemi di supporto decisionale consente ai clienti di esprimere le proprie esigenze in termini di attributi funzionali ed estetici, lasciando al sistema il compito di tradurre tali esigenze in specifiche tecniche realizzabili. Questo approccio riduce il rischio di errori di configurazione e accelera il processo di definizione del prodotto finale.

Tuttavia, l'implementazione di configuratori 3D presenta delle tortuosità da gestire. La complessità del processo di valutazione aumenta significativamente al crescere del numero di componenti, opzioni e criteri di valutazione. Anche con l'ausilio di strumenti grafici e interattivi, l'analisi delle funzioni di valore, la definizione delle condizioni di indipendenza tra criteri e il confronto tra numerose alternative possono risultare compiti onerosi per il cliente \cite{frutos2004decision}. È quindi essenziale progettare interfacce che bilancino espressività e semplicità d'uso, guidando l'utente senza sovraccaricarlo di informazioni.

I configuratori 3D rappresentano una nuova tecnlogia avanzata in grado di rispoondere alle esigenze di personalizzazione del mercato contemporaneo. Per i clienti, essi offrono esperienze di acquisto più ricche, trasparenti e soddisfacenti, riducendo l'incertezza e facilitando scelte consapevoli. Per le aziende, costituiscono strumenti strategici per la raccolta di conoscenza, l'ottimizzazione dei processi produttivi, la riduzione dei costi di personalizzazione e il rafforzamento del legame con il cliente. La loro diffusione nei prossimi anni dipenderà dalla capacità di integrare efficacemente tecnologie di realtà virtuale, modelli decisionali avanzati e architetture di prodotto modulari, mantenendo al contempo un'interfaccia accessibile e intuitiva per utenti con diversi livelli di competenza tecnica.

%----------------------------------------------------------------------------------------
\subsection{Sfide dell'Integrazione AI-3D} \label{subsec:sfide-integrazione-ai-3d}

L'integrazione tra sistemi di Intelligenza Artificiale Conversazionale e configuratori 3D costituisce un dominio ingegneristico complesso, caratterizzato dalla necessità di far convergere l'elasticità dell'elaborazione del linguaggio naturale (NLP) con la rigidità dei vincoli spaziali e parametrici tipici della progettazione assistita. In questo scenario, il Model Context Protocol (MCP) assume il ruolo cruciale di meccanismo di orchestrazione e intermediazione, necessario per colmare il divario architetturale tra un Large Language Model (LLM) e un ambiente di simulazione altamente strutturato.

Una delle criticità primarie risiede nella traduzione affidabile dell'intento utente in comandi macchina logicamente validi. Nonostante gli LLM siano strumenti potenti per convertire il linguaggio naturale in rappresentazioni simboliche o chiamate API \cite{Raspanti2025GCD, Schick2023Toolformer, Patil2024Gorilla}, la garanzia della correttezza sintattica rimane una sfida aperta \cite{Raspanti2025GCD}. Per mitigare il rischio di output non conformi, la letteratura propone tecniche come il Grammar Constrained Decoding (GCD), che obbliga il modello a generare output aderenti a una grammatica formale predefinita, come una Context-Free Grammar \cite{Raspanti2025GCD}. Tuttavia, sebbene il GCD possa assicurare la validità formale della sintassi, non è in grado di prevenire errori semantici, come violazioni della consistenza dei predicati o riferimenti a variabili inesistenti, che impediscono l'esecuzione corretta delle istruzioni nel configuratore \cite{Raspanti2025GCD}.

Oltre alla traduzione dei comandi, emerge la complessità legata alla sincronizzazione dello stato e alla gestione dei vincoli in un ambiente distribuito. Il configuratore 3D opera come uno strumento specializzato che richiede input precisi per eseguire calcoli complessi \cite{Patil2024Gorilla}. Di conseguenza, l'MCP deve garantire che le richieste generate dall'AI rispettino rigorosamente i limiti interni del motore 3D, come la precisione numerica o i range validi dei parametri \cite{Patil2024Gorilla}. Questo richiede un netto disaccoppiamento architetturale: le attività di parsing e ragionamento sono delegate all'LLM, mentre l'esecuzione effettiva spetta al configuratore, con l'MCP che funge da orchestratore centrale del flusso di lavoro \cite{Daraghmi2022Saga, Raspanti2025GCD, Schick2023Toolformer}. Tale separazione preserva la generalità decisionale del modello linguistico, che deve apprendere autonomamente quali strumenti invocare e come popolarne gli argomenti \cite{Schick2023Toolformer}.

Tuttavia, la gestione di transazioni che coinvolgono servizi eterogenei introduce sfide significative per la coerenza dei dati. In caso di errori durante l'elaborazione, ad esempio un vincolo geometrico non soddisfatto, il sistema deve essere in grado di gestire il fallimento e avviare azioni di compensazione per annullare eventuali modifiche parziali \cite{Daraghmi2022Saga}. Per evitare anomalie dovute alla mancanza di isolamento dei dati, è preferibile posporre il commit finale sul database fino al completamento dell'intero flusso, gestendo lo stato transitorio a livello di cache in memoria \cite{Daraghmi2022Saga}. L'uso di sistemi di messaging asincrono, come Apache Kafka, risulta essenziale in questo contesto per mantenere l'ordine delle richieste e garantire la consistenza finale \cite{Daraghmi2022Saga}.

Questo livello intermedio comporta un aumento di latenza che può degradare l'esperienza realtime \cite{Schick2023Toolformer}. Per gestire scenari ad alto traffico sono necessarie strategie come l'impiego di cache in memoria (per esempio Redis), che riducono l'I/O su disco e migliorano il throughput delle operazioni CRUD \cite{Daraghmi2022Saga}. Inoltre, la multimodalità richiede che segnali testuali e visivi vengano allineati e fusi correttamente per risolvere riferimenti spaziali nella scena 3D \cite{Sundar2022Multimodal}.

Infine, l'integrazione di componenti distribuiti richiede una rigorosa gestione della sicurezza, in particolare per l'autenticazione cross-system. L'utilizzo di token JWT (JSON Web Token) è lo standard per l'accesso alle risorse, ma la natura stateless di questi strumenti rende complessa la loro revoca immediata in caso di compromissione \cite{Rujichaikul2025Token}. È dunque compito dell'MCP interagire con sistemi di monitoraggio applicativo per rilevare anomalie nei comportamenti, come il token hijacking o tentativi di generazione illecita di credenziali, garantendo l'integrità del canale di comunicazione tra l'intelligenza artificiale e il motore di configurazione \cite{Rujichaikul2025Token}.


%\paragraph{Contributo di Questa Tesi:}

%Questo lavoro affronta le sfide sopra attraverso:
%\begin{itemize}
%\item Progettazione di un'architettura dual-channel (REST + SignalR) per sincronizzazione real-time
%\item Implementazione di pattern GET-MODIFY-SAVE per operazioni atomiche complesse
%\item Definizione di tool MCP semanticamente ricchi per mapping linguaggio naturale
%\item Gestione robusta errori con partial success e messaggi user-friendly
%\item Validazione end-to-end con 10+ scenari di test
%\end{itemize}
%\paragraph{Structure of the Thesis}

\chapter{Architettura Tecnologica del Progetto}
\label{chap:stack-tecnologico}
%----------------------------------------------------------------------------------------

% OBIETTIVO DEL CAPITOLO:
% Fornire le conoscenze tecniche essenziali per comprendere le scelte architetturali
% del progetto. Focus su COSA sono le tecnologie principali, PERCHÉ sono state scelte
% e QUALI caratteristiche le rendono determinanti.
%
% APPROCCIO:
% - Spiegazioni concise e mirate (NO manuali completi)
% - Confronti con alternative (solo tabelle comparative)
% - Motivazioni tecniche chiare
% - Esempi concettuali (NO dettagli implementativi)
%
% SEPARAZIONE DELLE RESPONSABILITÀ:
% - Cap. 3 (questo): COSA/PERCHÉ - conoscenze tecnologiche (12-15 pagine)
% - Cap. 4 (Progettazione): COME architettura - design patterns, diagrammi
% - Cap. 5 (Implementazione): COME codice - classi, metodi, configurazioni
Questo capitolo descrive le tecnologie utilizzate nel progetto, spiegando per ognuna cosa fa e perché è stata scelta. L'obiettivo è fornire le conoscenze necessarie per comprendere l'architettura senza perdersi in dettagli implementativi, che saranno affrontati nei capitoli successivi dedicati alla progettazione e all'implementazione.

La struttura segue la logica dell'architettura del sistema. Si inizia con la piattaforma di backend: .NET 8 come runtime, C\# 12 come linguaggio di programmazione, ASP.NET Core per l'infrastruttura web e l'SDK MCP per comunicare con i modelli di intelligenza artificiale. Successivamente si analizzano i protocolli di comunicazione: REST per le operazioni standard, JSON-RPC per le chiamate di procedura remota e WebSocket per le connessioni persistenti. SignalR viene presentato come soluzione per gestire la comunicazione in tempo reale, nascondendo la complessità dei protocolli sottostanti e offrendo meccanismi automatici di riconnessione.

La sezione sulla sicurezza esamina come il sistema protegge le comunicazioni: i token JWT permettono l'autenticazione senza mantenere stato sul server, CORS regola l'accesso tra domini diversi e TLS cripta i dati in transito. Il capitolo si chiude con l'integrazione frontend, dove TypeScript garantisce la sicurezza dei tipi anche lato client e il client SignalR gestisce la comunicazione con il server.

Ogni tecnologia viene presentata con un approccio diretto: prima si spiega cos'è, poi perché è stata preferita alle alternative, infine quale ruolo svolge nel progetto. Le tabelle comparative facilitano il confronto tra opzioni diverse, mentre i diagrammi chiariscono i flussi di comunicazione.
\section{Panoramica dello Stack}
\label{sec:panoramica-stack}
% Contenuti da sviluppare (2 pagine):
%
% A) Visione d'insieme dello stack (0.7 pagine):
% - Organizzazione per layer funzionali:
%   * Backend Platform: .NET 8 LTS + C# 12 + ASP.NET Core
%   * Communication Layer: SignalR + WebSocket + REST + JSON-RPC 2.0
%   * Security Layer: JWT (RFC 7519) + CORS + HTTPS/WSS
%   * Frontend Integration: TypeScript 5.x + @microsoft/signalr
%
% B) Criteri di selezione tecnologica (0.6 pagine):
% - **Modernità**: stack aggiornato 2023-2024 con supporto LTS
% - **Performance**: throughput elevato per real-time (<10ms latency)
% - **Type-safety**: tipizzazione statica end-to-end (.NET ↔ TypeScript)
% - **Ecosistema**: librerie mature, documentazione completa, community attiva
% - **Interoperabilità**: compatibilità nativa con MCP Protocol (JSON-RPC)
% - **Manutenibilità**: pattern consolidati, tooling avanzato
%
% C) Coerenza con requisiti progetto (0.7 pagine):
% - Real-time: SignalR per notifiche bidirezionali low-latency
% - Scalabilità: architettura stateless con JWT authentication
% - Integrazione MCP: supporto nativo JSON-RPC e stdio transport
% - Configurator3D: SDK SignalR JavaScript per web client
%
% Tabella 3.1: Stack Technology Summary (COMPATTA)
% | Layer          | Tecnologia         | Versione | Motivazione
% |----------------|--------------------|----------|----------------------------------|
% | Runtime        | .NET               | 8 LTS    | Performance + LTS + ecosistema   |
% | Language       | C#                 | 12       | Type-safety + async/await        |
% | Web Framework  | ASP.NET Core       | 8.0      | DI + hosting SignalR             |
% | MCP Integration| MCP .NET SDK       | 0.6.0    | Type-safe tool definition        |
% | Real-Time Comm | SignalR            | 8.0      | Auto-reconnect + fallback        |
% | Authentication | JWT Bearer         | RFC 7519 | Stateless + scalable             |
% | Security       | CORS               | W3C      | Cross-origin frontend            |
% | Transport Sec  | HTTPS/WSS          | TLS 1.3  | End-to-end encryption            |
% | Frontend Lang  | TypeScript         | 5.x      | Type-safety + IntelliSense       |
% | Frontend SDK   | @microsoft/signalr | 8.x      | Browser SignalR client           |
%
% Elementi visivi:
% - Tabella 3.1: Stack summary (10 righe, 4 colonne)
%
% Pagine stimate: 2

La definizione dell'architettura software per un sistema distribuito che integri capacità di intelligenza artificiale conversazionale con ambienti di configurazione tridimensionale richiede una selezione tecnologica rigorosa. La scelta dello stack non risponde solamente a criteri di popolarità o tendenza, bensì a una precisa strategia ingegneristica con l'obiettivo di garantire robustezza, manutenibilità e prestazioni elevate. L'ecosistema tecnologico adottato per il progetto è stato strutturato secondo una logica a livelli funzionali (\emph{layered architecture}), progettata per disaccoppiare le responsabilità e facilitare l'evoluzione futura del sistema.

Il nucleo dell'infrastruttura di backend è costituito dalla piattaforma .NET 8 (LTS), supportata dal linguaggio C\# 12 e dal framework ASP.NET Core. Questa combinazione rappresenta le fondamenta del sistema, offrendo un ambiente di esecuzione gestito ma altamente performante, capace di supportare sia le logiche di business complesse del protocollo \acs{mcp} sia la gestione concorrente delle connessioni utente. Al di sopra del runtime, il livello di comunicazione agisce come sistema nervoso del progetto. Per soddisfare la necessità di interazioni bidirezionali a bassa latenza, è stato adottato SignalR, una libreria che astrae la complessità dei WebSocket, gestendo automaticamente la negoziazione del trasporto. Parallelamente, l'integrazione con gli agenti \acs{ai} e il protocollo \acs{mcp} sfrutta JSON-RPC 2.0, uno standard leggero per la chiamata di procedure remote, che convive con gli endpoint REST tradizionali utilizzati per operazioni di gestione meno frequenti.

La sicurezza attraversa trasversalmente questi livelli. L'autenticazione è viene gestita tramite lo standard JWT (JSON Web Token, RFC 7519), che permette una verifica dell'identità \emph{stateless}, essenziale per la scalabilità orizzontale. La protezione del trasporto è garantita dalla crittografia TLS (HTTPS/WSS), mentre le politiche CORS regolano l'accesso alle risorse da origini differenti, scenario tipico nelle moderne applicazioni web distribuite. Infine, l'integrazione frontend è realizzata mediante TypeScript 5.x. L'utilizzo del pacchetto \texttt{@microsoft/signalr} permette al client web di instaurare un canale diretto con il server, beneficiando della tipizzazione statica che si estende dal backend al frontend, riducendo drasticamente le possibilità di errore durante lo scambio dei messaggi.

La convergenza verso questo specifico stack tecnologico è il risultato di una valutazione basata su diversi aspetti principali come: modernità, prestazioni, sicurezza dei tipi, maturità dell'ecosistema, interoperabilità e manutenibilità. L'adozione di una versione con supporto a lungo termine come .NET 8, rilasciata tra il 2023 e il 2024, permette di ricevere aggiornamenti di sicurezza per l'intero ciclo di vita del progetto che conferiscono grande stabilità. Sul fronte delle prestazioni, il runtime di .NET ha dimostrato negli ultimi anni miglioramenti significativi nel \emph{throughput} delle richieste e nella gestione della memoria, requisiti imprescindibili per mantenere una latenza inferiore ai 10ms nelle operazioni di sincronizzazione dello stato del configuratore 3D.

Un fattore determinante è la garanzia di type‑safety end‑to‑end dove l'impiego congiunto di C\# lato server e TypeScript lato client permette di condividere definizioni di tipi Data Transfer Objects (DTO), spostando molte classi di errore dal runtime alla fase di compilazione. La maturità dell'ecosistema, librerie consolidate e documentazione esaustiva, riduce i rischi implementativi e accelera lo sviluppo tramite strumenti avanzati quali debugger, profiler, IntelliSense. L'adozione di standard aperti facilita interoperabilità e manutenibilità. La compatibilità nativa di .NET con JSON‑RPC semplifica l'implementazione del Model Context Protocol, mentre pattern consolidati come la Dependency Injection in ASP.NET Core mantengono il codice modulare e testabile.

L'architettura delineata risponde puntualmente alle specifiche funzionali e non funzionali del sistema. Il requisito di interattività in tempo reale per il configuratore 3D trova in SignalR la soluzione ideale: la capacità di inviare notifiche \emph{push} dal server al client permette di aggiornare la scena tridimensionale istantaneamente in risposta alle elaborazioni dell'\acs{ai}, senza costringere il client a costosi meccanismi di polling. Per quanto concerne la scalabilità, l'approccio \emph{stateless} garantito dai token JWT consente al sistema di crescere orizzontalmente senza la necessità di sincronizzare le sessioni utente tra nodi diversi. Inoltre, l'integrazione del \emph{Model Context Protocol} è supportata nativamente dalle capacità di serializzazione JSON e dalla gestione dei trasporti, sia HTTP che stdio, offerte dal framework, semplificando la creazione di strumenti personalizzati per i modelli linguistici.

La tabella \ref{tab:tech-stack-summary} riassume le tecnologie selezionate per ogni livello logico, evidenziando le motivazioni specifiche che ne hanno determinato l'adozione nel contesto di questa tesi.

\begin{table}[ht]
\centering
\caption{Sintesi dello Stack Tecnologico e motivazioni di adozione.}
\label{tab:tech-stack-summary}
\footnotesize
\begin{tabular}{@{}p{2.5cm}p{3cm}p{1.5cm}p{6cm}@{}}
\toprule
\textbf{Layer} & \textbf{Tecnologia} & \textbf{Versione} & \textbf{Motivazione Principale} \\ \midrule
Runtime & .NET & 8 LTS & Performance elevate, stabilità LTS ed ecosistema maturo \\
Linguaggio & C\# & 12 & Type-safety robusta e costrutti asincroni moderni \\
Framework Web & ASP.NET Core & 8.0 & Hosting SignalR integrato e Dependency Injection nativa \\
Integrazione MCP & MCP .NET SDK & 0.6.0 & Definizione tipizzata dei tool per l'AI \\
Real-Time Comm. & SignalR & 8.0 & Gestione automatica riconnessioni e fallback dei trasporti \\
Autenticazione & JWT Bearer & RFC 7519 & Architettura stateless e scalabile per sistemi distribuiti \\
Sicurezza & CORS & W3C & Abilitazione sicura delle richieste cross-origin dal frontend \\
Sicurezza Trasp. & HTTPS/WSS & TLS 1.3 & Cifratura end-to-end del canale di comunicazione \\
Linguaggio Front. & TypeScript & 5.x & Coerenza dei tipi con il backend e supporto IntelliSense \\
SDK Frontend & @microsoft/signalr & 8.x & Client leggero per la gestione eventi real-time nel browser \\ \bottomrule
\end{tabular}
\end{table}

\section{Piattaforma Backend .NET}
\label{sec:backend-net}


% FOCUS: Panoramica essenziale .NET 8, C# 12, ASP.NET Core, MCP SDK
% Approccio: COMPATTO, spiegare COSA/PERCHÉ, NO dettagli implementativi

\subsection{.NET 8 e C\# 12: Piattaforma e Linguaggio}
\label{subsec:dotnet-csharp}
%----------------------------------------------------------------------------------------

% Contenuti da sviluppare (1.5 pagine):
%
% A) .NET 8: Piattaforma (0.5 pagine):
% - Piattaforma unified open-source cross-platform (Windows/Linux/macOS)
% - Evoluzione: .NET Framework (Windows-only) → .NET Core → .NET 5+ unified
% - .NET 8 LTS (novembre 2023): supporto 3 anni (fino novembre 2026)
% - Componenti essenziali:
%   * CoreCLR: runtime con JIT compilation e Garbage Collector
%   * Librerie base: System.*, Collections, IO, Networking
%   * ASP.NET Core: framework web per API e SignalR
%   * NuGet: package manager
%
% B) C# 12: Linguaggio (0.4 pagine):
% - Linguaggio object-oriented type-safe, rilasciato con .NET 8
% - Paradigmi: OOP, functional (LINQ), async/await nativo
% - Feature rilevanti progetto:
%   * **Async/await**: gestione I/O asincrono (HTTP, SignalR non-blocking)
%   * **LINQ**: query in-memory eleganti
%   * **Pattern matching**: switch expressions per routing
%   * **Nullable reference types**: null-safety compile-time
%   * **Records**: DTOs immutabili per request/response
%
% C) PERCHÉ .NET 8 + C# 12 (0.6 pagine):
%
% Tabella 3.2: .NET vs Alternative Backend
% | Aspetto     | .NET 8   | Python   | Node.js | Java    |
% |-------------|----------|----------|---------|---------|
% | Performance | ★★★★★    | ★★☆☆☆    | ★★★☆☆   | ★★★★☆   |
% | Async Model | async/await | asyncio | async  | CompletableFuture |
% | Type Safety | Compiled | Optional | No      | Compiled|
% | MCP SDK     | ✅ Ufficiale| ✅    | ✅      | ❌      |
%
% Motivazioni scelta:
% - **Performance**: throughput elevato per real-time
% - **Async/await ergonomico**: sintassi pulita vs callback hell
% - **Type-safety**: compile-time errors
% - **MCP SDK availability**: package NuGet ufficiale
% - **Cross-platform**: deploy Docker Linux
%
% Elementi visivi:
% - Tabella 3.2: Comparison matrix (4×4)
%
% Pagine stimate: 1.5
L'adozione della piattaforma .NET 8 si colloca all'interno di un ecosistema software maturo, unificato e altamente ottimizzato \cite{Cvijić2024NET8}. Dopo aver superato la storica separazione tra il framework proprietario orientato a Windows e le prime versioni modulari di \textit{.NET Core}, Microsoft ha avviato con .NET 5 un percorso di convergenza architetturale, giunto a compimento nel novembre 2023 con il rilascio della versione 8, dotata di supporto a lungo termine (LTS) \cite{Toub2023Performance, Cvijić2024NET8}. Questa evoluzione ha trasformato .NET in una soluzione interamente \textit{open-source} e \textit{cross-platform}, progettata nativamente per operare con la medesima efficacia su ambienti Windows, Linux e macOS.

 La forte efficienza di questo stack tecnologico risiede nei componenti avanzati come il CoreCLR e il \textit{Garbage Collector} (GC). Il runtime implementa strategie di compilazione sofisticate. il compilatore Just-In-Time (JIT) sfrutta la \textit{Dynamic Profile-Guided Optimization} (PGO) e la \textit{Tiered Compilation} per adattare l'esecuzione del codice in base ai dati raccolti in tempo reale, minimizzando l'overhead e massimizzando il throughput \cite{Toub2023Performance}. Parallelamente, il GC è stato oggetto di continue ottimizzazioni mirate alla riduzione dei tempi di pausa, fattore determinante per sostenere carichi di lavoro ad alta concorrenza tipici delle moderne applicazioni web basate su ASP.NET Core \cite{Toub2023Performance}.

Inoltre, il linguaggio C\# 12 offre un'interfaccia espressiva, orientata agli oggetti e rigorosamente \textit{type-safe} \cite{Microsoft2024C12} stabilendo una stretta sinergia con il runtime. Le innovazioni introdotte in questa versione mirano a unire la sinteticità del codice con la sicurezza e le prestazioni. L'estensione dei Primary Constructors a classi e struct, unitamente alle Collection Expressions, permette di ridurre drasticamente il codice \textit{boilerplate} necessario per la definizione di tipi e l'inizializzazione delle strutture dati \cite{Microsoft2024C12}. Sul fronte dell'ottimizzazione, l'introduzione degli Inline Arrays e dei parametri \texttt{ref readonly} consente agli sviluppatori di gestire buffer a dimensione fissa e passaggi di riferimento in sola lettura con efficienza paragonabile a contesti \textit{unsafe}, ma mantenendo le garanzie di sicurezza della memoria gestita \cite{Toub2023Performance, Microsoft2024C12}.

La scelta di combinare .NET 8 e C\# 12 risponde a precisi requisiti di scalabilità e manutenibilità. Il supporto nativo al paradigma asincrono, tramite i costrutti \texttt{async/await}, e l'integrazione di LINQ (\textit{Language Integrated Query}) offrono un modello ergonomico per la gestione dell'I/O non bloccante e delle interrogazioni in-memory, evitando complessità sintattiche e favorendo la pulizia del codice \cite{Microsoft2024C12}.

Sotto il profilo prestazionale, i benchmark evidenziano miglioramenti significativi nelle operazioni \textit{compute-intensive}, come l'hashing crittografico, e una riduzione delle allocazioni di memoria nei percorsi critici \cite{Toub2023Performance}. Tale efficienza, unita alla robustezza del sistema di tipi che previene intere classi di errori a tempo di compilazione \cite{Microsoft2024C12}, rende la piattaforma superiore rispetto ad alternative interpretate per scenari real-time. Infine, la maturità dell'ecosistema, supportata dal gestore di pacchetti NuGet e dalla piena compatibilità con la containerizzazione Docker, garantisce un ciclo di sviluppo e rilascio affidabile, essenziale per l'integrazione di librerie complesse come gli SDK per protocolli distribuiti \cite{Cvijić2024NET8}.

\subsection{ASP.NET Core: Infrastructure Framework}
\label{subsec:aspnet-core}

ASP.NET Core rappresenta l'evoluzione open-source, multipiattaforma e ad alte prestazioni del framework web di Microsoft, progettato per rispondere alle esigenze di scalabilità delle moderne architetture cloud-native \cite{aspnetcore_overview, rao_jain_tyagi_enhancing}. Distaccandosi radicalmente dal precedente ASP.NET, questa versione propone una riprogettazione strutturale con lo scopo di fornire una piattaforma unificata e leggera \cite{kronis_uhanaova_performance}, in grado di sostenere lo sviluppo di sistemi distribuiti complessi e di gestire carichi di lavoro enterprise con efficienza elevata \cite{aspnetcore_overview, jakkula_gollapudi_jaiswal_microservices}.

L'architettura del framework è intrinsecamente modulare, caratteristica che consente di ridurre l'overhead operativo includendo nel processo solo i componenti strettamente necessari \cite{rao_jain_tyagi_enhancing}. Elemento centrale di questo design è la pipeline di gestione delle richieste HTTP, realizzata tramite middleware configurabili che intercettano e processano il traffico per implementare logiche trasversali come il logging e l'autenticazione \cite{aspnetcore_overview, jakkula_gollapudi_jaiswal_microservices}. A livello di hosting, il sistema si avvale di Kestrel, un server web leggero e ottimizzato per l'esecuzione cross-platform, che supera la dipendenza storica da IIS garantendo prestazioni elevate anche in ambienti non Windows \cite{aspnetcore_overview, kronis_uhanaova_performance}. La robustezza dell'infrastruttura è ulteriormente assicurata dal supporto nativo per la dependency injection (DI), un pattern essenziale per favorire il disaccoppiamento dei componenti, la testabilità del codice e la manutenibilità a lungo termine \cite{aspnetcore_overview, rao_jain_tyagi_enhancing}.

ASP.NET Core si distingue perché il suo runtime è più leggero e richiede meno memoria, caratteristiche che lo rendono molto veloce nell'elaborare le richieste secondo diversi benchmark del settore \cite{rao_jain_tyagi_enhancing, kronis_uhanaova_performance}. Anche se componenti relativamente nuovi come il server Kestrel possono necessitare di tempo per essere pienamente consolidati, l'affidabilità dell'intero framework è dimostrata dall'uso su larga scala in servizi critici come Bing, Xbox e Azure \cite{aspnetcore_overview, kronis_uhanaova_performance}. Per questi motivi, ASP.NET Core è una scelta appropriata quando si progettano applicazioni che devono garantire sia buone prestazioni sia stabilità operativa \cite{aspnetcore_overview, rao_jain_tyagi_enhancing}.

Nel progetto ASP.NET Core è usato principalmente come infrastruttura interna, non come host principale delle API REST. Il framework viene impiegato per orchestrare i servizi interni tramite il contenitore per la dependency injection e per gestire funzionalità trasversali importanti come la configurazione basata sull’ambiente, il tracciamento (tracing) e il logging strutturato delle metriche di runtime \cite{aspnetcore_overview, rao_jain_tyagi_enhancing}. Inoltre, il server Kestrel è efficiente e viene usato per ospitare il componente SignalR di SignalrHub, permettendo comunicazioni real-time fluide e reattive, utili per l’interattività dell’applicazione \cite{aspnetcore_overview}.

% Contenuti da sviluppare (1 pagina):
%
% A) COSA è ASP.NET Core (0.4 pagine):
% - Framework web moderno cross-platform per .NET
% - Componenti: Kestrel web server, middleware pipeline, DI container, configuration, logging
%
% B) PERCHÉ ASP.NET Core (0.3 pagine):
% - **Performance**: Kestrel high-throughput (benchmark TechEmpower top 10)
% - **DI nativo**: IoC container built-in
% - **Middleware pipeline**: estensibilità
%
% C) Ruolo nel progetto (0.3 pagine):
% - NON usato per hosting HTTP REST API (MarkunoAPI è esterno)
% - Utilizzo SOLO per infrastruttura:
%   * Dependency Injection: registrazione servizi
%   * Configuration: caricamento appsettings.json
%   * Logging: ILogger structured logging
%   * SignalR hosting: Kestrel espone IwineHub
%
% Pagine stimate: 1
\subsection{MCP SDK: Astrazione Tool Definition}
\label{subsec:mcp-sdk}
%----------------------------------------------------------------------------------------

% Contenuti da sviluppare (1 pagina - RIDOTTA da 2.5):
%
% A) COSA è MCP SDK (0.4 pagine):
% - Package NuGet: ModelContextProtocol (versione 0.6.0)
% - Framework per implementazione server MCP in .NET
% - Componenti: McpServer base class, [McpTool] attributes, JSON-RPC handler, stdio transport
%
% B) PERCHÉ MCP SDK (0.6 pagine):
%
% Confronto: Manuale vs SDK
%
% **Implementazione manuale JSON-RPC**:
% - Parsing, validazione, routing, serializzazione, error handling manuale
% - Stima: ~500 linee codice boilerplate per 10 tool
%
% **Con MCP SDK**:
% - Tutto automatico: parsing, validazione, routing, serializzazione, errors
% - Stima: ~10 linee per tool (solo business logic)
%
% Vantaggi SDK:
% - **Boilerplate reduction**: ~95% meno codice
% - **Type-safety**: parametri validati compile-time
% - **Developer experience**: IntelliSense, debugging
%
% Elementi visivi:
% - Diagramma 3.3: MCP SDK workflow (AI → JSON-RPC → SDK → method)
%
% Pagine stimate: 1
Il Model Context Protocol (MCP) si configura come uno standard aperto e ampiamente adottato, progettato per razionalizzare l'architettura dei sistemi basati su intelligenza artificiale generativa e facilitare l'integrazione tra i diversi componenti software. La sua funzione primaria è quella di definire uno schema rigoroso per strutturare le interazioni tra client e server, standardizzando le chiamate API verso i Large Language Models (LLM), le sorgenti dati e gli strumenti agentici, riducendo così significativamente i costi e la complessità dello sviluppo \cite{Radosevich2025MCPSafetyAudit, mcp_survey_kent}.

Per permettere l'uso del protocollo in diversi ambienti di sviluppo, sono stati rilasciati SDK open-source per i principali linguaggi di programmazione, tra cui Python, Java, TypeScript e Kotlin \cite{Radosevich2025MCPSafetyAudit}. Nel contesto specifico di questo progetto, sviluppato in ambiente Microsoft, la componente tecnologica centrale è rappresentata dall'SDK ufficiale C\# per MCP, mantenuto in stretta collaborazione con Microsoft \cite{ModelContextProtocol2025CSDK}. Questo strumento, distribuito tramite il pacchetto NuGet \textbf{\texttt{ModelContextProtocol}}, funge da framework per l'implementazione di server MCP all'interno di applicazioni e librerie .NET, offrendo le estensioni necessarie per l'hosting e l'injection delle dipendenze \cite{ModelContextProtocol2025CSDK}. La libreria è ideale per progetti che non hanno bisogno di un server HTTP completo. Si basa sulla classe \textbf{\texttt{McpServer}}, configurabile sia in modo esplicito che usando i pattern standard di .NET \cite{ModelContextProtocol2025CSDK}.

Sebbene la comunicazione sottostante sia gesttita semanticamente dallo standard \textbf{JSON-RPC 2.0} \cite{mcp_survey_kent, Ahmadi2025MCPBridge}, l'SDK opera una completa astrazione di tale complessità, privilegiando lo \textbf{\texttt{stdio}} (Standard Input/Output) come canale di trasporto primario \cite{Ahmadi2025MCPBridge, mcp_survey_kent, ModelContextProtocol2025CSDK}.Le funzionalità del server vengon esposte tramite un paradigma dichiarativo basato su attributi. Le classi contenenti la logica dei tool vengono marcate con \texttt{[McpServerToolType]}, mentre i singoli metodi che l'LLM dovrà invocare sono decorati con \textbf{\texttt{[McpServerTool]}} \cite{ModelContextProtocol2025CSDK}. Per garantire che il modello comprenda correttamente la semantica degli strumenti, è essenziale fornire metadati descrittivi sia ai metodi che ai parametri tramite l'attributo \texttt{[Description]} del namespace \texttt{System.ComponentModel} \cite{ModelContextProtocol2025CSDK}.

L'adozione di questo SDK è giustificata da un'analisi comparativa rispetto all'implementazione manuale del protocollo, dalla quale emerge un netto miglioramento nella \textit{developer experience} e nella sicurezza del codice. Gestire manualmente il protocollo JSON-RPC imporrebbe allo sviluppatore l'obbligo di implementare parser complessi, validare gli schemi di input, gestire il routing delle chiamate e serializzare le risposte, oltre a dover sollevare eccezioni specifiche come \texttt{McpErrorCode.InvalidParams} in caso di errori \cite{ModelContextProtocol2025CSDK}. Al contrario, l'approccio gestito dall'SDK automatizza interamente il parsing e la validazione rispetto ai tipi forti di C\#, eliminando la necessità di manipolare oggetti non tipizzati e riducendo drasticamente il codice \textit{boilerplate} necessario \cite{ModelContextProtocol2025CSDK}. Procedendo in questo modo si garantisce ub \textit{type-safety} superiore e permettendo allo sviluppatore di concentrarsi sullo sviluppo sulla logica di business piuttosto che sull'infrastruttura di comunicazione.

Nel flusso di lavoro del progetto, l'SDK agisce come giuntura tra la logica applicativa C\# e le capacità decisionali dell'agente AI. Il processo segue uno schema rigido dove a seguito dell'input utente, l'LLM elabora una richiesta strutturata che viene trasmessa via JSON-RPC \cite{Wang2025MCPBench, mcp_survey_kent}. Il server intercetta tale richiesta, trasforma il payload negli argomenti tipizzati e invoca il metodo C\# corrispondente \cite{ModelContextProtocol2025CSDK, Wang2025MCPBench}. È rilevante notare che l'architettura supporta anche flussi bidirezionali o ricorsivi: l'istanza di \texttt{McpServer} può essere utilizzata per richiamare il client (il contesto LLM) per operazioni di \textit{sampling}, come dimostrato da funzioni che necessitano di generare sintesi di contenuti scaricati interagendo nuovamente con il modello \cite{ModelContextProtocol2025CSDK}.

\section{Architettura della Comunicazione}
\label{sec:comunicazione}
%----------------------------------------------------------------------------------------

% FOCUS: Protocolli comunicazione client-server
% Approccio: COMPATTO per protocolli base, DETTAGLIATO per SignalR

\subsection{Protocolli di Base: REST, JSON-RPC, WebSocket}
\label{subsec:protocolli-base}

% Contenuti da sviluppare (1.5 pagine - UNISCE 3 protocolli):
%
% A) REST API (0.5 pagine):
% - COSA: Architectural style HTTP-based, stateless, resource-based
% - Principi: HTTP verbs (GET/POST/PUT/DELETE), URI risorse, JSON representations
% - PERCHÉ: standard universale, caching, idempotenza
% - Ruolo progetto: MarkunoAPI endpoints (POST /muconf/plist, /pcreate, /radd)
% - Limitazione: request-response only, no server push → serve SignalR
%
% B) JSON-RPC 2.0 (0.5 pagine):
% - COSA: Protocollo RPC lightweight, spec 2.0 del 2010
% - Struttura: { jsonrpc, method, params, id } / { jsonrpc, result, id }
% - PERCHÉ: semplicità (spec 10 pag vs SOAP 1000+), bidirezionale, stateless
% - Ruolo progetto: MCP Protocol usa JSON-RPC per AI ↔ MCP Server
%   * Methods: initialize, tools/list, tools/call
%   * MCP SDK gestisce parsing/serializzazione automaticamente
%
% C) WebSocket Protocol (0.5 pagine):
% - COSA: RFC 6455, protocollo full-duplex su TCP, handshake HTTP upgrade
% - Caratteristiche: bidirezionale, persistent, low-overhead (2-14 byte header), low-latency (<10ms)
% - PERCHÉ: vs HTTP polling (latency 1-5sec, overhead alto, server load)
%
% Tabella 3.3: Polling vs WebSocket (COMPATTA)
% | Aspetto     | Short Polling | WebSocket  |
% |-------------|---------------|------------|
% | Latency     | 1-5 sec       | <10 ms     |
% | Overhead    | Alto          | Minimo     |
% | Server Load | Alto          | Basso      |
% | Scalabilità | Bassa         | Alta       |
%
% - Limitazioni WebSocket: no fallback automatico, riconnessione manuale, no typed messages
% - → SignalR risolve queste limitazioni (vedi 3.3.2)
%
% Elementi visivi:
% - Tabella 3.3: Polling vs WebSocket (4×2)
%
% Pagine stimate: 1.5
L'architettura del sistema si fonda su tre standard di comunicazione distinti ma complementari: REST, JSON-RPC 2.0 e WebSocket. Ognuno di questi protocolli risponde a specifiche esigenze architetturali, dalla gestione delle risorse \emph{stateless} alla chiamata di procedure remote, fino alla comunicazione in tempo reale e la loro cooperazione integrata risulta fondamentale per il corretto funzionamento dell’intera piattaforma.
\subsubsection{REST: Lo Standard per le Risorse Web}

Il \textbf{REpresentational State Transfer (REST)} costituisce lo stile architetturale di riferimento per l'esposizione di interfacce web scalabili e interoperabili \cite{yasmin_first_2008}. Definito originariamente da Roy Fielding nel 2000, non si configura come una semplice raccolta di pattern, bensì come un insieme organico di vincoli progettuali mirati a ottimizzare scalabilità, efficienza e affidabilità dei sistemi distribuiti \cite{bogner_restruler_2024}.

L’architettura si fonda sul protocollo HTTP e sul paradigma di comunicazione stateless: ogni richiesta ha con se i dati indispensabili alla sua elaborazione, liberando il server dal compito di gestire uno stato persistente per il client \cite{bogner_restruler_2024}. Tale approccio orientato alle risorse identifica ogni entità tramite un URI (\emph{Uniform Resource Identifier}) univoco e ne permette la manipolazione attraverso rappresentazioni standardizzate, tipicamente in formato JSON \cite{yasmin_first_2008, bogner_restruler_2024}.

Un punto importante del modello REST è l’uso dei verbi HTTP con un significato preciso: \textbf{GET} serve per leggere in modo sicuro e ripetibile le informazioni, \textbf{POST} per aggiungere nuove risorse, e \textbf{DELETE} per cancellarle. Usare correttamente questi verbi è fondamentale per garantire che l’interfaccia funzioni nel modo giusto \cite{bogner_restruler_2024}. La diffusione capillare di questo standard, cresciuta esponenzialmente nell'ultimo decennio, è sostenuta anche dalla gestione efficiente del \emph{caching}, che riduce il carico computazionale evitando la rigenerazione di risposte identiche \cite{yasmin_first_2008}.

Nel contesto progettuale, il servizio API esterno adotta questo paradigma per esporre endpoint transazionali quali \texttt{POST /muconf/plist} o \texttt{/pcreate}. Tuttavia, il modello REST presenta un limite strutturale intrinseco: essendo basato su un ciclo \emph{request-response} sincrono, non supporta nativamente il \emph{server push}, risultando inadeguato per scenari che richiedono aggiornamenti bidirezionali in tempo reale, come le notifiche istantanee \cite{mongoose_json-rpc_ws}.

\subsubsection{JSON-RPC 2.0: Semplicità nella Chiamata Remota}

Per la gestione delle interazioni procedurali complesse, il sistema adotta \textbf{JSON-RPC 2.0}, un protocollo \emph{stateless} e leggero specificato nel 2010 per l'invocazione di metodi remoti (RPC) \cite{json-rpc_spec}.A differenza di protocolli più complessi come SOAP, JSON-RPC utilizza la sintassi leggera di JSON per definire lo scambio di messaggi, indipendentemente dal livello di trasporto usato (HTTP, socket o stdio) \cite{json-rpc_spec}.

La struttura del protocollo è rigorosa ma minimale. Una richiesta valida deve includere la versione del protocollo (\texttt{"jsonrpc": "2.0"}), il nome del metodo (\texttt{method}), gli eventuali parametri (\texttt{params}) e un identificativo (\texttt{id}) necessario per collegare la risposta \cite{json-rpc_spec}. L'omissione dell'identificativo trasforma la chiamata in una \emph{Notification}, per la quale il server non è tenuto a inviare alcuna risposta, ottimizzando il traffico di rete \cite{json-rpc_spec, mongoose_json-rpc_ws}. Le risposte, a loro volta, devono restituire un risultato (\texttt{result}) o un oggetto di errore strutturato (\texttt{error}) contenente codice e messaggio descrittivo \cite{json-rpc_spec}.

La scelta di JSON-RPC 2.0 è motivata dalla sua capacità di supportare comunicazioni bidirezionali asincrone mantenendo una semplicità implementativa estrema \cite{mongoose_json-rpc_ws}. Nel progetto, esso costituisce la spina dorsale del \emph{Model Context Protocol} (MCP), veicolando comandi critici come \texttt{initialize} o \texttt{tools/call}. L'utilizzo di un SDK dedicato permette di astrarre interamente le operazioni di \emph{parsing} e serializzazione, garantendo la conformità alla specifica senza dispensiosi compiti per lo sviluppatore \cite{mongoose_json-rpc_ws}.

\subsubsection{WebSocket: Canale Full-Duplex Real-Time}

Mentre REST e JSON-RPC gestiscono efficacemente le interazioni basate su richiesta, l'architettura necessita di un canale dedicato per la trasmissione di eventi asincroni a bassa latenza. A tale scopo viene adottato il protocollo \textbf{WebSocket}, che permette di instaurare un tunnel di comunicazione \textbf{full-duplex} persistente su una singola connessione TCP, superando i limiti strutturali del modello HTTP tradizionale \cite{mongoose_json-rpc_ws}.

L'impiego di WebSocket è giustificato dalla necessità di eliminare l'inefficienza delle tecniche di \textit{polling}. Mantenendo il canale aperto, il server può trasmettere dati al client istantaneamente (approccio \textit{push}) senza l'overhead di negoziare una nuova connessione per ogni messaggio. Come evidenziato nella Tabella \ref{tab:polling-vs-websocket}, questo approccio riduce drasticamente la latenza e il consumo di banda rispetto alle alternative basate su interrogazione periodica.

\begin{table}[ht]
\centering
\caption{Confronto prestazionale: HTTP Polling vs WebSocket.}
\label{tab:polling-vs-websocket}
\small
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Metrica} & \textbf{Short Polling} & \textbf{WebSocket} \\
\midrule
Latenza & Alta (1-5 sec) & Bassissima ($<$10 ms) \\
Overhead & Alto (Header HTTP completi) & Minimo (Frame leggeri) \\
Carico Server & Elevato (Connessioni multiple) & Basso (Connessione persistente) \\
Scalabilità & Limitata & Elevata \\
\bottomrule
\end{tabular}
\end{table}

Tuttavia, la gestione "grezza" di un socket persistente introduce complessità infrastrutturali, quali la gestione delle disconnessioni impreviste e l'attraversamento di proxy restrittivi. Per tale motivo, nel progetto l'utilizzo di WebSocket non avviene in forma diretta, ma è mediato dalla libreria \textbf{SignalR}, che astrae queste complessità garantendo meccanismi di \textit{fallback} e riconnessione automatica, come verrà dettagliato nel capitolo dedicato alle tecnologie \textit{real-time}.
% Contenuti da sviluppare (3 pagine):
%
% A) COSA è SignalR (0.8 pagine):
% - Libreria ASP.NET Core per comunicazione real-time client-server
% - Astrazione high-level su WebSocket con fallback automatico
% - Componenti principali:
%   * **Transport layer**: WebSocket (preferito) → Server-Sent Events → Long Polling (fallback)
%   * **Hub pattern**: Clients.All.Method() (broadcast), Clients.Client(id).Method() (unicast)
%   * **Strongly-typed hubs**: interfaccia IClient, compile-time safety
%   * **Auto-reconnection**: retry con backoff [0, 2, 5, 10] secondi
%   * **Lifecycle events**: OnConnectedAsync, OnDisconnectedAsync
%
% B) PERCHÉ SignalR (0.8 pagine):
%
% Tabella 3.4: WebSocket vs SignalR (COMPATTA)
% | Aspetto         | WebSocket Raw       | SignalR                 |
% |-----------------|---------------------|-------------------------|
% | Fallback        | Manuale             | Automatico (SSE → LP)   |
% | Riconnessione   | Custom              | Automatica backoff      |
% | Typed messages  | Serializzazione man | Strongly-typed methods  |
% | Broadcasting    | Loop manuale        | Clients.All.Method()    |
% | Complessità     | 300-500 lines       | 20-30 lines             |
%
% Vantaggi SignalR:
% - **Produttività**: 90% meno codice boilerplate
% - **Affidabilità**: auto-reconnect, fallback transport
% - **Developer experience**: type-safety, IntelliSense
%
% C) Ruolo nel progetto (1 pagina):
%
% **IwineHub**: SignalR Hub esterno pre-esistente
% - Bridging MCP Server ↔ Configurator3D
% - Funzionalità: routing messaggi (SendMessage), broadcasting, ConnectionId exchange
% - Hosting: Kestrel porta 7193, JWT authentication, CORS configurato
%
% **SignalR Client .NET**: usato da MCP Server
% - Package: Microsoft.AspNetCore.SignalR.Client
% - API: StartAsync(), On<T>(event, handler), InvokeAsync(method, args)
% - Auto-reconnect: [0, 2, 5, 10] secondi backoff
%
% **SignalR Client Browser**: usato da Configurator3D
% - Package npm: @microsoft/signalr v8.x
% - Handlers: on("open", ...), on("create", ...) per comandi MCP
% - ACK pattern: invoke("SendAck", commandId) conferma elaborazione
%
% **Dual-Channel Pattern**: REST + SignalR complementari
% - REST: operazioni CRUD pesanti
% - SignalR: notifiche real-time leggere
% - Vantaggi: separation of concerns, resilienza
%
% D) Caratteristiche determinanti (0.4 pagine):
% - **Bidirezionalità real-time**: latency <10ms vs polling 1-5 sec
% - **Affidabilità**: auto-reconnect per sessioni lunghe
% - **Fallback transport**: 100% compatibility in ambienti restrittivi
% - **Ecosystem maturity**: Microsoft production-ready, LTS support
%
% Elementi visivi:
% - Tabella 3.4: WebSocket vs SignalR (5×3)
% - Diagramma 3.4: Dual-Channel pattern (MCP → REST + SignalR → Configurator)
%
% Pagine stimate: 3
\subsection{SignalR: Framework Real-Time}
\label{subsec:signalr-framework}

L'evoluzione dei sistemi distribuiti verso architetture reattive impone l'adozione di strumenti capaci di garantire una comunicazione a bassa latenza e alta affidabilità. Per rispondere a tale esigenza, l'architettura del progetto integra \textbf{SignalR}, una libreria open-source dell'ecosistema ASP.NET Core progettata per astrarre la complessità della comunicazione bidirezionale tra server e client \cite{integrating_signalr_dotnet}. Il framework non segue il tradizionale modello \emph{request-response} di HTTP, abilitando un meccanismo di \emph{server push} che permette l'aggiornamento istantaneo delle interfacce client senza ricorrere a tecniche inefficienti di polling \cite{Medavarapu2022, microsoft_signalr_docs}.

\bigskip
\noindent \textbf{Architettura e Astrazione del Trasporto.}
SignalR opera come un livello di astrazione ad alto livello costruito sopra i protocolli di trasporto sottostanti. Il componente fondamentale è il \textbf{Transport Layer}, che gestisce la negoziazione della connessione implementando una logica di \emph{fallback} automatico \cite{Comparison2024}. Il framework tenta inizialmente di stabilire una connessione via \textbf{WebSocket}, considerato il trasporto preferenziale per le sue caratteristiche \emph{full-duplex}.

Qualora l'ambiente di rete (proxy, firewall) o le capacità del client non lo supportino, SignalR degrada in modo trasparente verso \textbf{Server-Sent Events (SSE)} e, in ultima istanza, verso il \textbf{Long Polling} \cite{integrating_signalr_dotnet, microsoft_signalr_docs}.
Il modello di programmazione si basa sul \textbf{Hub Pattern}, che funge da pipeline centrale per lo scambio di messaggi. Gli Hub permettono di invocare metodi sul client come se fossero locali, supportando diverse topologie di distribuzione: dal \emph{broadcasting} globale (tramite \texttt{Clients.All}) all'indirizzamento \emph{unicast} verso connessioni specifiche (\texttt{Clients.Client(id)}) \cite{Comparison2024, integrating_signalr_dotnet}. Per garantire la robustezza del codice, l'architettura sfrutta \textbf{Strongly-typed Hubs} basati sull'interfaccia generica \texttt{Hub<T>}, che assicurano la verifica dei tipi a tempo di compilazione (\emph{compile-time safety}), prevenendo errori di invocazione comuni nei sistemi basati su stringhe magiche \cite{integrating_signalr_dotnet}.
Un aspetto critico per la resilienza del sistema è la gestione del ciclo di vita della connessione. SignalR espone hook di eventi quali \texttt{OnConnectedAsync} e \texttt{OnDisconnectedAsync} per la gestione delle risorse e implementa una politica di \textbf{riconnessione automatica} configurabile. Nel progetto, è stata adottata una strategia di \emph{retry} con backoff incrementale a 0, 2, 5 e 10 secondi, permettendo il recupero trasparente della sessione in caso di instabilità transitoria della rete \cite{Comparison2024}.

\bigskip
\noindent \textbf{Vantaggi Operativi e Produttività.}
La scelta di adottare SignalR in luogo di un'implementazione diretta di WebSocket (\emph{raw WebSocket}) è giustificata da un'analisi costi-benefici legata alla produttività e alla manutenibilità. Mentre WebSocket fornisce un canale di comunicazione grezzo, il suo utilizzo diretto imporrebbe agli sviluppatori di re-implementare funzionalità infrastrutturali complesse. SignalR riduce drasticamente il codice \emph{boilerplate} necessario, stimato in una riduzione del 90\%, gestendo internamente la serializzazione dei messaggi, il routing e la gestione degli errori \cite{integrating_signalr_dotnet}.
La Tabella \ref{tab:websocket-vs-signalr} evidenzia le differenze strutturali tra le due tecnologie, sottolineando come SignalR risolva nativamente le criticità legate alla gestione manuale del protocollo.

\begin{table}[ht]
\centering
\caption{Confronto tecnico: WebSocket Raw vs SignalR.}
\label{tab:websocket-vs-signalr}
\small
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Aspetto} & \textbf{WebSocket Raw} & \textbf{SignalR} \\ \midrule
Fallback & Manuale & Automatico (SSE $\to$ LP) \\
Riconnessione & Custom (logica complessa) & Automatica con backoff \\
Messaggistica & Serializzazione manuale & Metodi Strongly-typed \\
Broadcasting & Loop manuale sulle socket & \texttt{Clients.All.Method()} \\
Complessità & Elevata (300-500 righe) & Minima (20-30 righe) \\ \bottomrule
\end{tabular}
\end{table}

Oltre all'efficienza del codice, l'adozione del framework migliora significativamente la \emph{Developer Experience} (DX) grazie all'integrazione con IntelliSense e alla sicurezza dei tipi offerta dall'ecosistema .NET, riducendo la superficie di errore durante lo sviluppo di funzionalità real-time \cite{Comparison2024}.

\bigskip
\noindent \textbf{Ruolo nell'Architettura di Progetto: SignalRHub .}
Nell'architettura del progetto di tesi, SignalR non è un semplice accessorio ma costituisce la colonna portante per l'interattività. Il componente centrale è identificato come \textbf{SignalRHub}, un Hub esterno preesistente ospitato sul server Kestrel (porta 7193), configurato con autenticazione JWT e policy CORS permissive per accettare connessioni dai client distribuiti \cite{integrating_signalr_dotnet}.

Il sistema implementa un \textbf{Dual-Channel Pattern}, separando logicamente le responsabilità di comunicazione:
\begin{enumerate}
    \item \textbf{Canale REST:} Utilizzato per operazioni CRUD pesanti e transazionali.
    \item \textbf{Canale SignalR:} Dedicato a notifiche leggere e aggiornamenti di stato in tempo reale.
\end{enumerate}
Questa separazione garantisce la resilienza del sistema e una chiara \emph{separation of concerns}. SignalRHub agisce da ponte (\emph{bridging}) tra due componenti principali:

\textbf{1. SignalR Client .NET (Lato MCP Server):}
Il server MCP utilizza il pacchetto \texttt{Microsoft.AspNetCore.SignalR.Client} per stabilire una connessione persistente con l'Hub tramite il metodo \texttt{StartAsync()}. Il client sottoscrive eventi specifici tramite \texttt{On<T>} per reagire ai comandi e utilizza \texttt{InvokeAsync} per inviare risultati o notifiche di stato, sfruttando la politica di riconnessione automatica (0-10s) per garantire la continuità operativa anche in caso di riavvio dell'Hub.

\textbf{2. SignalR Client Browser (Lato Configurator3D):}
Il frontend, basato sul pacchetto npm \texttt{@microsoft/signalr} v8.x, gestisce la visualizzazione dinamica. I gestori di eventi, come \texttt{on("open")} o \texttt{on("create")}, intercettano i comandi provenienti dal server MCP. Per garantire la coerenza distribuita, è stato implementato un \textbf{ACK pattern} indispensabile per la corretta elaborazione di un comando. Il client invoca il metodo \texttt{invoke("SendAck", commandId)}, confermando l'avvenuta ricezione ed esecuzione dell'operazione.

\bigskip
\noindent \textbf{Caratteristiche Determinanti per la Scelta.}
I fattori che hanno guidato la decisione di integrare SignaIR nell'architettura del progetto sono più di uno e rispondono a requisiti non funzionali critici:
\begin{itemize}
    \item \textbf{Bidirezionalità Real-Time:} La capacità di mantenere una latenza inferiore ai 10ms, contro gli 1-5 secondi tipici del polling, è essenziale per la fluidità del configuratore 3D.
    \item \textbf{Affidabilità:} La gestione automatica delle riconnessioni assicura la stabilità delle sessioni utente di lunga durata.
    \item \textbf{Fallback Transport:} La garanzia di compatibilità al 100\% in ambienti di rete restrittivi elimina i rischi di disservizio lato client.
    \item \textbf{Maturità dell'Ecosistema:} Il supporto LTS di Microsoft e la natura \emph{production-ready} della libreria offrono garanzie di manutenibilità a lungo termine \cite{microsoft_signalr_docs, integrating_signalr_dotnet}.
\end{itemize}

\section{Sicurezza Applicativa}
\label{sec:sicurezza}
%----------------------------------------------------------------------------------------

% FOCUS: JWT autenticazione stateless, CORS, HTTPS
% Approccio: DETTAGLIATO per JWT, COMPATTO per CORS/HTTPS

%----------------------------------------------------------------------------------------
\subsection{JWT: Autenticazione Stateless}
\label{subsec:jwt}
%----------------------------------------------------------------------------------------

% Contenuti da sviluppare (1.5 pagine - RIDOTTA da 3):
%
% A) COSA è JWT (0.6 pagine):
% - RFC 7519: JSON Web Token per access token stateless
% - Struttura: header.payload.signature (3 parti Base64Url encoded)
%   * Header: { "alg": "HS256", "typ": "JWT" }
%   * Payload: { "sub": "user123", "exp": 1735689600, "name": "..." } (claims)
%   * Signature: HMACSHA256(header + payload, secret_key)
% - Verifica: server ricalcola signature, check exp claim
%
% B) PERCHÉ JWT (0.6 pagine):
%
% Tabella 3.5: Session vs JWT (COMPATTA)
% | Aspetto      | Session-based     | JWT                |
% |--------------|-------------------|--------------------|
% | State        | Stateful          | Stateless          |
% | Storage      | Server memory/DB  | Client-side        |
% | Scalability  | Sticky sessions   | Horizontal scaling |
% | CSRF         | Vulnerable        | Immune             |
% | Cross-domain | Problematic       | Easy               |
%
% Vantaggi JWT:
% - **Stateless**: scalabilità orizzontale illimitata
% - **Self-contained**: no database lookup per ogni request
% - **Cross-domain**: CORS-friendly, no cookie restrictions
%
% C) Ruolo progetto (0.3 pagine):
% - MarkunoAPI emette JWT al login: POST /api/login → { Token }
% - MCP Server invia JWT in Authorization header: "Bearer <token>"
% - MarkunoAPI valida signature e exp claims
%
% Security considerations (breve):
% - HTTPS enforcement, secret protection, short expiration (15-30 min)
%
% Elementi visivi:
% - Tabella 3.5: Session vs JWT (5×3)
% - Diagramma 3.5: JWT flow (Login → Token → Request → Validate)
%
% Pagine stimate: 1.5

La sicurezza delle moderne architetture a microservizi richiede meccanismi di autenticazione che garantiscano scalabilità e disaccoppiamento. Per questo lavoro si è adotta il formato JSON Web Token (JWT), definito dalla RFC 7519 \cite{rfc7519_jwt}, per rappresentare in modo compatto e sicuro le asserzioni (claims) scambiate tra le parti comunicanti. Dal punto di vista strutturale, il token si presenta come una stringa codificata in Base64Url, suddivisa in tre segmenti distinti separati da un punto, i componenti sono: \textit{Header}, \textit{Payload} e \textit{Signature}.
L'\textbf{Header} definisce i metadati crittografici, specificando l'algoritmo di firma (es. \texttt{\{"alg": "HS256", "typ": "JWT"\}}), mentre il \textbf{Payload} incapsula le asserzioni vere e proprie. Queste includono claim standard registrati come il soggetto (\texttt{sub}), la scadenza (\texttt{exp}) e dati applicativi personalizzati, rendendo il token un oggetto informativo autosufficiente. La \textbf{Signature}, infine, è ottenuta applicando l'algoritmo specificato (come HMACSHA256) alla concatenazione di header e payload codificati, utilizzando una chiave segreta nota solo al server. Questo meccanismo permette al ricevente di verificare l'integrità del dato e l'autenticità dell'emittente ricalcolando la firma al momento della ricezione \cite{rfc7519_jwt, shingala_jwt_mqtt}.

La decisione di adottare JWT invece delle sessioni server-side è motivata da chiari vantaggi per i sistemi distribuiti infatti essendo stateless, i JWT rimuovono la necessità di sincronizzare lo stato delle sessioni tra nodi o di interrogare un database centralizzato ad ogni richiesta HTTP, favorendo una scalabilità orizzontale più semplice (vedi Tabella \ref{tab:session-vs-jwt}) \cite{lee_stateless_rest, obinna_jwt_cloud}.

\begin{table}[ht]
\centering
\caption{Confronto: Session-based Auth vs JWT.}
\label{tab:session-vs-jwt}
\small
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Aspetto} & \textbf{Session-based} & \textbf{JWT} \\ \midrule
Stato & Stateful (Server-side) & Stateless (Client-side) \\
Storage & Memoria Server / Redis & Client (LocalStorage/Cookie) \\
Scalabilità & Limitata (Sticky Sessions) & Elevata (Horizontal Scaling) \\
CSRF & Vulnerabile & Generalmente Immune \\
Cross-domain & Problematico & Semplice (CORS-friendly) \\ \bottomrule
\end{tabular}
\end{table}

Essendo \textbf{self-contained}, il token trasporta già tutte le informazioni necessarie per l'autorizzazione, riducendo la latenza di rete e il carico sui database. Inoltre, la natura standardizzata del formato JSON facilita l'interoperabilità \emph{cross-domain}, superando le restrizioni tipiche dei cookie in scenari CORS (\emph{Cross-Origin Resource Sharing}) complessi \cite{obinna_jwt_cloud}.

Il flusso di autenticazione prevede che il \textbf{servizio API esterno} agisca come \emph{Identity Provider}. Dopo una richiesta di login valida (\texttt{POST /api/login}), il server emette un JWT firmato contenente i claim dell'utente. Il client, rappresentato dall'\textbf{MCP Server}, riceve il token e lo include nell'header \texttt{Authorization} di tutte le richieste successive, usando lo schema standard \texttt{Bearer <token>}. Alla ricezione, il servizio API esterno verifica soltanto la firma crittografica e il campo di scadenza (\texttt{exp}), senza consultare tabelle di sessione. Per ridurre i rischi legati alla memorizzazione lato client, il sistema richiede l'uso esclusivo di canali cifrati HTTPS e adotta finestre di validità brevi (15–30 minuti), minimizzando l'impatto di un eventuale furto del token \cite{shingala_jwt_mqtt, rfc7519_jwt}.

\subsection{CORS e Transport Security}
\label{subsec:cors-https}
%----------------------------------------------------------------------------------------

% Contenuti da sviluppare (1 pagina - UNISCE CORS + HTTPS):
%
% A) CORS: Cross-Origin Resource Sharing (0.6 pagine):
% - Problema: Same-Origin Policy browser blocca requests cross-domain
% - Scenario progetto:
%   * Configurator3D: https://configurator.markuno.com
%   * SignalR Hub: https://api.markuno.com:7193 (porta diversa)
%   * Browser blocca WebSocket → serve CORS
% - Soluzione: server invia header Access-Control-*
%   * Access-Control-Allow-Origin: origin autorizzato
%   * Access-Control-Allow-Credentials: true (REQUIRED per SignalR + auth)
% - Preflight request: browser OPTIONS prima request effettiva
% - Ruolo progetto: IwineHub configurato CORS per Configurator3D origin
%
% B) HTTPS/WSS: Transport Layer Security (0.4 pagine):
% - HTTPS: HTTP over TLS, WSS: WebSocket Secure over TLS
% - TLS 1.3: encryption end-to-end, AES-256-GCM
% - PERCHÉ: confidenzialità (JWT encrypted), integrità, autenticità
% - Ruolo progetto:
%   * HTTPS: tutte chiamate REST MarkunoAPI
%   * WSS: SignalR WebSocket
%   * Sviluppo: self-signed certificate, Produzione: Let's Encrypt
% - Senza TLS: JWT intercettabile (MITM attack)
%
% Elementi visivi:
% - Diagramma 3.6: CORS preflight flow (OPTIONS → headers → request)
%
% Pagine stimate: 1

Quando frontend e backend risiedono su domini o porte diverse, è necessario abilitare Cross‑Origin Resource Sharing (CORS) per il controllo degli accessi e utilizzare TLS per cifrare le comunicazioni tra il client di configurazione 3D e l'hub di backend.

La sicurezza dei browser impone nativamente la \textit{Same-Origin Policy} (SOP), una misura difensiva che impedisce a uno script caricato da un'origine (definita dalla combinazione di protocollo, dominio e porta) di interagire con risorse provenienti da un'origine diversa \cite{mdncors}. Tale restrizione, sebbene fondamentale per prevenire attacchi di tipo CSRF (\textit{Cross-Site Request Forgery}), rappresenta un ostacolo tecnico nello scenario implementativo del progetto. Il frontend dell'applicazione è ospitato su un sottodominio dedicato (es. \url{https://app.dominio.com}), mentre il backend, che espone gli endpoint REST e l'hub SignalR, risponde su un indirizzo differente o su una porta specifica (es. \url{https://api.dominio.com:7193}). Essendo differenti l'origine e la porta di comunicazione, il browser classifica le richieste come \textit{cross-origin}, bloccando di default l'instaurazione della connessione WebSocket necessaria per la comunicazione in tempo reale.

Per far si che questa limitazione non impatti eccessivamente la sicurezza dell'applicazione, è stato configurato il middleware CORS lato server. Il protocollo CORS consente al backend di dichiarare esplicitamente quali origini sono autorizzate ad accedere alle risorse tramite l'invio di specifici header HTTP \cite{w3ccors}. Quando il browser rileva una richiesta verso un dominio esterno che potrebbe comportare effetti collaterali sui dati utente, avvia in modo precauzionale una "Preflight request" utilizzando il metodo HTTP \texttt{OPTIONS}. Come illustrato nel Diagramma \ref{fig:cors-flow}, il server risponde a questa richiesta preliminare specificando i metodi consentiti e, crucialmente, l'header \texttt{Access-Control-Allow-Origin}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/cors_flow.png}
    \caption{Diagramma di sequenza del flusso CORS Preflight tra Frontend e Backend. Il server autorizza esplicitamente l'origine e l'uso delle credenziali prima della connessione WebSocket.}
    \label{fig:cors-flow}
\end{figure}

Nel caso specifico della comunicazione real-time con SignalR, la configurazione si complica maggiormente in quanto vi è la necessità di trasmettere credenziali di autenticazione (cookie o header di autorizzazione). La specifica CORS impone che, quando le credenziali sono coinvolte, il server non possa utilizzare il carattere jolly (\texttt{*}) per l'origine, ma debba restituire l'esatto dominio del chiamante e includere l'header \texttt{Access-Control-Allow-Credentials: true} \cite{mdncors}. L'assenza di tale configurazione provocherebbe il fallimento immediato dell'handshake WebSocket inizializzato dal client.

Parallelamente al controllo degli accessi, la confidenzialità e l'integrità dei dati in transito sono garantite dall'adozione del protocollo \textit{Transport Layer Security} (TLS), su cui si basano HTTPS (\textit{HyperText Transfer Protocol Secure}) e WSS (\textit{WebSocket Secure}). L'intero traffico tra il configuratore 3D e le API di backend avviene esclusivamente su canale cifrato, utilizzando prevalentemente lo standard TLS 1.3. La nuova versione del protocollo riduce la latenza durante l'handshake e rimuove algoritmi crittografici obsoleti, limitando la possibilità di sorveglianza del traffico \cite{carnavalet2022survey}.

L'adozione di HTTPS è imprescindibile non solo per le API REST, ma soprattutto per proteggere il token di autenticazione JSON Web Token (JWT), impedendo la sua intercettazione. In assenza di un canale cifrato, un attaccante posizionato sulla rete (attacco \textit{Man-In-The-Middle}) potrebbe intercettare il token in chiaro e impersonare l'utente. Il protocollo TLS stabilisce una crittografia end-to-end che assicura che i dati scambiati siano leggibili solo dagli endpoint autorizzati, garantendo contemporaneamente l'autenticità del server tramite certificati digitali \cite{sy2019enhanced}. Dal punto di vista crittografico, il canale utilizza cifrari simmetrici moderni come AES-256-GCM (\textit{Galois/Counter Mode}), che forniscono cifratura autenticata garantendo sia la segretezza che l'integrità del messaggio contro tentativi di manomissione \cite{carnavalet2022survey}.

\section{Integrazione Frontend}
\label{sec:frontend}
%----------------------------------------------------------------------------------------

% FOCUS: TypeScript e SignalR client browser
% Approccio: COMPATTO, essenziale

%----------------------------------------------------------------------------------------
\subsection{TypeScript: Type-Safety JavaScript}
\label{subsec:typescript}

\subsubsection{Definizione e Paradigma del Linguaggio}
\label{subsubsec:ts-definizione}

Nel panorama dello sviluppo web moderno, \textbf{TypeScript} rappresenta un'evoluzione strutturale del tradizionale scripting lato client. Definito formalmente come un superset sintattico di JavaScript, questo linguaggio, sviluppato e mantenuto da Microsoft come progetto open-source, integra un sistema di tipizzazione statica opzionale all'interno della flessibilità dinamica propria dello standard ECMAScript \cite{typescript_docs, ecma262}.

L'architettura del linguaggio, giunta alla versione 5.x, non è destinata all'esecuzione diretta nei browser o nei runtime come Node.js. Essa necessita invece di un processo di compilazione, o più propriamente detto di \textit{transpilation}, gestito dal compilatore \texttt{tsc}. Il processo di compilazione converte TypeScript in JavaScript conforme a ECMA‑262, assicurando compatibilità cross‑platform e rimuovendo le annotazioni di tipo, che sono utili solo in fase di sviluppo \cite{typescript_docs, devblogs_microsoft}.

\subsubsection{Analisi Comparativa: Static vs Dynamic Typing}
\label{subsubsec:ts-analisi-comparativa}

L'adozione di TypeScript risponde alle criticità dello sviluppo su larga scala in JavaScript: grazie ai tipi statici opzionali, diminuisce la probabilità di errori, facilita il refactoring e migliora la manutenibilità del codice. Come evidenziato dalla documentazione tecnica relativa alla tipizzazione statica, la verifica dei vincoli sui dati in JavaScript avviene esclusivamente a \textit{runtime}, esponendo il software a errori che emergono solo durante l'esecuzione \cite{mdn_static_typing}. Al contrario, TypeScript anticipa tale validazione alla fase di compilazione (\textit{compile-time}), permettendo l'identificazione preventiva di incongruenze logiche e sintattiche \cite{typescript_docs}.

La Tabella \ref{tab:js-vs-ts} riassume le differenze strutturali tra i due approcci, evidenziando l'impatto sulla stabilità del codice e sull'esperienza di sviluppo.

\begin{table}[ht]
\centering
\caption{Confronto architetturale: JavaScript vs TypeScript.}
\label{tab:js-vs-ts}
\small
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Aspetto Funzionale} & \textbf{JavaScript (Standard ECMA)} & \textbf{TypeScript} \\ \midrule
Verifica dei Tipi & Runtime (Dinamica) & Compile-time (Statica) \\
Rilevamento Errori & In Produzione/Esecuzione & In Sviluppo/Compilazione \\
Supporto Tooling & IntelliSense Limitato & Autocomplete Completo \\
Refactoring & Rischioso (String-based) & Sicuro (Type-checked) \\ \bottomrule
\end{tabular}
\end{table}

Un vantaggio determinante derivante dall'adozione di questo paradigma è il potenziamento degli strumenti di supporto allo sviluppo. Ambienti di sviluppo integrati come Visual Studio Code sfruttano le definizioni di tipo per offrire funzionalità avanzate di \textbf{IntelliSense}, quali il completamento automatico del codice, la documentazione in linea e la navigazione semantica delle API \cite{vscode_intellisense}. Tale caratteristica permette di diminuire notevolmente il rischio di errori banali, come refusi nei nomi dei metodi o accessi a proprietà inesistenti, che in un contesto puramente JavaScript verrebbero intercettati solo a runtime \cite{typescript_docs, vscode_intellisense}.

\subsubsection{Implementazione nel Contesto Progettuale}
\label{subsubsec:ts-project-role}

Nell'architettura del configuratore 3D, l'impiego di TypeScript (versione 5.x) costituisce la base per garantire la robustezza del frontend. La necessità di manipolare strutture dati complesse per la configurazione tridimensionale e la gestione di comunicazioni real-time richiede garanzie di correttezza che trascendono le capacità del JavaScript puro.

In particolare, l'integrazione del client \textbf{SignalR} avviene attraverso il pacchetto \texttt{@microsoft/signalr}, il quale fornisce definizioni di tipo native \cite{npm_signalr}. Questo approccio permette di strutturare le invocazioni dei metodi remoti e la gestione degli eventi in modo \textit{type-safe}. Ogni messaggio scambiato tra client e server viene validato rispetto a interfacce predefinite, assicurando che il payload dei dati rispetti rigorosamente la struttura attesa dall'Hub. L'adozione di TypeScript rende le API di comunicazione verificabili staticamente, riducendo la fragilità tipica dei contesti dinamici e aumentando manutenibilità e scalabilità del client \cite{typescript_docs, npm_signalr}.
%----------------------------------------------------------------------------------------

% Contenuti da sviluppare (0.7 pagine):
%
% A) COSA è TypeScript (0.3 pagine):
% - Superset JavaScript con type system statico
% - Microsoft, open-source, versione 5.x (2023)
% - Compilation: TypeScript → transpiler tsc → JavaScript (ES6)
%
% B) PERCHÉ TypeScript (0.4 pagine):
%
% Tabella 3.6: JavaScript vs TypeScript (COMPATTA)
% | Aspetto      | JavaScript  | TypeScript         |
% |--------------|-------------|--------------------|
% | Type check   | Runtime     | Compile-time       |
% | Errors       | Production  | Development        |
% | IntelliSense | Limited     | Full autocomplete  |
% | Refactoring  | Risky       | Safe (type-checked)|
%
% Vantaggi progetto:
% - **Compile-time errors**: catch typo method names BEFORE runtime
% - **IntelliSense**: autocomplete SignalR methods
% - **Type safety**: message structure garantita
%
% Ruolo progetto:
% - Configurator3D scritto in TypeScript 5.x
% - SignalR client: import @microsoft/signalr, type-safe API
%
% Pagine stimate: 0.7

%----------------------------------------------------------------------------------------
\subsection{SignalR Client Browser}
\label{subsec:signalr-browser}
%----------------------------------------------------------------------------------------

% Contenuti da sviluppare (0.8 pagine):
%
% A) COSA è @microsoft/signalr (0.3 pagine):
% - Package npm: client SignalR per browser JavaScript/TypeScript
% - Versione 8.x (aligned con SignalR server 8.0)
% - API: HubConnectionBuilder, on(), invoke(), start()
%
% B) Configurazione (0.3 pagine):
% - HubConnectionBuilder: withUrl(), withAutomaticReconnect([0, 2, 5, 10]), configureLogging()
% - Event handlers: on("GetMessage", handler), on("GetConnectionId", handler)
% - Server invocation: invoke("SendMessage", receiverId, message)
% - Lifecycle: start(), stop(), onclose(callback)
%
% C) Ruolo progetto (0.2 pagine):
% - Handlers comandi MCP: on("open", ...), on("create", ...), on("list", ...), on("add", ...)
% - ACK pattern: invoke("SendAck", commandId, "success")
% - UI feedback: connection status indicator (verde/giallo/rosso)
% - Gestione errori: auto-reconnect, fallback Long Polling
%
% Elementi visivi:
% - Listing 3.6: Esempio HubConnectionBuilder setup (pseudo-code)
%
% Pagine stimate: 0.8


\subsubsection{Il Package @microsoft/signalr}
\label{subsubsec:signalr-package}

L'implementazione lato client della comunicazione real-time nel progetto \textit{Configurator3D} si basa sul package \texttt{@microsoft/signalr}, una libreria JavaScript ufficiale distribuita attraverso il registro npm e progettata per fornire un'interfaccia completa e type-safe per l'interazione con hub SignalR remoti \cite{npm_signalr}. Questa componente software, allineata alla versione 8.x del framework server-side, costituisce il layer di astrazione che permette alle applicazioni browser-based e ai runtime Node.js di stabilire connessioni bidirezionali con backend ASP.NET Core, gestendo automaticamente la negoziazione del protocollo di trasporto e la serializzazione dei messaggi \cite{microsoft_signalr_docs}.

Dal punto di vista architetturale, il package espone un insieme di API object-oriented incentrate sulla classe \texttt{HubConnection\-Builder}, che implementa il pattern \textit{Builder} per la configurazione dichiarativa delle connessioni. L'oggetto \texttt{Hub\-Connection} risultante rappresenta il canale di comunicazione attraverso cui avviene lo scambio di messaggi con il server. Le primitive fondamentali dell'API adottano una semantica asincrona basata su Promise, assicurando compatibilità nativa con il modello di concorrenza moderno di JavaScript. Nello specifico, il metodo \texttt{start()} inizializza la connessione effettuando l'handshake con il server, mentre \texttt{on(eventName, handler)} permette la registrazione di callback per eventi specifici inviati dal server, realizzando un pattern \textit{Observer} distribuito \cite{npm_signalr, ms_signalr_intro}.

La capacità di invocare metodi remoti in modo programmatico è fornita dalla primitiva \texttt{invoke(methodName, ...args)}, che serializza i parametri, li trasmette al server attraverso il canale WebSocket (o il trasporto di fallback attivo), e restituisce una Promise risolta con il valore di ritorno del metodo server-side. Questo meccanismo di \textit{Remote Procedure Call} (RPC) permette di ridurre significativamente la complessità dello sviluppo di interfacce distribuite, nascondendo i dettagli del protocollo sottostante e della gestione degli errori di rete \cite{microsoft_signalr_docs}.

\subsubsection{Configurazione e Resilienza della Connessione}
\label{subsubsec:signalr-configuration}
La robustezza della comunicazione real-time in ambienti di produzione richiede una configurazione precisa dei meccanismi di resilienza e diagnostica. Il \texttt{HubConnection\-Builder} mette a disposizione metodi fluent per definire i parametri operativi critici della connessione, offrendo la flessibilità necessaria ad adattarsi a diverse topologie di rete e requisiti di affidabilità \cite{microsoft_signalr_docs}.

Il metodo \texttt{withUrl(url, options)} definisce l'endpoint del servizio SignalR e, opzionalmente, configura aspetti avanzati del trasporto, come l'inclusione di header HTTP personalizzati o la specificazione esplicita dei protocolli di trasporto ammissibili. La resistenza alle disconnessioni temporanee, fenomeno impossibile da evitare del tutto in reti mobili o congestionate, è gestita dalla direttiva \texttt{withAutomaticReconnect(retryDelays)}, che implementa una strategia di riconnessione automatica con backoff esponenziale. La specifica dei ritardi di retry, tipicamente configurati come array crescente (ad esempio \texttt{[0, 2000, 5000, 10000]} millisecondi), consente di bilanciare la reattività nel ripristino della connessione con la necessità di evitare sovraccarichi sul server in scenari di degradazione estesa del servizio \cite{microsoft_signalr_docs, google_websocket_best_practices}.

Il monitoraggio diagnostico dello stato della connessione è facilitato dal metodo \texttt{configureLogging(level)}, che attiva la tracciatura dettagliata degli eventi del ciclo di vita della connessione, inclusi handshake, fallimenti di trasporto e messaggi scambiati. La definizione di handler per eventi specifici avviene per mezzo delle invocazioni del metodo \texttt{on(eventName, callback)}, dove \texttt{eventName} corrisponde al nome del metodo definito nell'interfaccia strongly-typed dell'hub server. Nel contesto progettuale, eventi quali \texttt{"GetMessage"} e \texttt{"GetConnectionId"} sono intercettati per aggiornare lo stato dell'applicazione client in risposta a notifiche push dal backend \cite{npm_signalr}.

La invocazione di metodi sul server avviene tramite la primitiva \texttt{invoke(method\-Name, ...args)}, che serializza automaticamente i parametri tipizzati in formato JSON. Ad esempio, \texttt{invoke("SendMessage", receiverId, message)} invia al server una richiesta di inoltro di un messaggio a un destinatario specifico. La chiamata restituisce una \texttt{Promise} che si risolve al completamento dell’operazione o viene respinta in caso di errore di rete o applicativo. Il ciclo di vita della connessione è gestito dai metodi \texttt{start()}, che apre il canale asincrono, e \texttt{stop()}, che chiude la connessione in modo ordinato; inoltre il callback \texttt{onclose(error)} viene invocato quando si verifica una disconnessione, sia intenzionale sia dovuta a un errore \cite{microsoft_signalr_docs, ms_signalr_intro}.

\subsubsection{Integrazione Applicativa e Pattern Operativi}
\label{subsubsec:signalr-project-role}
Nel contesto dell'architettura del configuratore tridimensionale, il client SignalR assume il ruolo di ponte da comunicazione tra l'interfaccia utente e il server MCP (\textit{Model Context Protocol}), gestendo lo scambio di comandi e notifiche di stato. La registrazione di handler per eventi specifici, corrispondenti ai comandi del protocollo applicativo, è implementata mediante invocazioni successive del metodo \texttt{on()}. Comandi quali \texttt{"open"}, \texttt{"create"} e \texttt{"add"} sono intercettati da callback che aggiornano atomicamente lo stato del modello 3D visualizzato, garantendo coerenza tra la rappresentazione locale e lo stato remoto gestito dal backend \cite{integrating_signalr_dotnet}.

Per assicurare l'affidabilità delle operazioni distribuite, è stato adottato un pattern di acknowledgment esplicito. Al completamento dell'elaborazione di un comando ricevuto, il client invoca il metodo \texttt{invoke("SendAck", commandId, status)}, trasmettendo al server la conferma dell'avvenuta ricezione ed esecuzione. Questo schema, ispirato ai protocolli di comunicazione affidabile, permette al server di rilevare eventuali perdite di messaggi o timeout di elaborazione, Attivando strategie di compensazione, come la ritrasmissione o la notifica di errore all'utente, si mitiga l'impatto dei guasti temporanei \cite{integrating_signalr_dotnet, Medavarapu2022}.

%----------------------------------------------------------------------------------------
% FINE CAPITOLO 3: Stack Tecnologico
% Pagine totali stimate: 2 + 3.5 + 4.5 + 2.5 + 1.5 = ~14 pagine
%----------------------------------------------------------------------------------------
\chapter{Progettazione del Sistema}
\label{chap:progettazione}
%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------
\section{Architettura Generale del Sistema}
\label{sec:architettura-generale}
%----------------------------------------------------------------------------------------

% Panoramica dell'architettura a tre livelli:
% - Livello MCP Server: ExternalApiTools espone tool MCP per l'AI Assistant
% - Livello Bridge: SignalRService gestisce comunicazione real-time
% - Livello External Systems: ExternalApi (REST) e Configurator3D (client)
%
% Concetti chiave da evidenziare:
% - Pattern Architetturale: Layered Architecture con separazione responsabilità
% - Protocolli di comunicazione: HTTP/REST sincrono + SignalR asincrono
% - Dependency Injection: configurazione centralizzata nel Program.cs
% - Motivazioni: Isolamento tra componenti, testabilità, manutenibilità
%
% Diagramma: diagram_1_overview.mmd
% Pagine stimate: 2-3
La progettazione del sistema si fonda su un'architettura definita a strati (\emph{Layered Architecture}), realizzata per garantire una  separazione delle responsabilità tra i componenti logici e per favorire la manutenibilità e la testabilità del software. Il design deve armonizzare tre linguaggi: quello umano (IA), quello tecnico (gestionali) e quello visivo (3D).

L'architettura proposta agisce come un intermediario intelligente, lavorando per disaccoppiare la logica decisionale dell'AI dai dettagli operativi dei sottosistemi sottostanti. Come viene illustrato nel Diagramma 1, il sistema comprende tre livelli funzionali principali: il livello di definizione degli strumenti MCP, il livello di servizio per la comunicazione in tempo reale e il livello di integrazione con i sistemi esterni.

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{figures/diagram_1_overview.png}
  \caption{Diagramma 1: Architettura di alto livello: componenti principali e relazioni tra Program, ExternalApiTools, SignalRService, ExternalApi e Configurator3D.}
  \label{fig:diagram-1}
\end{figure}

\subsection*{Il Pattern Architetturale e i Componenti Logici}

Al vertice della gerarchia logica si colloca il modulo dedicato agli strumenti MCP (identificato nel diagramma come \texttt{ExternalApiTools}). La loro responsabilità è esporre all'AI Assistant un set di funzionalità astratte,come l'autenticazione, la gestione dei progetti o l'inserimento di articoli, mascherando la complessità delle chiamate sottostanti. Questo livello opera come un traduttore che è in grado di convertire i comandi, espressi in linguaggio umano, in comandi eseguibili dal sistema.

A supporto delle operazioni che richiedono un'interazione immediata con l'interfaccia utente, interviene il livello di servizio real-time, rappresentato dalla classe \texttt{SignalRService}. Questo modulo implementa il pattern \emph{Bridge}, agendo come canale di comunicazione asincrono verso il configuratore grafico (\texttt{Configurator3D}). La scelta di segregare la logica di comunicazione in un servizio dedicato permette di isolare il protocollo di trasporto dal resto della logica di business, facilitando eventuali evoluzioni future dell'infrastruttura di messaggistica senza impattare sulla definizione dei tool MCP.

I sistemi esterni, sebbene fisicamente separati dal server MCP, costituiscono parte integrante dell'ecosistema progettato. Da un lato, le API del sistema gestionale (rappresentate dalla classe \texttt{ExternalApi}) forniscono la persistenza dei dati e la logica di business core attraverso un'interfaccia REST; dall'altro, il client grafico (\texttt{Configurator3D}) agisce come terminale di visualizzazione, ricevendo comandi di aggiornamento della scena e restituendo feedback sullo stato della configurazione.

\subsection*{Strategie di Comunicazione e Protocolli}

Un aspetto distintivo dell'architettura risiede nella natura ibrida dei pattern di comunicazione adottati. Il sistema adotta due paradigmi differenti che sono:

\begin{enumerate} \item \textbf{Comunicazione Sincrona (HTTP/REST):} Utilizzata per l'interazione tra il livello dei tool MCP e le API del gestionale esterno. Questo approccio è stato scelto per operazioni atomiche e transazionali, come il login o il recupero di liste di progetti, dove la consistenza immediata della risposta ha priorità massima. \item \textbf{Comunicazione Asincrona (SignalR/WebSocket):} Adottata per il dialogo tra il server MCP e il client 3D. La necessità di modificare la scena grafica in tempo reale, senza imporre al client un dispensioso polling continuo, ha guidato la scelta verso un protocollo \emph{full-duplex} capace di inviare notifiche push.
\end{enumerate}

\subsection*{Gestione delle Dipendenze e Configurazione}

Il punto di ingresso dell'applicazione, identificato dalla classe \texttt{Program}, oltre all'avvio del progetto, ha il ruolo di
\emph{Composition Root} ossia configura il contenitore di \emph{Dependency Injection} (DI), responsabile dell'istanziazione e del ciclo di vita di tutti i servizi.

L'integrazione della Dependency Injection deriva dalla necessità di invertire il controllo tra i componenti del sistema. la classe \texttt{ExternalApiTools} non deve generare al proprio interno le istanze di \texttt{SignalRService} o dei client HTTP, ma ne riceve le astrazioni tramite interfacce al momento della sua creazione.

Dunque, l'architettura è strutturata per adattarsi agilmente ai cambiamenti dei sistemi terzi. Il server MCP funge da adattatore che normalizza i flussi di dati, offrendo all'Intelligenza Artificiale un punto di accesso coerente e delegando ai servizi sottostanti l'intera gestione dei protocolli di comunicazione.

%----------------------------------------------------------------------------------------
\section{Sistema di Configurazione e Bootstrap}
\label{sec:configurazione-bootstrap}
%----------------------------------------------------------------------------------------

% Gestione della configurazione applicativa:
% - AppSettings: struttura con BaseUrl, ExternalCredentials, SignalRConfig
% - Pattern Dependency Injection: registrazione servizi singleton
% - IConfiguration: caricamento da appsettings.json
% - Responsabilità Program.cs: load config → register services → configure MCP
%
% Concetti chiave:
% - Externalizzazione configurazione: zero hardcoding
% - Environment-specific settings: appsettings.Development.json, appsettings.Production.json
% - Singleton pattern: SignalRService condiviso tra tool
% - Security: credenziali in file esclusi da version control
%
% Diagramma: diagram_2_configuration.mmd
% Pagine stimate: 2-3
La fase di inizializzazione, o \emph{bootstrap}, costituisce il momento fondante del ciclo di vita applicativo, durante il quale vengono stabilite le condizioni operative necessarie per la corretta esecuzione del server MCP. La progettazione di questo stadio definisce una strategia strutturata per la gestione delle dipendenze, l'isolamento dei parametri di configurazione e la predisposizione dei canali di comunicazione sicuri. L'architettura adotta un approccio dichiarativo, delegando al componente \texttt{Program} (l'\emph{entry point}) la responsabilità di orchestrare il caricamento delle impostazioni e la registrazione dei servizi nel contenitore di \emph{Dependency Injection} (DI).

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{figures/diagram_2_configuration.png}
  \caption{Diagramma 2: Layer di configurazione: struttura di \texttt{AppSettings} (con ExternalCredentials e SignalRConfig) e relazioni con Program, IServiceCollection e IConfiguration.}
  \label{fig:diagram-2}
\end{figure}

\subsection*{Modellazione e Gestione della Configurazione}

Un principio cardine adottato nel design del sistema è la completa esternalizzazione della configurazione, eliminando qualsiasi forma di codifica rigida (\emph{hardcoding}) di parametri sensibili o variabili d'ambiente all'interno del codice sorgente. Come illustrato nel Diagramma 2, il modello di configurazione è stato strutturato gerarchicamente attraverso la classe \texttt{AppSettings}, che funge da radice per l'aggregazione di tutte le impostazioni applicative.

Questa classe mappa direttamente la struttura del file \texttt{appsettings.json}, suddividendo le responsabilità in sotto-moduli specializzati: \begin{itemize} \item \textbf{ExternalCredentials}: incapsula le credenziali di accesso predefinite (utente e password) necessarie per l'autenticazione iniziale verso le API del sistema gestionale esterno. \item \textbf{SignalRConfig}: definisce i parametri di connessione per il bridge real-time, inclusi l'URL dell'Hub e i flag di sicurezza per la gestione dei certificati SSL in ambienti di sviluppo (\texttt{AllowInsecure}). \item \textbf{BaseUrl}: specifica l'endpoint radice per le chiamate REST, permettendo di variare l'ambiente di destinazione senza ricompilare l'applicazione. \end{itemize}

Il caricamento di tali parametri è gestito dall'interfaccia \texttt{IConfiguration}, che implementa una strategia a livelli di priorità. Il sistema è progettato per supportare configurazioni specifiche per l'ambiente (\emph{environment-specific settings}), caricando in sequenza il file di base e successivamente le sovrascritture specifiche (es. \texttt{appsettings.Development.json} o \texttt{appsettings.Production.json}). Questo approccio  permette di escludere i file contenenti credenziali reali dal sistema di controllo versione (\emph{version control}), mantenendo i segreti confidenziali.

\subsection*{Orchestrazione dei Servizi e Dependency Injection}

Una volta caricata la configurazione, il flusso di bootstrap procede con la registrazione dei servizi nel framework. Questa fase serve a definire il ciclo di vita degli oggetti e come essi interagiscono tra loro. Il design sfrutta il pattern della \emph{Dependency Injection} per disaccoppiare l'implementazione dei servizi dalla loro utilizzazione nei tool MCP.

Particolare attenzione è stata posta nella definizione del ciclo di vita del \texttt{SignalRService}. A differenza dei componenti stateless, questo servizio gestisce una connessione WebSocket persistente verso il client 3D. Di conseguenza, è stato configurato come \textbf{Singleton} che crea un'istanza condivisa all'avvio dell'applicazione e mantenuta viva per l'intera durata dell'esecuzione. Questa scelta assicura che tutti i tool MCP che necessitano di inviare aggiornamenti real-time utilizzino il medesimo canale di comunicazione, evitando la proliferazione di connessioni ridondanti e garantendo la coerenza dello stato di connessione.

Parallelamente, vengono registrati i servizi per la comunicazione HTTP e il nucleo stesso del server MCP (\texttt{ExternalApiTools}). Il metodo \texttt{ConfigureServices} agisce quindi come punto di convergenza dove le configurazioni statiche, caricate dagli \texttt{AppSettings}, vengono iniettate nei servizi dinamici, rendendo il sistema pronto a gestire le richieste dell'agente AI in modo robusto e configurabile.
%----------------------------------------------------------------------------------------
\section{Servizio di Comunicazione Real-Time}
\label{sec:servizio-signalr}
%----------------------------------------------------------------------------------------

% Architettura del SignalRService:
% - Campi privati: _hubConnection, _logger, _isConnected, _receiveHandlers
% - Metodi pubblici: ConnectAsync, SendCommandAsync, CallHubMethodAsync, OnReceiveMessage
% - HubConnection lifecycle: build → start → reconnect → dispose
%
% Funzionalità avanzate:
% - Auto-reconnessione: tentativi multipli con intervalli crescenti (0s, 2s, 5s, 10s)
% - Multiple endpoint fallback: prova URL base, URL+/hub, URL+/configuratorHub
% - Event handling: registrazione handler per messaggi in arrivo
% - Self-signed certificate support: per ambiente di sviluppo
%
% Concetti chiave:
% - Observer Pattern: registrazione callback per ReceiveMessage
% - Resilienza: retry logic automatico
% - Logging: tracciamento stati connessione
% - Threading safety: gestione concorrente handler
%
% Diagramma: diagram_3_signalr_service.mmd
% Pagine stimate: 3-4

L'orchestrazione della comunicazione bidirezionale tra il server MCP e il client grafico è affidata al componente \texttt{SignalRService}. Tale classe non è stata concepita come un mero involucro (\emph{wrapper}) delle librerie di trasporto, bensì come un servizio infrastrutturale incaricato di isolare la logica di dominio dalle specifiche del protocollo WebSocket, garantendo la gestione del canale di comunicazione in modo centralizzato.

\subsubsection*{Gestione del Ciclo di Vita e Connessione} Il \texttt{SignalRService} si interpone come uno strato di astrazione tra i moduli applicativi e l'oggetto \texttt{HubConnection}. Il compito principale del servizio è la gestione del ciclo di vita della connessione, incapsulata nella procedura interna \texttt{TryBuildAndStartConnectionAsync}.

Questa logica implementa meccanismi di riconnessione automatica e politiche di \emph{retry}, fondamentali per assicurare che il bridge tra MCP e configuratore rimanga attivo senza interventi manuali in caso di micro-interruzioni di rete. Dal punto di vista della sicurezza, il servizio è configurato per gestire la negoziazione dei trasporti e, in fase di sviluppo, supporta l'interazione con certificati \emph{self-signed}, facilitando il testing locale del sistema.

\begin{figure}[H] \centering \includegraphics[width=0.6\textwidth]{figures/3_signalr_service.png} \caption{Diagramma delle classi del SignalR Service Layer: astrazione della connessione e interfacce verso l'Hub.} \label{fig:diagram-3} \end{figure}

\subsubsection*{Primitive di Comunicazione e Flussi Dati} L'interfaccia pubblica del servizio è stata modellata per riflettere le necessità operative del sistema, fornendo metodi specializzati per l'invio e la ricezione di informazioni:

\begin{itemize} \item \textbf{Flusso Server-to-Client:} Attraverso il metodo \texttt{SendCommandAsync}, il servizio espone una primitiva per l'invio di comandi strutturati (\texttt{open}, \texttt{create}). Questi vengono incapsulati in un oggetto \texttt{Message} e inoltrati al client. Per garantire l'estensibilità, il metodo generico \texttt{CallHubMethodAsync} permette l'invocazione di qualsiasi procedura esposta dall'Hub, offrendo flessibilità per evoluzioni future. \item \textbf{Flusso Client-to-Server:} Il servizio adotta un modello reattivo basato su eventi. Tramite \texttt{OnReceiveMessage}, i componenti del server MCP possono registrare handler specifici. Alla ricezione di un messaggio dal WebSocket, il servizio provvede a notificare i moduli interessati, permettendo un'elaborazione asincrona e disaccoppiata. \end{itemize}

\subsubsection*{Architettura Semplificata e Instradamento} A differenza di architetture multi-livello complesse, il sistema attuale adotta un modello di instradamento diretto. L'\texttt{SignalrHub} funge da ripetitore trasparente: i messaggi in ingresso non subiscono processi di validazione o routing logico pesante sul server, ma vengono immediatamente inoltrati alla totalità dei client connessi tramite il metodo \texttt{Clients.All.GetMessage(message)}.

Questa scelta progettuale privilegia la bassa latenza e la semplicità di implementazione per il prototipo corrente. La protezione dell'accesso è garantita a livello infrastrutturale tramite policy di CORS (Cross-Origin Resource Sharing) definite nel punto di ingresso dell'applicazione, che limitano le connessioni ai soli domini autorizzati.

Infine, il servizio utilizza il sistema di \textbf{Dependency Injection} di ASP.NET Core per accedere ai parametri di configurazione essenziali, come il \texttt{PathBase}, permettendo al bridge di adattarsi dinamicamente all'ambiente di esecuzione senza alterazioni al codice sorgente.
%----------------------------------------------------------------------------------------
\section{Infrastruttura SignalR e WebSocket}
\label{sec:infrastruttura-signalr}
%----------------------------------------------------------------------------------------

% Questa sezione descrive in dettaglio l'architettura del bridge SignalR esistente
% utilizzato come layer di comunicazione real-time tra MCP Server e Configurator 3D.
% Il bridge implementa il pattern Hub di SignalR e gestisce tutti gli aspetti della
% comunicazione WebSocket, inclusi routing, broadcasting e comunicazione point-to-point.

%----------------------------------------------------------------------------------------
\subsection{Architettura Multi-Layer del Bridge}
\label{subsec:architettura-bridge}
%----------------------------------------------------------------------------------------

% Architettura a livelli del sistema SignalR:
%
% CLIENT LAYER:
% - Web Application (TypeScript/JavaScript)
% - Mobile Application (Native/Hybrid)
% - Desktop Application (.NET/Electron)
% - Configurator3D (client grafico specifico del progetto)
%
% TRANSPORT LAYER:
% - WebSocket Protocol (preferito): comunicazione bidirezionale full-duplex
% - Server-Sent Events (fallback): per browser senza supporto WebSocket
% - Long Polling (fallback finale): massima compatibilità
% - Fallback automatico gestito da SignalR Client SDK
%
% SIGNALR CORE LAYER:
% - SignalR Client SDK (@microsoft/signalr)
% - Connection Manager: gestione ciclo di vita connessioni
% - Protocol Handler: serializzazione/deserializzazione (JSON/MessagePack)
%
% APPLICATION LAYER (IwineHub):
% - CORS Middleware: gestione Cross-Origin Resource Sharing
% - Authentication: validazione JWT token
% - IwineHub: hub principale per routing messaggi
% - IClient Interface: contratto strongly-typed per comunicazione server-to-client
%
% BUSINESS LAYER:
% - Message Handler: gestione ciclo di vita messaggi
% - Routing Engine: instradamento basato su Action/Route
% - Validation Service: validazione struttura e contenuto messaggi
%
% INFRASTRUCTURE LAYER:
% - Configuration: gestione appsettings.json
% - Service Extensions: extension methods per configurazione servizi
% - Logging: sistema logging centralizzato (ILogger)
%
% DATA LAYER:
% - Message DTO: Data Transfer Object per messaggi
% - Hub Context: contesto runtime con informazioni connessioni
%
% Concetti chiave:
% - Separation of Concerns: ogni layer ha responsabilità specifiche
% - Transport Agnostic: fallback automatico tra protocolli
% - Strongly-Typed Hub: type-safety per comunicazione server-to-client
% - Dependency Injection: configurazione servizi via extension methods
%
% Diagramma: 05-component-diagram.md (diagramsSignalR)
% Pagine stimate: 2-3

La progettazione del sottosistema di comunicazione real-time si fonda su un'architettura a più strati, strutturata per garantire scalabilità e manutenibilità attraverso il principio della separazione delle responsabilità (\emph{Separation of Concerns}). Il sistema è suddiviso in livelli logici distinti, ciascuno incaricato di una fase specifica nel ciclo di vita del messaggio.

\subsubsection*{Dal Trasporto al Core Framework}

Al vertice si colloca il \textbf{Client Layer}, rappresentato dal \texttt{Configurator3D}. Questo livello interagisce con il \textbf{Transport Layer}, il quale riduce la complessità dei protocolli di rete. Il sistema predilige l'uso di WebSocket per garantire comunicazioni \emph{full-duplex} a bassa latenza, gestendo però in modo trasparente i fallback verso protocolli meno performanti per assicurare la compatibilità con ogni ambiente di rete.

Il coordinamento tra i protocolli e l'applicazione è affidato al \textbf{SignalR Core Layer}. In questo strato operano il \emph{Connection Manager}, responsabile del monitoraggio delle sessioni attive, e il \emph{Protocol Handler}, che si occupa della serializzazione dei payload in formato JSON. L'integrazione con l'SDK ufficiale permette di delegare a questo livello la gestione della robustezza e della resilienza delle connessioni a basso livello.

\subsubsection*{Logica Applicativa e di Business}

Il cuore del sistema risiede nell'\textbf{Application Layer}, dove il middleware CORS e i servizi di autenticazione JWT proteggono l'accesso alle risorse. Il punto di contatto è rappresentato dal \texttt{SignalrHub}, che riceve le invocazioni dai client. L'interazione è governata dall'interfaccia \texttt{IClient}: questo contratto \emph{strongly-typed} definisce rigorosamente i metodi invocabili, eliminando errori di runtime e garantendo la totale \emph{type-safety} nelle comunicazioni bidirezionali.

Sotto lo strato applicativo opera il \textbf{Business Layer}, incaricato della logica di dominio. Qui, il \emph{Message Handler} orchestra i flussi di dati e si appoggia al \emph{Routing Engine} per l'instradamento delle richieste alle azioni opportune. Contemporaneamente, il \emph{Validation Service} verifica la conformità strutturale dei payload, garantendo che solo messaggi validi vengano effettivamente elaborati.

\subsubsection*{Infrastruttura e Persistenza Dati}

A supporto dell'intera architettura agisce l'\textbf{Infrastructure Layer}. Questo livello fornisce servizi trasversali mediante il pattern della \emph{Dependency Injection}, gestendo il logging centralizzato e l'estrazione dei parametri operativi dai file di configurazione (\texttt{appsettings.json}). Infine, il \textbf{Data Layer} definisce i \emph{Data Transfer Objects} (DTO) per il trasporto delle informazioni e fornisce l'accesso all'\emph{Hub Context}, permettendo di recuperare in tempo reale lo stato delle connessioni e degli utenti attivi.
%----------------------------------------------------------------------------------------
\subsection{Modello delle Classi e Pattern Hub}
\label{subsec:modello-classi-hub}
%----------------------------------------------------------------------------------------

% Struttura delle classi principali del sistema SignalR:
%
% IwineHub (extends Hub<IClient>):
% - Componente centrale che gestisce tutte le comunicazioni SignalR
% - Metodi principali:
%   - SendMessage(Message message): broadcasting o routing messaggi
%   - SendConnectionId(string receiverId, string senderId): scambio ConnectionId
% - Proprietà ereditate da Hub<T>:
%   - Clients: IHubCallerClients<IClient> per invocare metodi su client
%   - Context: HubCallerContext con info connessione corrente
%   - Groups: IGroupManager per gestione gruppi client
% - Eventi lifecycle:
%   - OnConnectedAsync(): invocato alla connessione client
%   - OnDisconnectedAsync(Exception): invocato alla disconnessione
%
% IClient (interface):
% - Definisce contratto per metodi invocabili sui client (Strongly-Typed Hub)
% - Metodi:
%   - GetMessage(Message message): riceve messaggi broadcast o diretti
%   - GetConnectionId(string connectionId): riceve ConnectionId di altro client
%
% Message (DTO):
% - Data Transfer Object per trasferimento messaggi tra client
% - Proprietà:
%   - Action (string): tipo di azione da eseguire (open, create, list_elements, etc.)
%   - Name (string): nome messaggio/evento
%   - Route (string): percorso destinazione per routing
%   - Params (object): parametri dinamici associati (receiverId, payload, etc.)
%
% Program (static):
% - Configurazione e bootstrap applicazione ASP.NET Core
% - Responsabilità:
%   - ConfigureServices(): registrazione servizi (AddSignalR, AddCors, AddAuth)
%   - ConfigureMiddleware(): pipeline middleware (UseCors, UseAuth, MapHub)
%
% IServiceCollectionExtensions (static):
% - Extension methods per configurazione modulare
% - Metodi:
%   - AddCustomAuthentication(): configura JWT Bearer authentication
%   - AddCustomAuthorization(): configura policy autorizzazione
%
% Concetti chiave:
% - Hub Pattern: centralizzazione routing messaggi real-time
% - Strongly-Typed Hub: type-safety tramite interfaccia IClient
% - DTO Pattern: Message come contratto dati tra client/server
% - Extension Methods: configurazione modulare e riutilizzabile
% - Lifecycle Hooks: OnConnectedAsync/OnDisconnectedAsync per gestione eventi
%
% Diagramma: 01-class-diagram.md (diagramsSignalR)
% Pagine stimate: 2-3

La progettazione del sottosistema di comunicazione in tempo reale si fonda sul pattern dello \emph{Strongly-Typed Hub}, una scelta architetturale che permette di definire in modo rigoroso il contratto di interfaccia tra il server e i client connessi. In questo modello, la classe \texttt{SignalRHub} non si limita a ereditare le funzionalità base del framework ASP.NET Core, ma estende la classe astratta \texttt{Hub<T>} tipizzandola con l'interfaccia \texttt{IClient}. Questo approccio garantisce la coerenza delle chiamate a tempo di compilazione, eliminando le fragilità tipiche delle invocazioni basate su stringhe e assicurando che ogni messaggio inviato dal server rispetti una firma predefinita.

\begin{figure}[H] \centering \includegraphics[width=1\textwidth]{figures/ClassDiagram.png} \caption{Diagramma delle classi del livello di comunicazione: struttura del SignalRHub, definizione del contratto IClient e composizione del DTO Message.} \label{fig:diagramma delle classi SignalRHub} \end{figure}

\subsubsection{Contratti di Interfaccia e Modello Dati}

L'adozione dell'interfaccia \texttt{IClient} rappresenta il punto cardine per la standardizzazione delle operazioni \emph{server-to-client}. Essa definisce formalmente i metodi che il server può invocare sui client connessi, tra cui spicca \texttt{GetMessage}, dedicato alla ricezione dei payload operativi, e \texttt{GetConnectionId}, utilizzato per la sincronizzazione degli identificativi di sessione. Questa astrazione permette di separare nettamente la logica di invio dalla tecnologia di trasporto, rendendo il sistema più manutenibile e trasparente.

Il veicolo informativo tra le parti è rappresentato dal DTO (\emph{Data Transfer Object}) denominato \texttt{Message}. Questa classe è stata progettata come un contenitore semantico flessibile, capace di trasportare l'intero contesto dell'interazione in un'unica struttura dati. Le proprietà \texttt{Action} e \texttt{Name} permettono di determinare l'operazione richiesta (ad esempio la creazione o l'apertura di un elemento), mentre la proprietà \texttt{Route} fornisce un riferimento logico sul percorso del messaggio. Sebbene l'Hub operi principalmente in modalità diffusiva, l'inclusione di metadati come la rotta e i parametri dinamici (\texttt{Params}) assicura che il client ricevente disponga di tutte le informazioni necessarie per elaborare correttamente il comando nel proprio contesto applicativo.

\subsubsection{Orchestrazione dei Messaggi e Gestione della Sessione}

All'interno dell'architettura, la classe \texttt{SignalRHub} assume il ruolo di orchestratore centrale. La sua responsabilità primaria consiste nella gestione dei flussi di messaggi in ingresso e nella loro successiva distribuzione. Attraverso il metodo \texttt{SendMessage}, l'Hub riceve i pacchetti dati e, sfruttando le primitive del framework, ne esegue il broadcasting verso la totalità dei client attivi tramite il metodo \texttt{Clients.All.GetMessage}. Questa logica di propagazione circolare permette di mantenere sincronizzate le diverse istanze del configuratore senza introdurre complessi motori di instradamento intermedi, privilegiando la reattività e la semplicità di flusso.

Oltre allo smistamento dei messaggi, l'Hub facilita lo scambio degli identificativi di connessione tramite il metodo \texttt{SendConnectionId}. Questo passaggio è fondamentale per consentire ai client di conoscersi reciprocamente all'interno della rete di SignalR, ponendo le basi per interazioni mirate. Per quanto riguarda il ciclo di vita delle connessioni, il sistema si affida alle implementazioni standard fornite dalla classe base \texttt{Hub}, che gestisce in modo trasparente l'attivazione e la disattivazione delle sessioni, garantendo stabilità operativa senza la necessità di logiche di monitoraggio personalizzate in questa fase del progetto.

\subsubsection{Infrastruttura di Bootstrap e Configurazione}

L'integrazione del \texttt{SignalRHub} nell'ecosistema dell'applicazione avviene attraverso una configurazione modulare gestita nella classe \texttt{Program}. Seguendo i principi della \emph{Dependency Injection}, i servizi necessari al funzionamento del protocollo vengono registrati all'avvio, permettendo una gestione pulita e centralizzata delle dipendenze.

In questa fase di bootstrap, viene definito l'endpoint dedicato all'Hub e vengono impostate le policy di \emph{Cross-Origin Resource Sharing} (CORS), essenziali per permettere la comunicazione sicura tra il server e i client web. La modularità è ulteriormente supportata da metodi di estensione che preparano l'infrastruttura per future evoluzioni, garantendo che il sistema sia pronto a ospitare strati aggiuntivi di controllo e autorizzazione qualora i requisiti di sicurezza dovessero evolvere verso modelli più complessi.
%----------------------------------------------------------------------------------------
\subsection{Gestione del Ciclo di Vita delle Connessioni}
\label{subsec:lifecycle-connessioni}
%----------------------------------------------------------------------------------------

% Fasi della connessione client-server SignalR:
%
% FASE 1 - NEGOZIAZIONE (HTTP Negotiate):
% - Client SignalR SDK invia HTTP POST a /hub/negotiate
% - Server risponde con:
%   - Connection Token: identificatore univoco negoziazione
%   - Available Transports: lista trasporti supportati [WebSocket, SSE, LongPolling]
%   - Negotiation Version: versione protocollo SignalR
%
% FASE 2 - UPGRADE WEBSOCKET:
% - Se WebSocket supportato, client richiede HTTP Upgrade
% - Header: Connection: Upgrade, Upgrade: websocket
% - Handshake WebSocket (RFC 6455)
% - Server accetta: StatusCode 101 Switching Protocols
% - Connessione TCP persistente stabilita
%
% FASE 3 - REGISTRAZIONE HUB:
% - Server invoca IwineHub.OnConnectedAsync()
% - Hub ottiene ConnectionId dal Context (GUID univoco)
% - Hub invia ConnectionId al client via IClient.GetConnectionId()
% - Client salva ConnectionId per comunicazioni future
%
% FASE 4 - FASE OPERATIVA:
% - Client e server possono scambiare messaggi bidirezionalmente
% - Client invoca metodi hub: SendMessage(message)
% - Server invoca metodi client: Clients.Client(id).GetMessage(message)
% - Keep-alive automatico gestito da SignalR (ping/pong)
%
% FASE 5 - DISCONNESSIONE:
% - Disconnessione può essere:
%   - Esplicita: client chiama connection.stop()
%   - Implicita: timeout, network error, server shutdown
% - Server invoca IwineHub.OnDisconnectedAsync(Exception)
% - Hub rilascia risorse (rimuove da gruppi, cleanup stato)
% - ConnectionId viene invalidato
%
% Stati della connessione (State Machine):
% - Disconnected: stato iniziale, nessuna connessione
% - Connecting: tentativo connessione in corso (timeout 30s)
% - Connected: connessione stabilita, ConnectionId ricevuto
% - Active: stato operativo con sotto-stati:
%   - Idle: pronto per send/receive
%   - Sending: invio messaggio in corso
%   - WaitingACK: attesa conferma server
%   - Receiving: ricezione messaggio in corso
%   - Processing: elaborazione messaggio
%   - Error: errore temporaneo con retry
% - Reconnecting: tentativo riconnessione automatica (max 5 tentativi, backoff esponenziale)
% - Disconnecting: disconnessione in corso
%
% Concetti chiave:
% - Handshake HTTP: negoziazione protocollo e trasporto
% - WebSocket Upgrade: transizione da HTTP a WS
% - ConnectionId: identificatore univoco per routing P2P
% - State Machine: gestione robusta stati connessione
% - Keep-Alive: mantenimento connessione con ping/pong automatici
% - Graceful Shutdown: cleanup risorse in disconnessione
%
% Diagrammi:
% - 02-sequence-connection.md (sequence diagram connessione)
% - 07-state-diagram.md (state machine connessione)
% Pagine stimate: 3-4
La robustezza di un sistema \emph{real-time} dipende in larga misura dalla capacità di gestire in modo deterministico il ciclo di vita delle connessioni client-server. L'architettura progettata adotta un modello a stati finiti per governare ogni fase dell'interazione, dalla negoziazione iniziale fino alla disconnessione controllata, garantendo la coerenza del canale di comunicazione anche in presenza di instabilità di rete.

\subsubsection{Protocollo di Negoziazione e Handshake}

Il processo di connessione segue una sequenza rigorosa, suddivisa in fasi distinte per assicurare la massima compatibilità e sicurezza. La procedura ha inizio con la fase di \textbf{Negoziazione} (\emph{HTTP Negotiate}), durante la quale il client SignalR contatta l'endpoint /hub/negotiate tramite una richiesta HTTP POST standard. In questa fase preliminare, il server non instaura ancora il canale persistente, ma restituisce un \emph{Connection Token} crittografico e un elenco dei trasporti disponibili (WebSocket, SSE, Long Polling), permettendo al client di selezionare la strategia di comunicazione più efficiente supportata dall'ambiente.

Successivamente, se le condizioni lo permettono, avviene l'\textbf{Upgrade del Trasporto}. Il client richiede l'elevazione della connessione tramite l'header \texttt{Upgrade: websocket}, in conformità alla RFC 6455. Il server risponde con lo status \texttt{101 Switching Protocols}, trasformando la connessione HTTP effimera in un tunnel TCP persistente e bidirezionale. A questo punto, il controllo passa al livello applicativo: il server invoca automaticamente l'evento \texttt{OnConnectedAsync} sull'Hub, il quale recupera l'identificativo univoco della sessione (\emph{ConnectionId}) e lo trasmette al client. Questo scambio completa l'handshake, portando il sistema in uno stato pienamente operativo.

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{figures/SequenceDiagramSignalr.png}
  \caption{Diagramma di sequenza del flusso di connessione e messaggistica tra Configurator3D, SignalRHub e SignalRService.}
  \label{fig:sequence-signalr}
\end{figure}

\subsubsection{Macchina a Stati della Connessione}

Per modellare il comportamento dinamico del client, è stata definita una macchina a stati (\emph{State Machine}) che copre l'intero ciclo di vita della sessione. Lo stato iniziale, \textbf{Disconnected}, rappresenta l'assenza di attività. L'invocazione del metodo di avvio innesca la transizione verso lo stato \textbf{Connecting}, durante il quale il sistema tenta di completare l'handshake entro un timeout predefinito (tipicamente 30 secondi).

Il successo della negoziazione porta allo stato \textbf{Connected}, che evolve rapidamente in \textbf{Active}. In questa fase operativa, il client può trovarsi in diversi sotto-stati funzionali: \emph{Idle} (in attesa), \emph{Sending/Receiving} (durante il transito dei messaggi) o \emph{WaitingACK} (in attesa di conferma di ricezione). L'architettura prevede meccanismi di \emph{Keep-Alive} automatici (ping/pong) per monitorare la salute del canale in assenza di traffico dati.


\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{figures/StateDiagram.png}
\caption{Macchina a stati della connessione SignalR: fasi di negoziazione, operatività, riconnessione e disconnessione.}
\label{fig:state-signalr}
\end{figure}

Particolare attenzione è stata posta alla resilienza: in caso di interruzione imprevista del segnale, la macchina a stati transita automaticamente in \textbf{Reconnecting}. Qui, entra in gioco una politica di \emph{Backoff Esponenziale}, che distanzia progressivamente i tentativi di riconnessione (es. 2s, 4s, 8s, fino a 30s) per evitare di sovraccaricare il server in scenari di disservizio diffuso (\emph{thundering herd problem}). Solo dopo il fallimento di tutti i tentativi previsti (configurati a un massimo di 5), il sistema transita definitivamente nello stato \textbf{Disconnected}, notificando l'errore all'applicazione ospite.

Infine, la fase di \textbf{Disconnessione} può essere innescata esplicitamente dal client o implicitamente per timeout. In entrambi i casi, il server esegue una procedura di \emph{Graceful Shutdown}, invocando l'evento \texttt{OnDisconnectedAsync} per rilasciare le risorse allocate, rimuovere l'utente dai gruppi di messaggistica e invalidare il ConnectionId, garantendo la pulizia dello stato globale del sistema.
%----------------------------------------------------------------------------------------
\subsection{Pattern di Comunicazione: Broadcasting e Point-to-Point}
\label{subsec:pattern-comunicazione}
%----------------------------------------------------------------------------------------

% BROADCASTING (Many-to-Many):
%
% Meccanismo:
% - Client mittente invoca SendMessage(message) con Route="/broadcast"
% - Hub valida messaggio (Action valido, Route presente, Params validi)
% - Hub invoca Clients.All.GetMessage(message)
% - SignalR invia messaggio in parallelo a tutti i client connessi
% - Ogni client elabora messaggio indipendentemente
%
% Caratteristiche:
% - Fire-and-forget: mittente non attende conferma riceventi
% - Invio parallelo: tutti i client ricevono simultaneamente
% - Indipendenza: elaborazione autonoma per ogni client
% - No acknowledgment: nessuna garanzia di ricezione/elaborazione
%
% Casi d'uso:
% - Notifiche di sistema (manutenzione, aggiornamenti)
% - Eventi globali (nuovo ordine, cambio stato applicazione)
% - Sincronizzazione dati (cache invalidation)
% - Broadcasting eventi pubblici
%
%
% POINT-TO-POINT (One-to-One):
%
% Meccanismo:
% FASE 1 - Scambio ConnectionId:
% - Client A richiede ConnectionId di Client B
% - Client A invoca SendConnectionId(receiverId: "B", senderId: "A")
% - Hub verifica esistenza Client B nel Context
% - Hub invoca Clients.Client("B").GetConnectionId("A")
% - Client B riceve e salva ConnectionId di A per future comunicazioni
%
% FASE 2 - Invio messaggio diretto:
% - Client A invoca SendMessage(message) con Params.receiverId = "B"
% - Hub estrae receiverId dai Params
% - Hub ottiene proxy Client B dal Context: GetClient(receiverId)
% - Se Client B connesso:
%   - Hub invoca Clients.Client("B").GetMessage(message)
%   - Client B elabora messaggio
%   - Hub risponde a Client A: Delivered (200)
% - Se Client B disconnesso:
%   - Hub risponde a Client A: Client offline (404)
%   - Possibili strategie:
%     - Message Queue: salva in coda per delivery posticipato
%     - Push Notification: notifica via email/push
%     - Retry Logic: tentativo automatico reinvio
%
% Caratteristiche:
% - Bassa latenza: comunicazione diretta senza intermediari
% - Real-time delivery: se entrambi i client online
% - Routing efficiente: server gestisce solo instradamento
% - Acknowledgment opzionale: conferma ricezione se richiesto
%
% Casi d'uso:
% - Chat privata tra utenti
% - Notifiche personali
% - Comandi diretti (MCP → Configurator3D)
% - Sincronizzazione stato tra client specifici
%
% Concetti chiave:
% - Clients.All: broadcasting a tutti i client
% - Clients.Client(connectionId): targeting client specifico
% - Clients.Group(groupName): broadcasting a gruppo
% - ConnectionId Exchange: prerequisito per comunicazione P2P
% - Offline Handling: gestione client disconnessi
% - Parallel Processing: elaborazione concorrente messaggi
%
% Diagrammi:
% - 03-sequence-broadcast.md (sequence diagram broadcasting)
% - 04-sequence-p2p.md (sequence diagram point-to-point)
% Pagine stimate: 3-4
L'infrastruttura di comunicazione real-time è stata progettata per offrire la massima flessibilità, supportando tecnicamente diverse topologie di instradamento dei messaggi. Tuttavia, in relazione agli obiettivi specifici di questa tesi e allo stato attuale del prototipo, è stata operata una precisa scelta implementativa riguardo il pattern di distribuzione dei dati.

\subsubsection{Adozione del Pattern Broadcasting}

Nello scenario operativo corrente, il sistema è stato configurato per utilizzare prevalentemente il pattern di Broadcasting. Tale decisione è giustificata dalla natura sperimentale del progetto, che in questa fase non prevede la gestione concorrente di sessioni multi-utente. Essendo l'interazione limitata a un singolo flusso logico tra il server MCP e l'istanza del configuratore 3D, l'invio indistinto dei messaggi a tutti i client connessi (\emph{fire-and-forget}) rappresenta la soluzione più efficiente e leggera, eliminando l'overhead necessario per la gestione e il tracciamento degli identificativi di sessione.

Come illustrato nel diagramma di sequenza seguente, quando il server necessita di aggiornare la scena grafica, l'Hub propaga l'evento parallelamente sull'intero canale. Il client del configuratore, essendo l'unico attore rilevante in ascolto, intercetta ed elabora il comando in autonomia, garantendo l'immediatezza dell'esecuzione senza richiedere complessi meccanismi di handshake per l'indirizzamento.

 \begin{figure}[ht]
   \centering \includegraphics[width=1\textwidth]{figures/03-sequence-broadcast.png} \caption{Flusso di Broadcasting: propagazione parallela del messaggio (soluzione adottata nel prototipo).} \label{fig:sequence-broadcast}
  \end{figure}

\subsubsection{Predisposizione per la Comunicazione Point-to-Point (P2P)}
Nonostante l'adozione attuale del modello diffusivo, l'architettura dell'\texttt{IwineHub} è stata ingegnerizzata per supportare nativamente anche la comunicazione Point-to-Point (P2P). Questa capacità rappresenta un elemento cruciale per la scalabilità futura del sistema verso scenari di produzione multi-tenant.

Qualora il sistema dovesse evolvere per gestire più progettisti che operano contemporaneamente su configurazioni distinte, il Broadcasting diverrebbe inefficace per problemi di privacy e collisione dei comandi. In tale contesto, l'architettura è già pronta per attivare il routing diretto: sfruttando gli identificativi univoci di sessione (\emph{ConnectionId}) generati da SignalR, l'Hub possiede già le primitive necessarie per creare tunnel di comunicazione privati tra il server e uno specifico client. Questa predisposizione garantisce che il passaggio a un ambiente multi-utente non richiederà una riscrittura del nucleo di comunicazione, ma soltanto l'attivazione di logiche di instradamento mirato già definite nel contratto dell'interfaccia.
\subsection{Flusso di Elaborazione Messaggi}
\label{subsec:flusso-elaborazione}
%----------------------------------------------------------------------------------------

% Pipeline completa di elaborazione messaggi dal client al server:
%
% FASE 1 - CLIENT-SIDE: PREPARAZIONE E INVIO
%
% Serializzazione:
% - Client costruisce oggetto Message {Action, Name, Route, Params}
% - SignalR Client SDK serializza automaticamente in JSON
% - Esempio: {Action: "notifica", Name: "nuovo_ordine", Route: "/orders/broadcast",
%             Params: {orderId: 123, status: "pending"}}
%
% Selezione Trasporto:
% - SignalR sceglie automaticamente miglior trasporto disponibile
% - Ordine preferenza:
%   1. WebSocket (preferito): full-duplex, bassa latenza
%   2. Server-Sent Events: fallback per browser senza WebSocket
%   3. Long Polling: fallback finale per massima compatibilità
% - Trasporto trasparente per sviluppatore
%
%
% FASE 2 - SERVER-SIDE: RICEZIONE E VALIDAZIONE
%
% Deserializzazione:
% - Server riceve payload JSON via trasporto
% - SignalR deserializza automaticamente in oggetto Message
% - Binding automatico delle proprietà (Action, Name, Route, Params)
%
% Validazione:
% - Controlli eseguiti:
%   - Message non null
%   - Action è stringa valida e non vuota
%   - Route presente e ben formata (pattern regex)
%   - Params è oggetto valido (può essere null)
% - Se validazione fallisce:
%   - throw HubException("Invalid message format")
%   - Client riceve errore e può gestirlo
%
%
% FASE 3 - ROUTING DEL MESSAGGIO
%
% Analisi Route:
% - Route Pattern Matching:
%   - /broadcast → Clients.All.GetMessage(message)
%   - /direct/:connectionId → Clients.Client(connectionId).GetMessage(message)
%   - /group/:groupName → Clients.Group(groupName).GetMessage(message)
%
% Estrazione parametri:
% - Da Route: parsing parametri dinamici (es. :connectionId)
% - Da Params: lettura proprietà (es. Params.receiverId)
%
% Verifica destinatari:
% - Per route /direct: verifica esistenza connectionId nel Context
% - Per route /group: verifica esistenza gruppo
% - Se destinatario non trovato: gestione errore (404 o queue)
%
%
% FASE 4 - INVIO E DELIVERY
%
% Invio parallelo (broadcast/group):
% - SignalR utilizza Task.WhenAll per invio concorrente
% - Nessun blocco se un client è lento
% - Fire-and-forget: no attesa conferme
%
% Invio singolo (direct):
% - Invio a client specifico
% - Possibile attesa acknowledgment se implementato
%
%
% FASE 5 - CLIENT-SIDE: RICEZIONE ED ELABORAZIONE
%
% Ricezione evento:
% - Client riceve evento GetMessage tramite handler registrato
% - connection.on("GetMessage", (message) => {...})
%
% Deserializzazione client:
% - SignalR deserializza JSON in oggetto Message
%
% Elaborazione per Action:
% - Switch/dispatch basato su message.Action:
%   - "notifica" → Aggiorna UI, mostra notifica
%   - "message" → Visualizza messaggio in chat
%   - "update" → Aggiorna dati in cache/store
%   - "command" → Esegui comando applicazione (es. open, create)
%
% Acknowledgment (opzionale):
% - Se richiesto, client invia ACK al server
% - await connection.invoke("SendAck", messageId)
%
% Concetti chiave:
% - Serializzazione automatica: trasparente per sviluppatore
% - Transport fallback: robustezza connessione
% - Route-based routing: pattern matching per instradamento
% - Parallel delivery: performance in broadcasting
% - Action-based dispatch: pattern command per elaborazione
% - Optional ACK: conferma ricezione quando necessario
%
% Diagramma: 08-data-flow-diagram.md (flowchart elaborazione completa)
% Pagine stimate: 3-4
L'efficacia dell'architettura real-time proposta risiede nella definizione di una pipeline rigorosa per il trattamento dei dati, che governa l'intero ciclo di vita del messaggio dalla sua genesi sul client fino alla ricezione e all'esecuzione sul destinatario. Questo flusso non si limita al mero trasporto di byte, ma implementa una logica strutturata di trasformazione, validazione e instradamento che garantisce l'integrità semantica delle comunicazioni all'interno del sistema distribuito.

\subsubsection{Origine e Trasmissione: Il Lato Client}

Il processo ha inizio nel livello applicativo del client mittente, dove viene costruito l'oggetto DTO (\emph{Data Transfer Object}) \texttt{Message}. In questa fase, il sistema popola le proprietà fondamentali: l'\texttt{Action}, che definisce l'intento operativo (ad esempio "notifica" o "command"), la \texttt{Route} per l'instradamento, e l'oggetto \texttt{Params} contenente il payload specifico. Una volta invocato il metodo di invio, l'SDK client di SignalR si fa carico delle complessità di basso livello. Il framework serializza automaticamente l'oggetto nel formato concordato (tipicamente JSON) e seleziona in modo trasparente il miglior trasporto disponibile. Questa astrazione permette allo sviluppatore di ignorare i dettagli del protocollo di rete: se l'ambiente lo supporta, il payload viaggia su un canale WebSocket a bassa latenza; in caso contrario, il sistema degrada automaticamente verso Server-Sent Events o Long Polling, garantendo la consegna senza richiedere logiche condizionali nel codice sorgente.

\subsubsection{Ricezione e Validazione Server-Side}

Giunto all'Hub centrale, il messaggio subisce un processo di "ingestione". Il motore di SignalR esegue il \emph{binding} dei dati, deserializzando il payload JSON e ricostruendo l'istanza della classe \texttt{Message} in ambiente .NET. Prima di qualsiasi elaborazione logica, il messaggio viene sottoposto a una validazione formale rigorosa. Il sistema verifica che l'oggetto non sia nullo, che l'azione sia definita e che la rotta rispetti i pattern sintattici previsti. Il fallimento di anche uno solo di questi controlli interrompe immediatamente il flusso, sollevando un'eccezione (\texttt{HubException}) che notifica al mittente l'errore di formato (Bad Request), proteggendo il server dall'elaborazione di dati inconsistenti.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.55\textwidth]{figures/data-flow-diagram.png}
    \caption{Pipeline logica di elaborazione del messaggio: dalla serializzazione all'esecuzione sul client.}
    \label{fig:data-flow-messages}
\end{figure}

\subsubsection{Logica di Routing e Distribuzione}

Superata la validazione, il componente di \emph{Routing Engine} analizza la proprietà \texttt{Route} per determinare la strategia di destinazione. Il sistema supporta un meccanismo di \emph{pattern matching} che distingue tre scenari principali: \begin{enumerate} \item Broadcast (/broadcast): Il messaggio è destinato all'intera platea. Il server utilizza primitive di parallelismo (\texttt{Task.WhenAll}) per inviare il dato simultaneamente a tutti i client connessi, minimizzando la latenza complessiva. \item Direct (/direct/:id): Il sistema estrae l'identificativo del destinatario dai parametri. Viene effettuata una verifica di presenza nel contesto attivo (\emph{Hub Context}): se il client è online, il messaggio viene instradato sul suo canale privato; in caso contrario, possono essere attivate strategie di gestione dell'assenza (come la notifica di errore al mittente).
 \end{enumerate}

\subsubsection{Ricezione ed Esecuzione sul Destinatario}

Il ciclo si conclude sul client ricevente. L'SDK intercetta l'evento di rete e deserializza nuovamente il contenuto in un oggetto JavaScript/TypeScript. Qui entra in gioco un meccanismo di \emph{dispatching} basato sull'azione: uno \emph{switch} logico analizza la proprietà \texttt{Action} e delega l'esecuzione al gestore specifico. Ad esempio, un'azione di tipo "command" potrebbe innescare l'apertura di un modello 3D, mentre una "notifica" si limiterebbe ad aggiornare l'interfaccia utente. Opzionalmente, per operazioni critiche, il protocollo può prevedere un \emph{Acknowledgment} (ACK): terminata l'elaborazione, il client invia un segnale di ritorno al server, confermando l'avvenuto successo dell'operazione e chiudendo la transazione logica.
%----------------------------------------------------------------------------------------
\subsection{Integrazione con l'Architettura MCP}
\label{subsec:integrazione-mcp-signalr}
%----------------------------------------------------------------------------------------

% Collegamento tra bridge SignalR e architettura MCP complessiva:
%
% RUOLO DEL BRIDGE SIGNALR:
% - Layer intermedio tra MCP Server e Configurator3D client
% - Traduzione comandi MCP in messaggi SignalR
% - Gestione comunicazione bidirezionale real-time
% - Notifiche asincrone da client a MCP
%
% FLUSSO DI INTEGRAZIONE:
%
% 1. AI Assistant → MCP Server:
%    - Prompt testuale: "Apri il progetto Cucina Milano"
%    - MCP traduce in tool call: OpenProject(projectName: "Cucina Milano")
%
% 2. MCP Server → SignalRService:
%    - Tool invoca SignalRService.SendMessage()
%    - Costruisce Message: {Action: "open", Name: projectId, Route: "/direct/:connectionId"}
%    - SignalRService invoca IwineHub tramite HubConnection
%
% 3. IwineHub → Configurator3D:
%    - Hub instrada messaggio: Clients.Client(receiverId).GetMessage(message)
%    - Client riceve comando via WebSocket
%    - Client elabora: carica progetto, aggiorna vista 3D
%
% 4. Configurator3D → MCP Server (response):
%    - Client invia risposta: connection.invoke("SendMessage", responseMessage)
%    - IwineHub riceve e instrada a MCP connectionId
%    - SignalRService riceve via handler OnReceiveMessage
%    - MCP tool completa e risponde ad AI Assistant
%
% VANTAGGI DELL'INTEGRAZIONE:
% - Disaccoppiamento: MCP non dipende da dettagli SignalR
% - Real-time: aggiornamenti istantanei senza polling
% - Bidirezionalità: comunicazione full-duplex
% - Scalabilità: SignalR gestisce multiple connessioni
% - Resilienza: riconnessione automatica gestita da SignalRService
%
% CONSIDERAZIONI DI DESIGN:
% - SignalRService come singleton: condiviso tra tutti i tool MCP
% - Message DTO unificato: contratto comune MCP/SignalR/Client
% - ConnectionId mapping: gestione identificatori tra layer
% - Error handling: propagazione errori tra layer
% - Timeout management: gestione timeout operazioni asincrone
%
% Concetti chiave:
% - Bridge Pattern: SignalR come mediatore tra MCP e Client
% - Layered Architecture: separazione responsabilità tra layer
% - Message-Oriented Middleware: comunicazione basata su messaggi
% - Async/Await: gestione operazioni asincrone end-to-end
% - Singleton Service: istanza condivisa SignalRService
%
% Diagrammi: tutti i diagrammi precedenti mostrano aspetti di questa integrazione
% Pagine stimate: 2-3
L'architettura progettata trova la sua concreta realizzazione nel flusso di integrazione che lega il server MCP al client grafico attraverso il bridge SignalR. In questo contesto, il \texttt{SignalRService} non opera più come un componente isolato, ma assume il ruolo di attuatore per gli strumenti (\emph{Tools}) esposti dall'agente di Intelligenza Artificiale. L'obiettivo di questa integrazione è tradurre l'intento semantico dell'utente — espresso in linguaggio naturale — in comandi imperativi che modificano lo stato della scena 3D in tempo reale.

\subsubsection{Il Flusso di Esecuzione End-to-End}Il processo di interazione è stato modellato come un ciclo chiuso (\emph{closed-loop}), essenziale per garantire all'AI il feedback necessario sul completamento delle operazioni. Tale flusso si articola in quattro fasi sequenziali:\begin{enumerate}\item Interpretazione dell'Intento (AI $\rightarrow$ MCP): Il ciclo ha inizio quando l'AI Assistant riceve un prompt testuale, ad esempio "Apri il progetto Cucina Milano". Il server MCP, analizzando la richiesta, identifica la funzione pertinente e la traduce in una chiamata di tool strutturata (es. \texttt{OpenProject}), estraendo i parametri necessari come il nome o l'ID del progetto.\item **Incapsulamento e Dispatch (MCP $\rightarrow$ SignalR):** Il tool invocato non interagisce direttamente con il client, ma delega l'operazione al \texttt{SignalRService}. In questa fase avviene la traduzione dal dominio dell'AI al dominio della messaggistica: il comando viene incapsulato in un oggetto \texttt{Message} (DTO), specificando l'azione (es. "open"), il payload dati e la rotta di destinazione. Essendo il servizio registrato come Singleton, esso garantisce che tutti i tool MCP accedano alla medesima istanza del bridge, mantenendo la coerenza del canale di comunicazione.

\item **Instradamento ed Esecuzione (Hub $\rightarrow$ Client):** L'\texttt{IwineHub} riceve il messaggio e, sfruttando la connessione WebSocket persistente, lo instrada verso il \texttt{Configurator3D}. Il client intercetta il comando, decodifica il payload e innesca le logiche interne di rendering, procedendo al caricamento del modello richiesto e all'aggiornamento della vista grafica.

\item **Feedback Asincrono (Client $\rightarrow$ MCP):** L'ultimo passaggio è cruciale per la sincronizzazione. Una volta completata l'operazione grafica, il client invia un messaggio di risposta verso il server. Il \texttt{SignalRService}, in ascolto tramite i propri handler, intercetta questo feedback e lo restituisce al tool MCP in attesa. Questo permette all'AI Assistant di confermare all'utente l'avvenuto successo dell'operazione ("Ho aperto il progetto Cucina Milano"), chiudendo il cerchio comunicativo.
\end{enumerate}

\subsubsection{Considerazioni di Design per l'Integrazione}La stabilità di questo flusso si basa su specifiche scelte di design volte a mitigare la complessità dei sistemi distribuiti. Un aspetto critico riguarda la gestione del mapping delle connessioni: poiché l'MCP opera in un contesto prevalentemente \emph{stateless} (ogni richiesta è indipendente), è stato necessario implementare logiche per associare correttamente le richieste dell'AI alla specifica connessione SignalR attiva del client grafico, garantendo che i comandi raggiungano l'istanza corretta.Inoltre, l'adozione di un DTO unificato (\texttt{Message}) condiviso trasversalmente tra i layer funge da contratto formale, riducendo i rischi di disallineamento nel formato dei dati. Infine, il sistema integra meccanismi di gestione dei timeout sulle operazioni asincrone: qualora il client 3D non risponda entro una finestra temporale definita (segno di un possibile blocco o disconnessione), il server MCP è programmato per interrompere l'attesa e segnalare un'eccezione all'agente AI, garantendo che il sistema non rimanga in uno stato di attesa indefinita (\emph{deadlock}).
%----------------------------------------------------------------------------------------
\section{Sistema di Autenticazione}
\label{sec:autenticazione}
%----------------------------------------------------------------------------------------

% Modello di autenticazione:
% - User model: Id, Name, Email, Level, Token, Ruoli, Nome, Cognome
% - LoginResponse/LoginData DTO: wrapping risposta API
% - Bearer Token: JWT salvato in campo statico _authToken
% - Metodi: Login, Logout, CheckAuthStatus, AutoLoginIfNeeded
%
% Flusso di autenticazione:
% 1. Ricezione credenziali (user-provided o da config)
% 2. POST /api/login → MarkunoAPI
% 3. Estrazione token da LoginResponse
% 4. Salvataggio in variabile statica per richieste future
% 5. Header "Authorization: Bearer {token}" in chiamate successive
%
% Concetti chiave:
% - Stateful authentication: token in memoria per sessione applicativa
% - Auto-login: credenziali default da appsettings.json
% - Authorization levels: campo Level e Ruoli per permessi
% - Security considerations: gestione scadenza token (401 Unauthorized)
%
% Diagramma: diagram_4_authentication.mmd
% Pagine stimate: 2-3
La sicurezza e l'integrità delle comunicazioni tra il server MCP e il backend gestionale esterno rappresentano un requisito fondamentale dell'architettura. Poiché il sistema è progettato per operare su dati sensibili, quali anagrafiche progetti e cataloghi articoli, è stato implementato un meccanismo di autenticazione robusto basato su standard di settore, capace di garantire che ogni operazione venga eseguita in un contesto autorizzato.

\subsection{Strategia Token-Based}

Il modello di sicurezza adottato si fonda sullo standard JSON Web Token (JWT), scelto per la sua natura \emph{stateless} e per l'ampia interoperabilità in ambienti distribuiti. A differenza delle tradizionali sessioni basate su cookie, che richiedono il mantenimento dello stato lato server, l'approccio JWT delega al client — in questo caso il server MCP — la responsabilità di conservare e presentare le credenziali di accesso sotto forma di \emph{Bearer Token}.

Dal punto di vista della progettazione dei dati, l'interazione con il sistema di identità esterno è mediata da specifici oggetti di trasferimento dati (DTO). In particolare, il sistema non mappa l'intera struttura dell'utente remoto, ma si focalizza sull'incapsulamento della risposta di login (\texttt{LoginResponse}), estraendo e conservando esclusivamente le informazioni necessarie alla persistenza della sessione, ovvero il token di accesso e le eventuali scadenze associate.

Per garantire l'efficienza operativa e ridurre la latenza dovuta a ripetute negoziazioni delle credenziali, il design prevede una gestione della sessione di tipo \emph{stateful} all'interno del ciclo di vita dell'applicazione. Il token, una volta ottenuto, viene persistito in un contesto statico di memoria; questa scelta architetturale permette di riutilizzare il medesimo titolo di accesso per tutte le richieste successive, evitando di dover rieseguire il login per ogni singolo comando impartito dall'agente AI.

\subsection{Flusso di Autenticazione e Auto-Login}

Il processo di autenticazione è stato disegnato per essere trasparente all'utente finale e resiliente agli errori. Il flusso operativo può essere suddiviso in fasi logiche distinte che governano l'acquisizione e l'utilizzo del token.

In fase di avvio (\emph{bootstrap}) o alla prima richiesta operativa, il sistema recupera le credenziali di accesso. Per facilitare l'automazione e il testing, l'architettura supporta un meccanismo di Auto-Login: le credenziali predefinite sono iniettate tramite il file di configurazione (\texttt{appsettings.json}), permettendo al server MCP di autenticarsi autonomamente verso le API esterne senza richiedere un input manuale interattivo. Questa caratteristica è cruciale per scenari \emph{server-to-server} dove non è presente un operatore umano.

Successivamente, il sistema invoca l'endpoint di autenticazione (\texttt{POST /api/login}) del backend gestionale. Alla ricezione di una risposta positiva, il componente logico estrae il JWT dal payload e lo memorizza nella variabile statica dedicata. Da questo momento in poi, ogni chiamata REST effettuata verso il sistema esterno — sia essa la lettura di un progetto o l'inserimento di un articolo — verrà automaticamente arricchita con l'header HTTP \texttt{Authorization}, contenente il \emph{Bearer Token} valido.

Infine, la progettazione ha tenuto conto delle considerazioni di sicurezza relative alla scadenza della sessione. Sebbene il token venga mantenuto in memoria, il sistema deve essere pronto a gestire risposte di errore di tipo \texttt{401 Unauthorized}. In tale eventualità, l'architettura prevede logicamente la necessità di invalidare il token scaduto e innescare una nuova procedura di login, garantendo la continuità del servizio senza interrompere il flusso di lavoro dell'agente intelligente.
%----------------------------------------------------------------------------------------
\section{Gestione Progetti}
\label{sec:gestione-progetti}
%----------------------------------------------------------------------------------------

% Modello dati progetti:
% - Project model: Id, Des, Status, DtCrea, DtMod, Importo, User, Note, dati cliente
% - ProjectsResponse/ProjectsData DTO: wrapping lista progetti
% - ProjectField: metadati campi (Cod, Des, Type, Visible, Sort)
%
% Operazioni CRUD:
% - GetProjects: recupero lista con filtro onlyMy
% - ProjectExists: verifica esistenza per ID o nome (case-insensitive)
% - CreateProject: creazione via SignalR (invia comando al Configurator3D)
% - OpenProject: apertura via SignalR + ricerca per nome
%
% Concetti chiave:
% - Repository Pattern: astrazione accesso dati tramite MarkunoAPI
% - Dual-channel approach: lettura via REST, write operations via SignalR
% - Search flexibility: ricerca case-insensitive per user experience
% - Owner tracking: associazione User ai progetti
%
% Diagramma: diagram_5_projects.mmd
% Pagine stimate: 3-4
La gestione dei progetti rappresenta il cuore del sistema di configurazione. L'architettura deve conciliare due esigenze diverse: da un lato la necessità di accedere ai dati anagrafici memorizzati nel sistema gestionale esterno, dall'altro il bisogno di interagire dinamicamente con l'ambiente grafico 3D. Per risolvere questa sfida, è stata adottata una strategia che separa nettamente il modo in cui i dati vengono letti da come vengono utilizzati.

\subsection*{Modellazione Dati e Accesso tramite Repository}

Il server MCP non possiede un database proprietario per salvare i progetti, ma si comporta come un "proxy" che interroga l'infrastruttura esistente. Per non legare troppo la logica dell'Intelligenza Artificiale ai dettagli tecnici delle API esterne, è stato applicato il Repository Pattern. Questo livello di astrazione permette di nascondere la complessità delle chiamate di rete. In pratica, il codice che gestisce l'AI non deve preoccuparsi di come recuperare i dati, ma interagisce con un modello interno semplificato (\texttt{Project}). Questo modello contiene solo le informazioni essenziali per l'agente, come il codice identificativo, la descrizione e la tipologia, scartando i dettagli superflui presenti nel gestionale.

I dati ricevuti dal sistema esterno vengono uniformati tramite specifici oggetti di trasporto (DTO), come \texttt{ProjectsResponse}. Questo approccio garantisce stabilità: anche se le API esterne dovessero cambiare, la struttura dati interna rimarrebbe coerente. Inoltre, centralizzare l'accesso ai dati facilita l'implementazione di logiche di ricerca flessibili, come la possibilità di cercare un progetto per nome ignorando la differenza tra maiuscole e minuscole.

\subsection*{L'Approccio Dual-Channel}

Una caratteristica distintiva del progetto è l'utilizzo di due canali di comunicazione separati per gestire operazioni di natura diversa. Questo approccio, che possiamo definire Dual-Channel, si struttura così:

\begin{enumerate} \item Canale di Lettura (REST): Viene utilizzato per le operazioni informative, come ottenere la lista dei progetti disponibili tramite \texttt{GetProjects}. Questo garantisce che l'AI abbia sempre una visione aggiornata dei dati presenti nel gestionale. \item Canale di Azione (SignalR): Viene utilizzato per le operazioni che modificano la scena 3D, come l'apertura (\texttt{OpenProject}) o la creazione (\texttt{CreateProject}) di un progetto. \end{enumerate}

Questa distinzione è necessaria perché "aprire un progetto" non significa solo leggere un dato, ma è un comando complesso che obbliga il client grafico a scaricare i modelli 3D e preparare la scena. Il diagramma di sequenza seguente illustra bene questa cooperazione: quando l'utente chiede di aprire un progetto, il sistema usa prima il canale REST per trovare l'ID corretto del progetto, e subito dopo usa il canale SignalR per inviare al client il comando di caricamento visivo.
%----------------------------------------------------------------------------------------
\section{Gestione Articoli e Varianti}
\label{sec:gestione-articoli}
%----------------------------------------------------------------------------------------

% Sistema catalogo prodotti:
% - RuleSetItem model: Cod (parametro), Opz (valore), IsDef, IsLock
% - VariantOptions: Id (catalogo), Name (attributi), Options (mappa chiave-valore)
%
% Operazioni:
% - AddArticle: inserimento articolo + applicazione varianti
% - GetArticleInfo: recupero metadati articolo da catalogo
% - GetVariants: recupero opzioni varianti disponibili
% - SearchCatalogItems: ricerca nel catalogo per categoria/modello
%
% Flusso complesso AddArticle (pattern GET-MODIFY-SAVE):
% 1. POST /muconf/radd → inserimento articolo base, riceve rowId
% 2. POST /muconf/rget → recupero stato corrente con campo "pars"
% 3. Modifica locale campo pars applicando ruleset
% 4. POST /muconf/rsave → salvataggio pars modificato
% 5. Notifica client 3D via SignalR
%
% Concetti chiave:
% - Command Pattern: operazioni come AddArticle wrappate in tool MCP
% - GET-MODIFY-SAVE Pattern: lettura → modifica locale → scrittura
% - Configuration system: ruleset per parametrizzazione articoli
% - Catalog abstraction: separazione catalogo prodotti da logica business
%
% Diagramma: diagram_6_articles_variants.mmd
% Pagine stimate: 4-5
Il dominio della configurazione di prodotto non si esaurisce nella semplice selezione di un oggetto da un catalogo, ma richiede un sistema sofisticato per la gestione delle varianti e delle regole di compatibilità. La progettazione del modulo di gestione articoli è stata quindi guidata dalla necessità di astrarre la complessità del sistema gestionale sottostante, offrendo all'agente AI un'interfaccia semplificata per la manipolazione di entità complesse.

\subsection*{Modellazione delle Varianti e Astrazione del Catalogo}

Al centro del design dei dati si colloca la definizione di modelli capaci di rappresentare la variabilità del prodotto. Poiché un articolo può assumere configurazioni differenti in base a finiture, dimensioni o accessori, il sistema adotta il modello \texttt{RuleSetItem} per mappare puntualmente queste specifiche. Ogni istanza di questa classe associa un codice parametro (ad esempio, il tipo di struttura) al valore dell'opzione selezionata, includendo metadati di controllo quali \texttt{IsDef}, per identificare le configurazioni predefinite, e \texttt{IsLock}, per gestire vincoli di immodificabilità imposti dalle logiche di business.

Parallelamente, la classe \texttt{VariantOptions} funge da descrittore per l'esplorazione delle possibilità offerte dal catalogo. Essa incapsula le mappe chiave-valore delle opzioni disponibili per un dato modello, permettendo al sistema di interrogare il gestionale e restituire all'utente (o all'agente intelligente) l'elenco delle personalizzazioni ammissibili. Questa struttura disaccoppia la rappresentazione interna dei dati dalla logica di persistenza, garantendo che le operazioni di ricerca (\texttt{SearchCatalogItems}) e di recupero metadati (\texttt{GetArticleInfo}) operino su DTO (\emph{Data Transfer Objects}) standardizzati e indipendenti dalle specificità del database fisico.

\begin{figure}[H] \centering \includegraphics[width=\textwidth]{figures/GestioneArticolivarianti.png} \caption{Diagramma delle classi per la gestione articoli: interazione tra i tool MCP e le primitive del gestionale esterno.} \label{fig:diagram-articles} \end{figure} % -----------------------------

\subsection*{Il Pattern Transazionale di Configurazione}

L'aspetto più critico nella progettazione di questo modulo risiede nel flusso operativo per l'inserimento di un nuovo articolo configurato (\texttt{AddArticle}). A differenza di una classica operazione CRUD atomica, la natura del configuratore richiede un approccio sequenziale che garantisca la consistenza dello stato tra il server MCP e il motore di regole del gestionale. Per rispondere a questa esigenza, è stato adottato il pattern architetturale GET-MODIFY-SAVE.

Questo schema operativo, illustrato logicamente nel Diagramma 6, scompone l'inserimento di un prodotto in una transazione a più fasi, necessaria per applicare correttamente il \emph{RuleSet}:

\begin{enumerate} \item Istanziazione (Insertion): Il processo inizia con la richiesta di inserimento dell'articolo base tramite la primitiva \texttt{radd}. In questa fase, il sistema esterno alloca la riga d'ordine e restituisce un identificativo univoco, ma l'articolo si trova ancora nel suo stato predefinito (default). \item Acquisizione dello Stato (Retrieval): Immediatamente dopo, il sistema effettua una lettura dello stato corrente dell'oggetto appena creato tramite \texttt{rget}. Questo passaggio è fondamentale per ottenere la stringa di configurazione (identificata come campo \emph{pars}) che contiene l'attuale assetto delle varianti calcolato dal motore di regole. \item Manipolazione Locale (Modification): Il server MCP interviene sulla configurazione recuperata, applicando le modifiche richieste dal prompt dell'utente (il \emph{RuleSet}). Questa operazione avviene in memoria, modificando puntualmente i valori dei parametri senza ancora interagire con il database. \item Persistenza e Sincronizzazione (Commit): Infine, lo stato modificato viene inviato al sistema tramite \texttt{rsave} per la persistenza definitiva. Solo al termine di questo ciclo di scrittura, il sistema notifica l'avvenuto aggiornamento al client grafico tramite SignalR, garantendo che la visualizzazione 3D rifletta esattamente la configurazione validata dal backend. \end{enumerate}

L'adozione del Command Pattern per incapsulare questa logica complessa all'interno del metodo \texttt{AddArticle} permette di esporre all'AI un unico punto di ingresso (un singolo "Tool"), mascherando l'orchestrazione delle chiamate sottostanti e garantendo l'integrità referenziale della configurazione finale.
%----------------------------------------------------------------------------------------
\section{Protocollo di Messaggistica SignalR}
\label{sec:protocollo-messaggistica}
%----------------------------------------------------------------------------------------

% Struttura messaggi:
% - Message model: Action, Name, Route, Params
% - Azioni supportate: open, create, list_elements, add_article
%
% Comunicazione bidirezionale:
% - Server → Client: SendHubMessage invia comandi al Configurator3D
% - Client → Server: ListElements richiede dati, GetLastListElements recupera risposta
% - Handler registration: EnsureListElementsHandlerRegistered per callback
%
% Concetti chiave:
% - Command Pattern: action come discriminante operazione
% - Request-Response pattern: messaggi con risposta asincrona
% - Event-driven architecture: handler registrati per messaggi specifici
% - Payload caching: _lastListElementsPayload per recupero differito
%
% Diagramma: diagram_7_signalr_messages.mmd
% Pagine stimate: 3-4
La robustezza dell'interazione tra il server centrale e il client grafico dipende dalla definizione di un protocollo di comunicazione rigoroso, capace di astrarre la complessità del trasporto dati e di standardizzare le interazioni. Anziché definire endpoint multipli e frammentati per ogni singola funzionalità, il design del sistema converge su un unico modello di scambio dati, il \texttt{Message}, che agisce come veicolo universale per tutte le transazioni all'interno del canale SignalR.

\subsection{Semantica dei Messaggi e Command Pattern}

Il cuore del protocollo risiede nella struttura semantica del messaggio, concepita per implementare il \textbf{Command Pattern}. In questo contesto, l'oggetto trasferito non rappresenta solamente un payload di dati, ma incapsula un'intenzione operativa specifica. La proprietà \texttt{Action} assume il ruolo di discriminante fondamentale: essa istruisce il ricevente sulla logica da attivare, distinguendo tra i diversi comandi di modifica dello stato (come \texttt{open}, \texttt{create} o \texttt{add\_article}).

Questa impostazione garantisce un elevato disaccoppiamento tra le parti. Il server può inviare parametri complessi tramite l'oggetto generico \texttt{Params} e specificare il contesto dell'operazione tramite \texttt{Name} e \texttt{Route}, senza che il livello di trasporto debba conoscere i dettagli implementativi della logica di business. Tale flessibilità permette di estendere le funzionalità del sistema — aggiungendo ad esempio nuove azioni per la manipolazione della scena — senza dover alterare la firma dei metodi dell'Hub o la struttura del protocollo sottostante.

\subsection{Orchestrazione dei Comandi Server-Side}

Nel contesto dell'integrazione con l'architettura MCP, il flusso di comunicazione predominante è quello **Server-verso-Client**. Il server assume il ruolo di orchestratore, traducendo gli intenti dell'agente AI in direttive esecutive per il visualizzatore grafico.

L'invio dei comandi è centralizzato nel metodo \texttt{SendHubMessage}, che agisce come unico punto di uscita verso il client connesso. In questo scenario, il modello di comunicazione è prettamente imperativo: il server invia un pacchetto contenente l'azione e i parametri necessari (ad esempio, l'ID di un progetto da aprire o il codice di un articolo da inserire), e il client grafico agisce come esecutore passivo, aggiornando il rendering in risposta allo stimolo ricevuto.

Sebbene l'architettura SignalR supporti nativamente la bidirezionalità, nel design attuale questa capacità è riservata principalmente al feedback di stato (Acknowledgment). Il client, una volta completata l'operazione grafica richiesta (che potrebbe richiedere tempi non trascurabili per il caricamento degli asset), può notificare al server l'avvenuta esecuzione, chiudendo il cerchio logico dell'operazione senza necessitare di complessi meccanismi di interrogazione sincrona dello stato client-side.

\section{Flussi di Lavoro Principali}
\label{sec:flussi-lavoro}
%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------
\subsection{Caso d'Uso: Login e Recupero Progetti}
\label{subsec:login-progetti}
%----------------------------------------------------------------------------------------

% Flusso autenticazione:
% - Fase 1: Login (username/password → POST /api/login → salva token)
% - Fase 2: GetProjects (usa token → POST /muconf/plist → lista progetti)
% - AutoLogin: uso credenziali default se omesse
% - Gestione errori: 401 Unauthorized se token scaduto
%
% Concetti chiave:
% - Stateful session: token JWT persistente in memoria
% - Default credentials: facilitazione testing/sviluppo
% - Bearer authentication: standard HTTP per REST API
%
% Diagramma: sequence_1_login_getprojects.mmd
% Pagine stimate: 2

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/LogineRecuperoProgetti.png}
    \caption{Diagramma di sequenza del flusso di autenticazione e recupero progetti: gestione intelligente del token e delle credenziali.}
    \label{fig:sequence-login-simplified}
\end{figure}

Il primo diagramma di sequenza illustra l'orchestrazione fondamentale delle interazioni tra l'agente AI e il sistema gestionale esterno, delineando due macro-fasi operative: l'autenticazione iniziale e il successivo accesso alle risorse.

La prima fase descrive il processo di login, caratterizzato da una logica di flessibilità operativa. Il sistema è progettato per gestire sia l'inserimento esplicito delle credenziali da parte dell'utente sia, in loro assenza, il recupero automatico dei parametri di accesso predefiniti dai file di configurazione. Una volta inviata la richiesta al backend remoto e ottenuta una risposta positiva, il token di sicurezza (JWT) viene estratto e persistito in una variabile statica. Questa scelta architetturale garantisce il mantenimento della sessione per le operazioni future, riducendo la necessità di autenticazioni ridondanti. Parallelamente, il successo dell'operazione viene notificato al servizio di comunicazione in tempo reale.

La seconda parte del diagramma espone il flusso di recupero dell'elenco progetti. Prima di interrogare l'API esterna, il modulo verifica preventivamente la validità del token di autenticazione, innescando una procedura di rinnovo automatico qualora questo risultasse assente o scaduto. La richiesta viene quindi inoltrata corredata dagli header di autorizzazione necessari; la risposta grezza fornita dal server viene infine deserializzata e mappata in una struttura dati semplificata, ottimizzata per essere elaborata dall'assistente intelligente. Il diagramma evidenzia inoltre la gestione degli scenari di errore, come credenziali invalide o sessioni scadute, garantendo che l'agente riceva sempre un feedback coerente sullo stato dell'operazione.

%----------------------------------------------------------------------------------------
\subsection{Caso d'Uso: Creazione e Apertura Progetto}
\label{subsec:creazione-apertura-progetto}
%----------------------------------------------------------------------------------------

% Flusso creazione progetto:
% - CreateProject: costruisce Message {action: "create", params: {des, note, open}}
% - Invio via SignalR → Configurator3D mostra dialog pre-compilato
% - Client conferma → POST /muconf/pcreate lato client
% - Opzionale: apertura automatica se open=true
%
% Flusso apertura progetto:
% - OpenProject: ricerca progetto per nome (case-insensitive)
% - Costruisce Message {action: "open", name: projectId}
% - Invio via SignalR → Client carica geometrie 3D
%
% Concetti chiave:
% - Dual-channel orchestration: REST per query, SignalR per comandi
% - User experience: pre-compilazione form, feedback immediato
% - Case-insensitive search: robustezza ricerca
% - Error handling: progetto non trovato, SignalR offline
%
% Diagramma: sequence_2_create_open_project.mmd
% Pagine stimate: 2-3
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/CreazioneeAperturaProgetto.png}
    \caption{Diagramma di sequenza del flusso di creazione e apertura progetto: orchestrazione tra API REST e canale SignalR.}
    \label{fig:sequence-create-open}
\end{figure}
Il secondo diagramma di sequenza approfondisce le dinamiche di interazione mista che caratterizzano le operazioni di modifica della scena. A differenza del semplice recupero dati, queste procedure richiedono un'orchestrazione sincrona tra il livello API (per il recupero delle informazioni) e il canale Real-Time (per l'attuazione dei comandi sul client).

La prima sezione illustra la creazione di un progetto: l'operazione è modellata come un comando push verso il configuratore. Il server MCP non crea direttamente il record nel database, ma istruisce il client grafico — tramite un messaggio strutturato veicolato dal bridge SignalR — affinché presenti all'utente una maschera di creazione precompilata. Questo approccio delega la responsabilità della persistenza finale al client, mantenendo il server MCP nel ruolo di "pilota" remoto.

La seconda sezione descrive l'apertura di un progetto esistente, evidenziando la necessità di una fase preliminare di risoluzione. Poiché l'utente umano tende a riferirsi ai progetti per nome (es. "Cucina Milano"), mentre il sistema richiede identificativi numerici univoci, il server MCP esegue preventivamente una query di ricerca sulle API esterne. Una volta risolto l'ID corretto, viene inviato il comando di apertura al client 3D, il quale si fa carico autonomamente del recupero degli asset pesanti (modelli 3D, texture) e del rendering della scena, confermando al termine il successo dell'operazione.


%---------------
\subsection{Caso d'Uso: Aggiunta Articolo con Varianti}
\label{subsec:aggiunta-articolo}
%----------------------------------------------------------------------------------------

% Flusso completo in 3 fasi:
%
% FASE 1 - Inserimento articolo base:
% - Verifica autenticazione (AutoLoginIfNeeded se necessario)
% - Prepara body JSON con cod, des, cat, model, catmer, dimensioni (l, a, p)
% - POST /muconf/radd → riceve rowId
%
% FASE 2 - Applicazione varianti (se ruleset presente):
% - Step 2.1 GET: POST /muconf/rget per recuperare campo "pars" corrente
% - Step 2.2 MODIFY: applica ruleset modificando pars locale
%   (Esempio: pars["str"] = "c.01" (colore bianco), pars["fin"] = "m.02" (finitura rovere))
% - Step 2.3 SAVE: POST /muconf/rsave con pars modificato
%
% FASE 3 - Notifica Client 3D (se receiverId fornito):
% - CallHubMethodAsync("SendMessage", receiverId, {action: "open", name: projectId})
% - Client riceve notifica → GET /muconf/pget → aggiorna vista 3D
% - Renderizza nuovo articolo con varianti applicate
%
% Concetti chiave:
% - GET-MODIFY-SAVE Pattern: operazione atomica in 3 step
% - Parametric configuration: ruleset per personalizzazione articoli
% - Real-time sync: notifica immediata al client 3D
% - Graceful degradation: articolo inserito anche se varianti falliscono
%
% Diagrammi: diagram_8_sequence_add_article.mmd, sequence_3_add_article_variants.mmd
% Pagine stimate: 2-3
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/AggiuntaArticoloconVarianti.png}
    \caption{Diagramma di sequenza del flusso di aggiunta di un articolo con una variante.}
    \label{fig:sequence-add-article}
\end{figure}

Il terzo diagramma di sequenza analizza la complessità transazionale legata all'inserimento di un prodotto configurabile. A differenza di una scrittura atomica, questa operazione impone un'orchestrazione a più fasi per garantire l'applicazione corretta delle varianti (il Ruleset).

Dopo una verifica preliminare della sessione di autenticazione, il sistema procede con l'inserimento dell'articolo "neutro" tramite le API del backend gestionale. Ottenuto l'identificativo univoco della riga generata (rowId), il flusso logico valuta la presenza di regole di configurazione. Se presenti, viene attivato il pattern Get-Modify-Save: il tool recupera lo stato di configurazione predefinito dal server remoto, lo elabora in memoria applicando le varianti richieste dall'agente AI e lo persiste nuovamente sul database. Il ciclo si conclude con la fase di sincronizzazione visiva: il server invia un comando via SignalR al client 3D, innescando l'aggiornamento della scena affinché l'utente possa visualizzare immediatamente il nuovo elemento con le finiture applicate.
%----------------------------------------------------------------------------------------
\subsection{Caso d'Uso: Comunicazione Bidirezionale}
\label{subsec:comunicazione-bidirezionale}
%----------------------------------------------------------------------------------------

% Flusso full-duplex:
%
% Request (AI → Client):
% - ListElements: costruisce Message {action: "list_elements", params: {catalogo, cerca}}
% - Invio via CallHubMethodAsync → Client esegue ricerca nel catalogo
%
% Response (Client → AI):
% - Client invia risposta: SendMessage con action="list_elements" e params=array risultati
% - Handler ReceiveMessage attivato → salva payload in _lastListElementsPayload
% - GetLastListElements recupera risultati salvati
%
% Gestione disconnessione/riconnessione:
% - Evento Closed: _isConnected = false, logging
% - Auto-reconnect SignalR: tentativi automatici con retry intervals
%
% Concetti chiave:
% - Full-duplex communication: bidirezionalità WebSocket
% - Observer Pattern: callback per messaggi in arrivo
% - Asynchronous request-response: richiesta e risposta disaccoppiate
% - Connection resilience: auto-reconnect per continuità servizio
%
% Diagramma: sequence_4_signalr_bidirectional.mmd
% Pagine stimate: 2

%----------------------------------------------------------------------------------------
\subsection{Caso d'Uso: Gestione Errori}
\label{subsec:gestione-errori}
%----------------------------------------------------------------------------------------

% Scenari di errore gestiti:
%
% 1. Token scaduto (401 Unauthorized):
%    - Detect error 401 → messaggio "Token scaduto, effettua nuovo login"
%    - User experience: hint per azione correttiva
%
% 2. Progetto non trovato:
%    - FirstOrDefault() → null → response con availableProjects (primi 10)
%    - Hint: "Usa GetProjects per lista completa"
%
% 3. SignalR offline:
%    - IsConnected = false → error "SignalR non connesso"
%    - Hint: "Verifica con CheckSignalRStatus()"
%
% 4. Errore validazione API (400 Bad Request):
%    - Parse error response → extract validCategories/availableParams
%    - Hint: "Usa SearchCatalogItems per categorie valide"
%
% 5. Errore applicazione varianti:
%    - Articolo inserito ma rsave fallisce → response parziale
%    - {success: true, variantsApplied: false, variantsError: "..."}
%
% 6. Network timeout:
%    - TaskCanceledException dopo 30s → error "Request timeout"
%    - Hint: "Riprova o verifica connettività"
%
% Concetti chiave:
% - Defensive programming: validazione input, gestione eccezioni
% - Meaningful error messages: descrizione errore + hint azione correttiva
% - Partial success handling: operazioni atomiche con fallback
% - User-friendly feedback: error messages comprensibili per AI Assistant
%
% Diagramma: sequence_5_error_handling.mmd
% Pagine stimate: 2
Un aspetto cruciale nella progettazione di un sistema destinato all'interazione con agenti di Intelligenza Artificiale è la qualità del feedback in caso di errore. A differenza di un'interfaccia grafica tradizionale, dove l'utente umano può intuire il problema dal contesto, un agente AI necessita di messaggi di errore strutturati e "azionabili" (actionable) per poter tentare strategie di recupero autonomo. L'architettura proposta implementa una strategia di gestione delle eccezioni divisa in due livelli: la gestione delle anomalie infrastrutturali e la validazione della logica di business.

\subsubsection{Gestione delle Anomalie Infrastrutturali}

\begin{figure}[H]
\centering \includegraphics[width=0.9\textwidth]{figures/sequence_error_infrastructure} \caption{Gestione degli errori infrastrutturali: scadenza token e indisponibilità del servizio SignalR.} \label{fig:seq-error-infra}
\end{figure}
Il primo livello di difesa riguarda la stabilità del canale di comunicazione. Poiché il sistema dipende da token di sessione volatili e da connessioni WebSocket persistenti, è fisiologico che possano verificarsi interruzioni di servizio. Il diagramma seguente illustra due scenari critici: \begin{enumerate} \item Scadenza della Sessione: Se il token di sicurezza scade durante l'operatività, il middleware intercetta l'errore HTTP 401 e restituisce all'agente non un semplice fallimento, ma un suggerimento esplicito per effettuare il rinnovo delle credenziali. \item Indisponibilità del Canale Real-Time: Prima di inviare comandi grafici, il sistema verifica proattivamente lo stato del bridge SignalR. Se il servizio non è raggiungibile, l'operazione viene abortita preventivamente, evitando di lasciare l'AI in attesa di un feedback che non arriverebbe mai. \end{enumerate}



\subsubsection{Validazione Logica e Integrità dei Dati}

\begin{figure}[H] \centering \includegraphics[width=0.9\textwidth]{figures/sequence_error_logic} \caption{Gestione degli errori logici: entità non trovate e fallimenti parziali nella configurazione.} \label{fig:seq-error-logic} \end{figure}

Il secondo livello di gestione riguarda la coerenza semantica delle richieste. Quando l'agente AI tenta di operare su entità inesistenti o fornisce parametri non conformi alle regole del configuratore, il sistema risponde con errori arricchiti di metadati contestuali.

Il diagramma successivo evidenzia come il sistema guidi l'agente verso la correzione dell'errore: \begin{enumerate} \item Gestione "Not Found": Nel caso di ricerca di un progetto inesistente, il sistema non si limita a restituire un codice 404, ma fornisce una lista parziale di progetti validi simili, permettendo all'LLM di correggere eventuali errori di "allucinazione" sul nome. \item Fallimenti Parziali (Partial Success): Uno scenario complesso riguarda l'inserimento di articoli con varianti invalide. In questo caso, il sistema adotta una politica di best-effort: l'articolo base viene inserito correttamente, ma l'applicazione delle varianti errate viene segnalata come warning. Questo approccio evita il rigetto totale di operazioni lunghe e costose, informando puntualmente l'agente su quale specifico parametro ha causato l'anomalia. \end{enumerate}

\chapter{Implementazione}
\label{chap:implementazione}
%----------------------------------------------------------------------------------------

% Questo capitolo descrive gli aspetti implementativi concreti del sistema,
% includendo scelte tecnologiche, snippet di codice significativi, configurazioni,
% e dettagli tecnici delle implementazioni dei componenti progettati nel capitolo precedente.

%----------------------------------------------------------------------------------------
\section{Ambiente di Sviluppo e Setup Progetto}
\label{sec:ambiente-sviluppo}
%----------------------------------------------------------------------------------------

% STACK TECNOLOGICO:
% - .NET 8.0 SDK (target framework)
% - C# 12 (linguaggio principale)
% - ASP.NET Core 8.0 (per IwineHub SignalR server)
% - Visual Studio 2022 / VS Code (IDE)
% - Git (version control)
%
% DIPENDENZE NUGET PRINCIPALI:
%
% MCP Server:
% - ModelContextProtocol (SDK MCP ufficiale)
% - Microsoft.AspNetCore.SignalR.Client (client SignalR)
% - System.Text.Json (serializzazione JSON)
% - Microsoft.Extensions.DependencyInjection (DI container)
% - Microsoft.Extensions.Logging (logging)
% - Microsoft.Extensions.Configuration (gestione configurazione)
%
% SignalR Bridge Server:
% - Microsoft.AspNetCore.SignalR (server SignalR)
% - Microsoft.AspNetCore.Authentication.JwtBearer (autenticazione JWT)
% - Microsoft.AspNetCore.Cors (gestione CORS)
%
% Configurator3D Client:
% - @microsoft/signalr (JavaScript/TypeScript client)
% - TypeScript 5.x (type-safety)
%
% STRUTTURA PROGETTO:
% ```
% MarkunoMCP/
% ├── MarkunoApiTools/          # MCP Server principale
% │   ├── Program.cs             # Entry point e configurazione
% │   ├── MarkunoApiTools.cs     # Tool MCP implementation
% │   ├── Models/                # DTO e modelli dati
% │   │   ├── User.cs
% │   │   ├── Project.cs
% │   │   ├── Message.cs
% │   │   └── RuleSetItem.cs
% │   ├── Services/              # Servizi
% │   │   └── SignalRService.cs
% │   └── appsettings.json       # Configurazione
% │
% ├── IwineSignalRServer/        # Bridge SignalR
% │   ├── Program.cs             # ASP.NET Core setup
% │   ├── Hubs/
% │   │   └── IwineHub.cs        # Hub SignalR principale
% │   ├── Interfaces/
% │   │   └── IClient.cs         # Strongly-typed client interface
% │   └── appsettings.json
% │
% └── Configurator3D/            # Client grafico 3D
%     ├── src/
%     │   ├── signalr-client.ts  # Client SignalR
%     │   └── message-handler.ts # Handler messaggi
%     └── package.json
% ```
%
% CONFIGURAZIONE APPSETTINGS.JSON:
% ```json
% {
%   "MarkunoApi": {
%     "BaseUrl": "https://api.markuno.com",
%     "DefaultUser": "admin",
%     "DefaultPassword": "***"
%   },
%   "SignalR": {
%     "HubUrl": "https://localhost:7193",
%     "AllowInsecureCertificates": true
%   },
%   "Logging": {
%     "LogLevel": {
%       "Default": "Information",
%       "Microsoft.AspNetCore.SignalR": "Debug"
%     }
%   }
% }
% ```
%
% SETUP AMBIENTE SVILUPPO:
% 1. Installazione .NET 8.0 SDK
% 2. Clone repository Git
% 3. Restore dipendenze NuGet: dotnet restore
% 4. Configurazione certificati SSL sviluppo: dotnet dev-certs https --trust
% 5. Setup appsettings.Development.json con credenziali locali
% 6. Avvio SignalR server: dotnet run --project IwineSignalRServer
% 7. Avvio MCP server: dotnet run --project MarkunoApiTools
%
% Concetti chiave:
% - Multi-project solution: separazione MCP server e SignalR bridge
% - Configuration management: appsettings per ambiente
% - Dependency management: NuGet per pacchetti .NET
% - SSL/TLS: certificati sviluppo per HTTPS/WSS
%
% Pagine stimate: 3-4

%----------------------------------------------------------------------------------------
\section{Implementazione MCP Server Core}
\label{sec:implementazione-mcp-core}
%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------
\subsection{Bootstrap e Dependency Injection}
\label{subsec:bootstrap-di}
%----------------------------------------------------------------------------------------

% PROGRAM.CS - Entry Point:
%
% ```csharp
% var builder = WebApplication.CreateBuilder(args);
%
% // Caricamento configurazione
% builder.Configuration
%     .AddJsonFile("appsettings.json", optional: false)
%     .AddJsonFile($"appsettings.{builder.Environment.EnvironmentName}.json", optional: true)
%     .AddEnvironmentVariables();
%
% // Registrazione servizi
% builder.Services.AddSingleton<SignalRService>();
% builder.Services.AddHttpClient<MarkunoApiTools>();
% builder.Services.AddLogging(config => {
%     config.AddConsole();
%     config.AddDebug();
% });
%
% // Configurazione MCP
% builder.Services.AddMcp(options => {
%     options.ServerInfo = new ServerInfo {
%         Name = "markuno-mcp-server",
%         Version = "1.0.0"
%     };
% });
%
% var app = builder.Build();
%
% // Avvio SignalR connection in background
% var signalRService = app.Services.GetRequiredService<SignalRService>();
% await signalRService.ConnectAsync();
%
% // Registrazione tool MCP
% app.MapMcpTool<MarkunoApiTools>();
%
% await app.RunAsync();
% ```
%
% DEPENDENCY INJECTION PATTERN:
% - Singleton per SignalRService: istanza condivisa tra tool
% - HttpClient factory: gestione pool connessioni HTTP
% - ILogger injection: logging strutturato per ogni componente
% - IConfiguration injection: accesso configurazione type-safe
%
% LIFECYCLE MANAGEMENT:
% - Application startup: avvio connessione SignalR
% - Graceful shutdown: disconnessione pulita SignalR
% - Background services: keep-alive SignalR connection
%
% Concetti chiave:
% - Dependency Injection Container: Microsoft.Extensions.DI
% - Configuration providers: JSON, environment variables
% - Logging abstraction: ILogger<T> per ogni classe
% - Service lifetimes: Singleton, Scoped, Transient
%
% Pagine stimate: 2-3

%----------------------------------------------------------------------------------------
\subsection{Implementazione Tool MCP}
\label{subsec:implementazione-tool}
%----------------------------------------------------------------------------------------

% STRUTTURA CLASSE MARKUNOAPITOOLS:
%
% ```csharp
% public class MarkunoApiTools : McpToolsBase
% {
%     private readonly HttpClient _httpClient;
%     private readonly SignalRService _signalRService;
%     private readonly ILogger<MarkunoApiTools> _logger;
%     private readonly IConfiguration _config;
%
%     private static string? _authToken;
%     private static User? _currentUser;
%
%     public MarkunoApiTools(
%         HttpClient httpClient,
%         SignalRService signalRService,
%         ILogger<MarkunoApiTools> logger,
%         IConfiguration config)
%     {
%         _httpClient = httpClient;
%         _signalRService = signalRService;
%         _logger = logger;
%         _config = config;
%
%         // Configura HttpClient base address
%         var baseUrl = _config["MarkunoApi:BaseUrl"];
%         _httpClient.BaseAddress = new Uri(baseUrl);
%     }
%
%     [McpTool("login", "Autentica utente e ottiene token JWT")]
%     public async Task<string> Login(
%         [McpParameter("username")] string? username = null,
%         [McpParameter("password")] string? password = null)
%     {
%         // Usa credenziali da config se non fornite
%         username ??= _config["MarkunoApi:DefaultUser"];
%         password ??= _config["MarkunoApi:DefaultPassword"];
%
%         var loginRequest = new { name = username, password };
%         var response = await _httpClient.PostAsJsonAsync("/api/login", loginRequest);
%
%         if (!response.IsSuccessStatusCode)
%         {
%             return JsonSerializer.Serialize(new {
%                 success = false,
%                 error = "Login fallito",
%                 statusCode = (int)response.StatusCode
%             });
%         }
%
%         var loginResponse = await response.Content.ReadFromJsonAsync<LoginResponse>();
%         _authToken = loginResponse?.Data?.User?.Token;
%         _currentUser = loginResponse?.Data?.User;
%
%         _logger.LogInformation("Login effettuato per utente {Username}", username);
%
%         return JsonSerializer.Serialize(new {
%             success = true,
%             username = _currentUser?.Name,
%             userId = _currentUser?.Id,
%             level = _currentUser?.Level
%         });
%     }
%
%     private async Task EnsureAuthenticatedAsync()
%     {
%         if (string.IsNullOrEmpty(_authToken))
%         {
%             await Login();
%         }
%     }
%
%     private void AddAuthHeader()
%     {
%         if (!string.IsNullOrEmpty(_authToken))
%         {
%             _httpClient.DefaultRequestHeaders.Authorization =
%                 new AuthenticationHeaderValue("Bearer", _authToken);
%         }
%     }
% }
% ```
%
% ATTRIBUTI MCP:
% - [McpTool]: marca metodi come tool esposti all'AI
% - [McpParameter]: definisce parametri con descrizione
% - Metadata per discovery automatico tool
%
% GESTIONE AUTENTICAZIONE:
% - Token JWT in variabile statica (_authToken)
% - User corrente in variabile statica (_currentUser)
% - Auto-login con credenziali default
% - Header Authorization automatico per richieste HTTP
%
% PATTERN ASYNC/AWAIT:
% - Tutti i metodi tool sono async Task<string>
% - HttpClient async per chiamate REST API
% - SignalRService async per comunicazione real-time
%
% Concetti chiave:
% - Attribute-based programming: metadata per tool MCP
% - Static state: token condiviso tra invocazioni tool
% - Async programming: operazioni I/O non bloccanti
% - HttpClient patterns: gestione pool connessioni
%
% Pagine stimate: 3-4

%----------------------------------------------------------------------------------------
\subsection{Implementazione Tool Complessi}
\label{subsec:tool-complessi}
%----------------------------------------------------------------------------------------

% ESEMPIO: IMPLEMENTAZIONE AddArticle CON PATTERN GET-MODIFY-SAVE
%
% ```csharp
% [McpTool("add_article", "Aggiunge articolo con varianti al progetto")]
% public async Task<string> AddArticle(
%     [McpParameter("projectId")] string projectId,
%     [McpParameter("cod")] string cod,
%     [McpParameter("des")] string des,
%     [McpParameter("cat")] string cat,
%     [McpParameter("model")] string model,
%     [McpParameter("catmer")] string catmer,
%     [McpParameter("l")] int l,
%     [McpParameter("a")] int a,
%     [McpParameter("p")] int p,
%     [McpParameter("ruleset")] List<RuleSetItem>? ruleset = null,
%     [McpParameter("receiverId")] string? receiverId = null)
% {
%     await EnsureAuthenticatedAsync();
%     AddAuthHeader();
%
%     // FASE 1: Inserimento articolo base
%     var articleData = new {
%         id = projectId,
%         cod, des, cat, model, catmer,
%         l, a, p,
%         tipo = "a",
%         ruleset = new List<object>(), // Vuoto per ora
%         note = "",
%         rule = ""
%     };
%
%     var addResponse = await _httpClient.PostAsJsonAsync("/muconf/radd", articleData);
%     if (!addResponse.IsSuccessStatusCode)
%     {
%         return ErrorResponse("Errore inserimento articolo", addResponse.StatusCode);
%     }
%
%     var addResult = await addResponse.Content.ReadFromJsonAsync<ApiResponse>();
%     var rowId = addResult?.Data?.Data; // Estrai rowId
%
%     _logger.LogInformation("Articolo base inserito, rowId={RowId}", rowId);
%
%     // FASE 2: Applicazione varianti (se presenti)
%     bool variantsApplied = false;
%     if (ruleset != null && ruleset.Count > 0)
%     {
%         // Step 2.1: GET - Recupera stato corrente
%         var getRequest = new {
%             id = projectId,
%             idr = rowId,
%             noeval = true
%         };
%         var getResponse = await _httpClient.PostAsJsonAsync("/muconf/rget", getRequest);
%         var getResult = await getResponse.Content.ReadFromJsonAsync<ArticleResponse>();
%         var pars = getResult?.Data?.Pars ?? new Dictionary<string, string>();
%
%         // Step 2.2: MODIFY - Applica ruleset
%         foreach (var rule in ruleset)
%         {
%             pars[rule.Cod] = rule.Opz;
%             _logger.LogDebug("Applicata regola: {Cod}={Opz}", rule.Cod, rule.Opz);
%         }
%
%         // Step 2.3: SAVE - Salva modifiche
%         var saveRequest = new {
%             id = projectId,
%             idr = rowId,
%             pars
%         };
%         var saveResponse = await _httpClient.PostAsJsonAsync("/muconf/rsave", saveRequest);
%         variantsApplied = saveResponse.IsSuccessStatusCode;
%
%         _logger.LogInformation("Varianti applicate: {Count} regole", ruleset.Count);
%     }
%
%     // FASE 3: Notifica client 3D (se receiverId fornito)
%     bool notified = false;
%     if (!string.IsNullOrEmpty(receiverId))
%     {
%         var message = new Message {
%             Action = "open",
%             Name = projectId,
%             Route = $"/direct/{receiverId}",
%             Params = new { projectId, rowId }
%         };
%
%         notified = await _signalRService.CallHubMethodAsync(
%             "SendMessage", receiverId, message);
%
%         _logger.LogInformation("Client 3D notificato: {Notified}", notified);
%     }
%
%     // Risposta completa
%     return JsonSerializer.Serialize(new {
%         success = true,
%         rowId,
%         article = new { cod, des },
%         variantsApplied,
%         variantsCount = ruleset?.Count ?? 0,
%         notified
%     });
% }
% ```
%
% GESTIONE ERRORI:
% - Try-catch per eccezioni HTTP
% - Validazione response status codes
% - Logging strutturato per debugging
% - Partial success: articolo inserito anche se varianti falliscono
%
% PATTERN IMPLEMENTATIVI:
% - GET-MODIFY-SAVE: lettura → modifica → scrittura
% - Fluent chaining: operazioni sequenziali async
% - Dictionary manipulation: modifica campo pars
% - Conditional execution: varianti e notifica opzionali
%
% Concetti chiave:
% - Complex workflows: orchestrazione multiple API calls
% - Error resilience: partial success handling
% - Structured logging: tracciamento operazioni
% - Async coordination: await multiple operations
%
% Pagine stimate: 3-4

%----------------------------------------------------------------------------------------
\section{Implementazione SignalR Service}
\label{sec:implementazione-signalr-service}
%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------
\subsection{Classe SignalRService e Connection Management}
\label{subsec:signalr-service-class}
%----------------------------------------------------------------------------------------

% STRUTTURA CLASSE:
%
% ```csharp
% public class SignalRService : IAsyncDisposable
% {
%     private HubConnection? _hubConnection;
%     private readonly ILogger<SignalRService> _logger;
%     private readonly IConfiguration _config;
%     private string _configuredUrl;
%     private bool _isConnected;
%     private readonly List<Action<string, object>> _receiveHandlers = new();
%     private readonly object _lastListLock = new();
%     private string? _lastListElementsPayload;
%
%     public SignalRService(ILogger<SignalRService> logger, IConfiguration config)
%     {
%         _logger = logger;
%         _config = config;
%         _configuredUrl = _config["SignalR:HubUrl"] ?? "https://localhost:7193";
%     }
%
%     public bool IsConnected => _isConnected &&
%                                _hubConnection?.State == HubConnectionState.Connected;
%
%     public string? ConnectionId => _hubConnection?.ConnectionId;
% }
% ```
%
% METODO ConnectAsync CON RETRY LOGIC:
%
% ```csharp
% public async Task<bool> ConnectAsync()
% {
%     if (IsConnected) return true;
%
%     var urls = new[] {
%         _configuredUrl,
%         $"{_configuredUrl}/hub",
%         $"{_configuredUrl}/configuratorHub"
%     };
%
%     foreach (var url in urls)
%     {
%         try
%         {
%             _logger.LogInformation("Tentativo connessione a {Url}", url);
%
%             if (await TryBuildAndStartConnectionAsync(url))
%             {
%                 _isConnected = true;
%                 _logger.LogInformation("Connesso con successo, ConnectionId={Id}", ConnectionId);
%                 return true;
%             }
%         }
%         catch (Exception ex)
%         {
%             _logger.LogWarning(ex, "Fallito tentativo connessione a {Url}", url);
%         }
%     }
%
%     _logger.LogError("Tutti i tentativi di connessione falliti");
%     return false;
% }
%
% private async Task<bool> TryBuildAndStartConnectionAsync(string url)
% {
%     var allowInsecure = _config.GetValue<bool>("SignalR:AllowInsecureCertificates");
%
%     var builder = new HubConnectionBuilder()
%         .WithUrl(url, options => {
%             if (allowInsecure)
%             {
%                 options.HttpMessageHandlerFactory = handler => {
%                     if (handler is HttpClientHandler clientHandler)
%                     {
%                         clientHandler.ServerCertificateCustomValidationCallback =
%                             (message, cert, chain, errors) => true;
%                     }
%                     return handler;
%                 };
%             }
%         })
%         .WithAutomaticReconnect(new[] {
%             TimeSpan.Zero,      // Tentativo immediato
%             TimeSpan.FromSeconds(2),
%             TimeSpan.FromSeconds(5),
%             TimeSpan.FromSeconds(10)
%         })
%         .ConfigureLogging(logging => {
%             logging.SetMinimumLevel(LogLevel.Debug);
%         })
%         .Build();
%
%     // Registra event handlers
%     builder.Closed += async (error) => {
%         _isConnected = false;
%         _logger.LogWarning("Connessione SignalR chiusa: {Error}", error?.Message);
%         await Task.CompletedTask;
%     };
%
%     builder.Reconnecting += (error) => {
%         _logger.LogInformation("Tentativo riconnessione SignalR");
%         return Task.CompletedTask;
%     };
%
%     builder.Reconnected += (connectionId) => {
%         _isConnected = true;
%         _logger.LogInformation("Riconnessione riuscita, nuovo ConnectionId={Id}", connectionId);
%         return Task.CompletedTask;
%     };
%
%     // Registra message handlers
%     RegisterReceiveHandlers(builder);
%
%     await builder.StartAsync();
%     _hubConnection = builder;
%     return true;
% }
% ```
%
% GESTIONE RICONNESSIONE:
% - WithAutomaticReconnect: backoff esponenziale (0s, 2s, 5s, 10s)
% - Event handlers: Closed, Reconnecting, Reconnected
% - State tracking: _isConnected flag aggiornato
% - Logging: tracciamento tutti gli eventi lifecycle
%
% MULTIPLE ENDPOINT FALLBACK:
% - Prova URL base configurato
% - Prova URL + /hub (convenzione SignalR)
% - Prova URL + /configuratorHub (endpoint custom)
% - Loop su array con try-catch per resilienza
%
% CERTIFICATI SSL SVILUPPO:
% - ServerCertificateCustomValidationCallback per self-signed
% - Configurabile via appsettings (AllowInsecureCertificates)
% - Solo per ambiente sviluppo, disabilitato in produzione
%
% Concetti chiave:
% - Builder pattern: configurazione fluent HubConnection
% - Retry logic: tentativi multipli con backoff
% - Event-driven: handlers per lifecycle events
% - Configuration-driven: URL e certificati da appsettings
%
% Pagine stimate: 3-4

%----------------------------------------------------------------------------------------
\subsection{Invio e Ricezione Messaggi}
\label{subsec:invio-ricezione-messaggi}
%----------------------------------------------------------------------------------------

% INVIO MESSAGGI AL SERVER:
%
% ```csharp
% public async Task<bool> CallHubMethodAsync(string methodName, params object[] args)
% {
%     if (!IsConnected)
%     {
%         _logger.LogWarning("Tentativo invio messaggio senza connessione attiva");
%         return false;
%     }
%
%     try
%     {
%         await _hubConnection!.InvokeCoreAsync(methodName, args);
%         _logger.LogDebug("Invocato metodo {Method} con {ArgCount} argomenti",
%             methodName, args.Length);
%         return true;
%     }
%     catch (Exception ex)
%     {
%         _logger.LogError(ex, "Errore invocazione metodo {Method}", methodName);
%         return false;
%     }
% }
%
% public async Task<bool> SendCommandAsync(string receiverId, Message message)
% {
%     return await CallHubMethodAsync("SendMessage", receiverId, message);
% }
% ```
%
% RICEZIONE MESSAGGI DAL SERVER:
%
% ```csharp
% private void RegisterReceiveHandlers(HubConnection connection)
% {
%     // Handler per messaggi diretti
%     connection.On<string, object>("ReceiveMessage", (senderId, message) => {
%         _logger.LogInformation("Ricevuto messaggio da {Sender}", senderId);
%
%         // Invoca tutti gli handler registrati
%         foreach (var handler in _receiveHandlers)
%         {
%             try
%             {
%                 handler(senderId, message);
%             }
%             catch (Exception ex)
%             {
%                 _logger.LogError(ex, "Errore in message handler");
%             }
%         }
%     });
%
%     // Handler per messaggi generici
%     connection.On<object>("GetMessage", (message) => {
%         _logger.LogInformation("Ricevuto GetMessage: {Message}", message);
%     });
%
%     _logger.LogDebug("Handler messaggi registrati");
% }
%
% public void OnReceiveMessage(Action<string, object> handler)
% {
%     _receiveHandlers.Add(handler);
%     _logger.LogDebug("Registrato nuovo handler, totale={Count}", _receiveHandlers.Count);
% }
% ```
%
% HANDLER SPECIFICO PER LIST_ELEMENTS:
%
% ```csharp
% private void EnsureListElementsHandlerRegistered()
% {
%     if (_receiveHandlers.Any(h => h.Method.Name.Contains("ListElements")))
%         return;
%
%     OnReceiveMessage((senderId, message) => {
%         try
%         {
%             var messageObj = JsonSerializer.Deserialize<Message>(
%                 message.ToString() ?? "{}");
%
%             if (messageObj?.Action == "list_elements")
%             {
%                 lock (_lastListLock)
%                 {
%                     _lastListElementsPayload = JsonSerializer.Serialize(messageObj.Params);
%                 }
%                 _logger.LogInformation("Salvato payload list_elements");
%             }
%         }
%         catch (Exception ex)
%         {
%             _logger.LogError(ex, "Errore parsing message list_elements");
%         }
%     });
% }
%
% public string? GetLastListElements()
% {
%     lock (_lastListLock)
%     {
%         return _lastListElementsPayload;
%     }
% }
% ```
%
% PATTERN OBSERVER:
% - List di Action<string, object> per handler multipli
% - OnReceiveMessage registra callback
% - RegisterReceiveHandlers invoca tutti i callback
% - Thread-safe con try-catch per ogni handler
%
% GESTIONE STATE:
% - _lastListElementsPayload: cache ultimo payload ricevuto
% - Lock per thread-safety (_lastListLock)
% - Getter pubblico per recupero asincrono
%
% SERIALIZZAZIONE/DESERIALIZZAZIONE:
% - SignalR serializza automaticamente Message in JSON
% - Deserializzazione manuale per processing specifico
% - System.Text.Json per performance
%
% Concetti chiave:
% - Observer Pattern: multiple handlers per eventi
% - Thread-safety: lock per accesso concorrente
% - Type-safe invocation: InvokeCoreAsync con params
% - Error isolation: try-catch per ogni handler
%
% Pagine stimate: 3-4

%----------------------------------------------------------------------------------------
\section{Implementazione Hub (SignalR Server)}
\label{sec:implementazione-hub}
%----------------------------------------------------------------------------------------

% CLASSE HUB PRINCIPALE:
%
% ```csharp
% public class IwineHub : Hub<IClient>
% {
%     private readonly ILogger<IwineHub> _logger;
%
%     public IwineHub(ILogger<IwineHub> logger)
%     {
%         _logger = logger;
%     }
%
%     public override async Task OnConnectedAsync()
%     {
%         var connectionId = Context.ConnectionId;
%         _logger.LogInformation("Client connesso: {ConnectionId}", connectionId);
%
%         // Invia ConnectionId al client
%         await Clients.Caller.GetConnectionId(connectionId);
%
%         await base.OnConnectedAsync();
%     }
%
%     public override async Task OnDisconnectedAsync(Exception? exception)
%     {
%         var connectionId = Context.ConnectionId;
%         _logger.LogInformation("Client disconnesso: {ConnectionId}, Reason: {Reason}",
%             connectionId, exception?.Message);
%
%         await base.OnDisconnectedAsync(exception);
%     }
%
%     public async Task SendMessage(Message message)
%     {
%         var senderId = Context.ConnectionId;
%         _logger.LogInformation("SendMessage da {Sender}, Action={Action}, Route={Route}",
%             senderId, message.Action, message.Route);
%
%         try
%         {
%             // Validazione messaggio
%             if (string.IsNullOrEmpty(message.Action))
%             {
%                 throw new HubException("Action è obbligatoria");
%             }
%
%             // Routing basato su Route
%             if (message.Route?.StartsWith("/broadcast") == true)
%             {
%                 // Broadcasting a tutti
%                 await Clients.All.GetMessage(message);
%                 _logger.LogDebug("Messaggio broadcast a tutti i client");
%             }
%             else if (message.Params is JsonElement paramsElement &&
%                      paramsElement.TryGetProperty("receiverId", out var receiverIdProp))
%             {
%                 // Point-to-point a client specifico
%                 var receiverId = receiverIdProp.GetString();
%                 await Clients.Client(receiverId!).GetMessage(message);
%                 _logger.LogDebug("Messaggio inviato a {Receiver}", receiverId);
%             }
%             else
%             {
%                 // Default: broadcast
%                 await Clients.All.GetMessage(message);
%             }
%         }
%         catch (Exception ex)
%         {
%             _logger.LogError(ex, "Errore processing messaggio");
%             throw new HubException($"Errore processing messaggio: {ex.Message}");
%         }
%     }
%
%     public async Task SendConnectionId(string receiverId, string senderId)
%     {
%         _logger.LogInformation("SendConnectionId: {Sender} → {Receiver}",
%             senderId, receiverId);
%
%         try
%         {
%             await Clients.Client(receiverId).GetConnectionId(senderId);
%         }
%         catch (Exception ex)
%         {
%             _logger.LogError(ex, "Errore invio ConnectionId");
%             throw new HubException($"Client {receiverId} non trovato");
%         }
%     }
% }
% ```
%
% INTERFACCIA STRONGLY-TYPED:
%
% ```csharp
% public interface IClient
% {
%     Task GetMessage(Message message);
%     Task GetConnectionId(string connectionId);
% }
% ```
%
% CONFIGURAZIONE ASP.NET CORE:
%
% ```csharp
% // Program.cs del SignalR Server
% var builder = WebApplication.CreateBuilder(args);
%
% // Aggiungi SignalR
% builder.Services.AddSignalR(options => {
%     options.EnableDetailedErrors = true;
%     options.KeepAliveInterval = TimeSpan.FromSeconds(15);
%     options.ClientTimeoutInterval = TimeSpan.FromSeconds(30);
% });
%
% // Aggiungi CORS
% builder.Services.AddCors(options => {
%     options.AddPolicy("AllowAll", policy => {
%         policy.AllowAnyOrigin()
%               .AllowAnyMethod()
%               .AllowAnyHeader();
%     });
% });
%
% var app = builder.Build();
%
% app.UseCors("AllowAll");
% app.UseRouting();
%
% // Mappa Hub SignalR
% app.MapHub<IwineHub>("/configuratorHub");
%
% app.Run();
% ```
%
% ROUTING MESSAGGI:
% - Pattern matching su message.Route
% - Clients.All per broadcasting
% - Clients.Client(id) per point-to-point
% - Clients.Caller per risposta a mittente
% - Clients.Group(name) per gruppi (se implementato)
%
% VALIDAZIONE:
% - Controllo message.Action non vuoto
% - Try-catch per errori processing
% - HubException per errori client-friendly
% - Logging strutturato per debugging
%
% STRONGLY-TYPED HUB:
% - Hub<IClient> per type-safety
% - Compilazione verifica metodi IClient
% - IntelliSense per metodi client
% - Refactoring safe
%
% Concetti chiave:
% - Hub as controller: routing e orchestrazione
% - Strongly-typed clients: type-safety end-to-end
% - Lifecycle hooks: OnConnected/OnDisconnected
% - CORS configuration: cross-origin support
%
% Pagine stimate: 3-4

%----------------------------------------------------------------------------------------
\section{Implementazione Client Configurator3D}
\label{sec:implementazione-client-3d}
%----------------------------------------------------------------------------------------

% CLIENT TYPESCRIPT SIGNALR:
%
% ```typescript
% import * as signalR from "@microsoft/signalr";
%
% export class SignalRClient {
%     private connection: signalR.HubConnection;
%     private messageHandlers: Map<string, (message: Message) => void>;
%
%     constructor(hubUrl: string) {
%         this.messageHandlers = new Map();
%
%         this.connection = new signalR.HubConnectionBuilder()
%             .withUrl(hubUrl)
%             .withAutomaticReconnect([0, 2000, 5000, 10000])
%             .configureLogging(signalR.LogLevel.Information)
%             .build();
%
%         this.setupEventHandlers();
%     }
%
%     private setupEventHandlers(): void {
%         // Handler ricezione messaggi
%         this.connection.on("GetMessage", (message: Message) => {
%             console.log("Ricevuto messaggio:", message);
%             this.handleMessage(message);
%         });
%
%         // Handler ricezione ConnectionId
%         this.connection.on("GetConnectionId", (connectionId: string) => {
%             console.log("Ricevuto ConnectionId:", connectionId);
%             localStorage.setItem("signalr-connection-id", connectionId);
%         });
%
%         // Lifecycle events
%         this.connection.onclose((error) => {
%             console.warn("Connessione chiusa:", error);
%         });
%
%         this.connection.onreconnecting((error) => {
%             console.info("Tentativo riconnessione...");
%         });
%
%         this.connection.onreconnected((connectionId) => {
%             console.info("Riconnesso, nuovo ID:", connectionId);
%         });
%     }
%
%     async start(): Promise<void> {
%         try {
%             await this.connection.start();
%             console.log("SignalR connesso, ID:", this.connection.connectionId);
%         } catch (error) {
%             console.error("Errore connessione SignalR:", error);
%             setTimeout(() => this.start(), 5000); // Retry dopo 5s
%         }
%     }
%
%     registerHandler(action: string, handler: (message: Message) => void): void {
%         this.messageHandlers.set(action, handler);
%     }
%
%     private handleMessage(message: Message): void {
%         const handler = this.messageHandlers.get(message.Action);
%         if (handler) {
%             handler(message);
%         } else {
%             console.warn("Nessun handler per action:", message.Action);
%         }
%     }
%
%     async sendMessage(message: Message): Promise<void> {
%         await this.connection.invoke("SendMessage", message);
%     }
% }
% ```
%
% MESSAGE HANDLER SPECIFICI:
%
% ```typescript
% export class MessageHandler {
%     private signalRClient: SignalRClient;
%     private configurator: Configurator3D;
%
%     constructor(signalRClient: SignalRClient, configurator: Configurator3D) {
%         this.signalRClient = signalRClient;
%         this.configurator = configurator;
%
%         this.registerHandlers();
%     }
%
%     private registerHandlers(): void {
%         // Handler per "open"
%         this.signalRClient.registerHandler("open", async (message) => {
%             const projectId = message.Name;
%             console.log("Comando OPEN progetto:", projectId);
%
%             // Carica progetto nel configurator 3D
%             const projectData = await this.fetchProjectData(projectId);
%             await this.configurator.loadProject(projectData);
%
%             // Invia conferma
%             await this.sendAck(message, { loaded: true });
%         });
%
%         // Handler per "create"
%         this.signalRClient.registerHandler("create", async (message) => {
%             const params = message.Params as CreateProjectParams;
%             console.log("Comando CREATE progetto:", params);
%
%             // Mostra dialog creazione con dati pre-compilati
%             this.configurator.showCreateDialog({
%                 description: params.des,
%                 notes: params.note,
%                 autoOpen: params.open
%             });
%         });
%
%         // Handler per "list_elements"
%         this.signalRClient.registerHandler("list_elements", async (message) => {
%             const params = message.Params as ListElementsParams;
%             console.log("Richiesta LIST_ELEMENTS:", params);
%
%             // Cerca nel catalogo locale
%             const results = await this.configurator.searchCatalog(
%                 params.catalogo,
%                 params.cerca
%             );
%
%             // Invia risultati al server
%             await this.signalRClient.sendMessage({
%                 Action: "list_elements",
%                 Name: "response",
%                 Route: "/response",
%                 Params: results
%             });
%         });
%     }
%
%     private async fetchProjectData(projectId: string): Promise<ProjectData> {
%         const response = await fetch(`/api/projects/${projectId}`);
%         return await response.json();
%     }
%
%     private async sendAck(originalMessage: Message, data: any): Promise<void> {
%         await this.signalRClient.sendMessage({
%             Action: "ack",
%             Name: originalMessage.Action,
%             Route: "/ack",
%             Params: data
%         });
%     }
% }
% ```
%
% INTEGRAZIONE CON CONFIGURATOR 3D:
% - SignalRClient: gestione connessione e messaggi
% - MessageHandler: dispatch messaggi ad azioni specifiche
% - Configurator3D: interfaccia per operazioni 3D (loadProject, showCreateDialog, searchCatalog)
% - Comunicazione bidirezionale: client può rispondere con sendMessage
%
% PATTERN IMPLEMENTATIVI:
% - Map<string, handler>: dispatch dinamico per action
% - Async/await: operazioni asincrone (fetch, invoke)
% - Lifecycle management: setup in constructor, cleanup in destroy
% - Error handling: try-catch con logging
%
% Concetti chiave:
% - TypeScript: type-safety lato client
% - SignalR JS SDK: client WebSocket JavaScript
% - Handler registration: pattern observer client-side
% - Bidirectional communication: client può inviare/ricevere
%
% Pagine stimate: 3-4

%----------------------------------------------------------------------------------------
\section{Gestione Configurazione e Sicurezza}
\label{sec:configurazione-sicurezza}
%----------------------------------------------------------------------------------------

% GESTIONE APPSETTINGS PER AMBIENTE:
%
% appsettings.json (base):
% ```json
% {
%   "MarkunoApi": {
%     "BaseUrl": "https://api.markuno.com"
%   },
%   "SignalR": {
%     "HubUrl": "https://signalr.markuno.com",
%     "AllowInsecureCertificates": false
%   },
%   "Logging": {
%     "LogLevel": {
%       "Default": "Information"
%     }
%   }
% }
% ```
%
% appsettings.Development.json:
% ```json
% {
%   "MarkunoApi": {
%     "BaseUrl": "https://localhost:5001",
%     "DefaultUser": "dev-user",
%     "DefaultPassword": "dev-password"
%   },
%   "SignalR": {
%     "HubUrl": "https://localhost:7193",
%     "AllowInsecureCertificates": true
%   },
%   "Logging": {
%     "LogLevel": {
%       "Default": "Debug",
%       "Microsoft.AspNetCore.SignalR": "Trace"
%     }
%   }
% }
% ```
%
% SECRETS MANAGEMENT:
% - User Secrets per sviluppo locale
% - dotnet user-secrets init
% - dotnet user-secrets set "MarkunoApi:DefaultPassword" "secret"
% - Non committare credenziali in Git
% - Azure Key Vault per produzione
%
% CONFIGURAZIONE SSL/TLS:
%
% ```csharp
% // Sviluppo: Trust certificati self-signed
% if (builder.Environment.IsDevelopment())
% {
%     builder.Services.AddHttpClient()
%         .ConfigurePrimaryHttpMessageHandler(() => new HttpClientHandler {
%             ServerCertificateCustomValidationCallback =
%                 HttpClientHandler.DangerousAcceptAnyServerCertificateValidator
%         });
% }
% ```
%
% AUTENTICAZIONE JWT:
%
% ```csharp
% // IwineHub authentication
% builder.Services.AddAuthentication(JwtBearerDefaults.AuthenticationScheme)
%     .AddJwtBearer(options => {
%         options.Authority = "https://identity-server.com";
%         options.Audience = "iwine-hub";
%
%         // Per SignalR
%         options.Events = new JwtBearerEvents {
%             OnMessageReceived = context => {
%                 var accessToken = context.Request.Query["access_token"];
%                 var path = context.HttpContext.Request.Path;
%
%                 if (!string.IsNullOrEmpty(accessToken) &&
%                     path.StartsWithSegments("/configuratorHub"))
%                 {
%                     context.Token = accessToken;
%                 }
%                 return Task.CompletedTask;
%             }
%         };
%     });
% ```
%
% CORS CONFIGURATION:
%
% ```csharp
% builder.Services.AddCors(options => {
%     options.AddPolicy("Production", policy => {
%         policy.WithOrigins(
%             "https://configurator.markuno.com",
%             "https://app.markuno.com"
%         )
%         .AllowAnyMethod()
%         .AllowAnyHeader()
%         .AllowCredentials(); // Per SignalR cookies
%     });
%
%     options.AddPolicy("Development", policy => {
%         policy.AllowAnyOrigin()
%               .AllowAnyMethod()
%               .AllowAnyHeader();
%     });
% });
%
% var corsPolicy = builder.Environment.IsDevelopment()
%     ? "Development"
%     : "Production";
% app.UseCors(corsPolicy);
% ```
%
% BEST PRACTICES SICUREZZA:
% - Credenziali mai hardcoded
% - HTTPS/WSS obbligatorio in produzione
% - JWT con expiration breve (15-30 min)
% - Refresh token per sessioni lunghe
% - CORS policy restrittive in produzione
% - Input validation per tutti i parametri
% - Rate limiting per prevenire abuse
%
% Concetti chiave:
% - Configuration hierarchy: base → environment → secrets
% - Environment-specific settings: Development vs Production
% - JWT Bearer authentication: standard OAuth 2.0
% - CORS policies: security cross-origin
% - SSL/TLS: encryption in transit
%
% Pagine stimate: 3-4

%----------------------------------------------------------------------------------------

\chapter{Conclusioni e sviluppi futuri}
% BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\backmatter

\nocite{*} % Remove this as soon as you have the first citation

\bibliographystyle{alpha}
\bibliography{bibliography}

\begin{acknowledgements} % this is optional
Optional. Max 1 page.
\end{acknowledgements}

\end{document}
